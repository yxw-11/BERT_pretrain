{"index": 0, "text": "We used a discrimination task to investigate the effect of stereo vision on eccentricity. The eccentricities were 15 arc deg, 30 arc deg, 35 arc deg, 42 arc deg and 50 arc deg. Participants distributed attention to locations indicated by a predictive cue. Attention areas were defined by a capital H. The participants must attention the direction that the cue indicated and reported the type of the targets-concave or convex. The results showed that the perception of stereopsis declined with the increasing eccentricities. Within the central 30 arc deg of the visual field, the stereopsis was clear. But beyond 30 arc deg of the visual field, specially beyond 42 arc deg, it was very hard to distinguish crossed disparities and uncrossed disparities.", "paperid": 2896227666, "normalizedname_level1": "artificial intelligence"}
{"index": 1, "text": "This paper proposes an automatic method, for monitoring inverter fed induction motors using external stray flux measurements. The method relies on the marginal power spectrum of the Synchrosqueezed Wavelet Transform for the feature extraction stage and on Principal Component Analysis for the reduction of the high dimensionality of the generated feature vector. For the next stage two approaches were tested: a) a fault detector based on a one-class classifier and b) a fault diagnosis module based on a multiclass classifier. Both of them achieve high accuracies when tested with measurements coming from an experimental set up able to simulate stator short circuits and bearing faults. An explanation of the performance is given by visual inspection of the projection of the feature vectors into a three-dimensional space.", "paperid": 2893823922, "normalizedname_level1": "artificial intelligence"}
{"index": 2, "text": "Depth perception remains a key challenge in vitreoretinal surgery. Currently users only have the view from an overhead stereo-microscope available, but this means of visualisation is quite restrictive. Optical Coherence Tomography (OCT) has been introduced in the past and is even integrated in a number of commercial systems to provide a more detailed depth vision, even showing subsurface structures up to a few millimeters below the surface. The intra-operative use of OCT, especially in combination with robotics, is still sub-optimal. At present one can get either a very slowly updating large volume scan (C-scan) or a faster but not aligned cross-sectional B-scan or an even more local single point A-scan at very high update rate. In this work we propose a model-mediated approach. As the posterior eye segment can be approximated as a sphere, we propose to model the retina with this simplified sphere model, the center and radius of which can be estimated in real time. A time-varying Kalman filter is proposed here in combination with an instrument-integrated optical fiber that provides high-frequency A-scans along the longitudinal instrument direction. The model and convergence of the model has been validated first in a simulation environment and subsequently in-silico using an OCT A-scan probe mounted on a co-manipulated vitreoretinal robotic system. The probe was manipulated to measure a 3D stereo lithographically printed spherical model of the posterior eye segment. The feasibility of the proposed method was demonstrated in various scenarios. For the in-silico validation a 20 micrometer error and convergence speed of 2.0 seconds was found when sampling A-scans at 200Hz.", "paperid": 3004827631, "normalizedname_level1": "artificial intelligence"}
{"index": 3, "text": "Pixel-wise coded exposure, as an emerging field of research in computational imaging, is widely implemented in applications such as high-speed imaging, compressive sensing, and focal-stack imaging. In this paper, a complementary metal-oxide-semiconductor (CMOS) pixel design for binary coded exposure is presented. Based on an always-on charge distribution structure, the proposed pixel achieves programmable charge selection. A prototype image sensor chip, fabricated in a 0.13-μm CMOS process demonstrates pixel's capability of binary exposure encoding in 60 fps while operating from a 3.3 V supply.", "paperid": 2760739162, "normalizedname_level1": "artificial intelligence"}
{"index": 4, "text": "Being a powerful appearance model, compressive random projection derives effective Haar-like features from non-rotated 4-D-parameterized rectangles, thus supporting fast and reliable object tracking. In this paper, we show that such successful fast compressive tracking scheme can be further significantly improved by structural regularization and online data-driven sampling. Our major contribution is threefold. First, we find that superpixel-guided compressive projection can generate more discriminative features by sufficiently capturing rich local structural information of images. Second, we propose fast directional integration that enables low-cost extraction of feasible Haar-like features from arbitrarily rotated 5-D-parameterized rectangles to realize more accurate object localization. Third, beyond naive dense uniform sampling, we present two practical online data-driven sampling strategies to produce less yet more effective candidate and training samples for object detection and classifier updating, respectively. Extensive experiments on real-world benchmark data sets validate the superior performance, i.e., much better object localization ability and robustness, of the proposed approach over state-of-the-art trackers.", "paperid": 2748399257, "normalizedname_level1": "artificial intelligence"}
{"index": 5, "text": "Protein sequence classification is increasingly crucial in the current “biological information sciences” epoch, where researchers hammer at functional genomics and proteomics technologies for predicting the function of large-scale new proteins. This has sparked interest in the methods which do not rely on traditional sequence alignment, but prefer machine learning approaches. In this paper, we present a Convolutional Neural Network (CNN) based method to perform the classification on the different levels of G-protein Coupled Receptors (GPCRs). The method is implemented in conjunction with an improved feature extraction method and TF-IDF feature weighting strategy. Experimental results indicate that the proposed method makes significant improvements over previous methods, which attains an accuracy of up to 98.34%, 98.13% and 96.47% in the classification of family level, subfamily level I and II, respectively. In comparison to the other well-known classification methods for GPCRs, the classification error rate of the proposed method is reduced by of at least 55.14% (family level), 72.86% (level I) and 52.63% (Level II).", "paperid": 2752689404, "normalizedname_level1": "artificial intelligence"}
{"index": 6, "text": "Siamese-based trackers have achieved excellent performance on visual object tracking. However, the target template is not updated online, and the features of target template and search image are computed independently in a Siamese architecture. In this paper, we propose Deformable Siamese Attention Networks, referred to as SiamAttn, by introducing a new Siamese attention mechanism that computes deformable self-attention and cross-attention. The self-attention learns strong context information via spatial attention, and selectively emphasizes interdependent channel-wise features with channel attention. The crossattention is capable of aggregating rich contextual interdependencies between the target template and the search image, providing an implicit manner to adaptively update the target template. In addition, we design a region refinement module that computes depth-wise cross correlations between the attentional features for more accurate tracking. We conduct experiments on six benchmarks, where our method achieves new state-of-the-art results, outperforming recent strong baseline, SiamRPN++, by 0.464 to 0.537 and 0.415 to 0.470 EAO on VOT 2016 and 2018.", "paperid": 3035211844, "normalizedname_level1": "artificial intelligence"}
{"index": 7, "text": "Emotion recognition has gained importance and significant attention as a part of the human-computer interface (HCI), and is envisioned to provide an \"emotional dimension\" to HCI. In this paper, we propose a novel method for participant-dependent and participant-independent emotion recognition using electroencephalogram (EEG) signals. We aim to distinguish between positive and negative valence emotions on the valence-arousal graph, i.e., considering a binary classification problem. The EEG signals of DEAP dataset, where forty different videos were used to stimulate 32 participants is considered for the classification problem. Participant-dependent features are extracted in order to classify emotions for each participant, where a perfect classification score is shown to be achieved for one of the participants. Next, we consider generalization across participants and find participant-independent features. Applying the widely used or conventional method in this regard, we observe that the training time increases many fold with increase in participants. We propose a technique called averaging of features and show that the computational complexity of the proposed technique is significantly low as compared to the conventional method with increase in participants. The results obtained by detailed experiments and evaluation procedure indicate that averaging of features technique yields nearly the same performance as the conventional approach, but scarcely consumes computational time. The maximum classification accuracy for 32 participants was obtained to be 81.03% and 77.46% using conventional and averaging approaches respectively.", "paperid": 2794012231, "normalizedname_level1": "artificial intelligence"}
{"index": 8, "text": "To identify the dynamic changing objects in smart substations, this paper proposes a moving object detection scheme based on video Surveillance. Firstly, this paper describes the basic principle of the proposed detect scheme comprising its function diagram. Secondly, two main operations of the proposed scheme are discussed, which are image dithering and Gaussian-model foreground extraction. Taking the video in the substation as test data, the experiment illustrate that the propose scheme is of better performance in the detection of moving objects in the video blurring case.", "paperid": 2919311693, "normalizedname_level1": "artificial intelligence"}
{"index": 9, "text": "Lately, the problem of code-switching has gained a lot of attention and has emerged as an active area of research. In bilingual communities, the speakers commonly embed the words and phrases of a non-native language into the syntax of a native language in their day-to-day communications. The code-switching is a global phenomenon among multilingual communities, still very limited acoustic and linguistic resources are available as yet. For developing effective speech-based applications, the ability of the existing language technologies to deal with the code-switched data cannot be over emphasized. The code-switching is broadly classified into two modes: inter-sentential and intra-sentential code-switching. In this work, we have studied the intrasentential problem in the context of code-switching language modeling task. The salient contributions of this paper includes: (i) the creation of Hindi-English code-switching text corpus by crawling a few blogging sites educating about the usage of the Internet, and (ii) the exploration of the parts-of-speech features towards more effective modeling of Hindi-English code-switched data by the monolingual language models trained on native (Hindi) language data.", "paperid": 2909164373, "normalizedname_level1": "artificial intelligence"}
{"index": 10, "text": "The performance recognition of bacteria cell images is an effective survey for treatment of various diseases caused by the bacteria. Many algorithms for bacteria classification are designed for the needs of analysis of large-scale microscopic image bacteria. However, the biologist interpretation is suffered from insufficient information and thus may lead to limited accuracy in the bacteria classification process. To handle this drawback, machine learning tools, and image analysis approaches tackled identification of different bacteria species for improving the clinical microbiology investigation. In the proposed study, 200 bacterial images for ten different bacteria species with 20 images for each specie are extracted from DIBaS (Digital Images of Bacteria Species dataset). This proposed framework is divided into image preprocessing phase which obtained by histogram equalization, feature extraction by Bag-of-words model and classification phase by Support Vector Machine (SVM). The main objective is to enhance the bacterial images and find the image feature descriptors from the enhanced images which allowing to classify the bacterial images. The experimental results provided an average accuracy of 97% with classifier speed for automated detection and classification of bacterial images which would greatly reduce the disease outbreaks in future researches.", "paperid": 2912222853, "normalizedname_level1": "artificial intelligence"}
{"index": 11, "text": "The task of cross-view image geo-localization aims to determine the geo-location (GPS coordinates) of a query ground-view image by matching it with the GPS-tagged aerial (satellite) images in a reference dataset. Due to the dramatic changes of viewpoint, matching the cross-view images is challenging. In this paper, we propose the GeoCapsNet based on the capsule network for ground-to-aerial image geo-localization. The network first extracts features from both ground and aerial images via standard convolution layers and the capsule layers further encode the features to model the spatial feature hierarchies and enhance the representation power. Moreover, we introduce a simple and effective weighted soft-margin triplet loss with online batch hard sample mining, which can greatly improve the image retrieval accuracy. Experimental results show that our GeoCapsNet significantly outperforms the state-of-the-art approaches on two benchmark datasets.", "paperid": 2965143341, "normalizedname_level1": "artificial intelligence"}
{"index": 12, "text": "In this paper, we propose an unsupervised joint deep learning pipeline for depth and ego-motion estimation that explicitly incorporated with traditional spatial-temporal geometric constraints. The stereo reconstruction error provides the spatial geometric constraint to estimate the absolute scale depth. Meanwhile, the depth map with absolute scale and a pre-trained pose network serve as a good starting point for direct visual odometry (DVO), resulting in a fine-grained ego-motion estimation with the additional back-propagation signals provided to the depth estimation network. The proposed joint training pipeline enables an iterative coupling optimization process for accurate depth and precise ego-motion estimation. The experimental results show the state-of-the-art performance for monocular depth and ego-motion estimation on the KITTI dataset and a great generalization ability of the proposed approach.", "paperid": 2964814869, "normalizedname_level1": "artificial intelligence"}
{"index": 13, "text": "Robotics is increasing in popularity as a method of providing rich, personalized and cost-effective physiotherapy to individuals with some degree of upper limb paralysis, such as those who have suffered a stroke. These robotic rehabilitation systems are often high powered, and exoskeletal systems can attach to the person in a restrictive manner. Therefore, ensuring the mechanical safety of these devices before they come in contact with individuals is a priority. Additionally, rehabilitation systems may use novel sensor systems to measure current arm position. Used to capture and assess patient movements, these first need to be verified for accuracy by an external system. We present the ALAN-Arm, a humanoid robotic arm designed to be used for both accuracy benchmarking and safety testing of robotic rehabilitation systems. The system can be attached to a rehabilitation device and then replay generated or human movement trajectories, as well as autonomously play rehabilitation games or activities. Tests of the ALAN-Arm indicated it could recreate the path of a generated slow movement path with a maximum error of 14.2mm (mean = 5.8mm) and perform cyclic movements up to 0.6Hz with low gain (<1.5dB). Replaying human data trajectories showed the ability to largely preserve human movement characteristics with slightly higher path length and lower normalised jerk.", "paperid": 2743613233, "normalizedname_level1": "artificial intelligence"}
{"index": 14, "text": "In this work, a robotic prosthesis controlled by Spike-type neural networks in conjunction with quaternions is developed. Neural networks are implemented from the development of myoelectric signals to the control of the hand prosthesis. Similarly, the development and obtaining of the prosthesis seen from a mechanical part is shown.", "paperid": 2911237842, "normalizedname_level1": "artificial intelligence"}
{"index": 15, "text": "In this paper, we propose an approach for depth image super-resolution (SR). Given a noisy low resolution (LR) depth image and its corresponding registered high resolution (HR) colour image, our approach improves the resolution of the LR image while suppressing noise. We use the segmentation of HR colour images as a cue for depth image super-resolution. Our method begins with a highly over-segmented color image (using well-known segmentation approaches such as mean shift (MS) or simple linear iterative clustering (SLIC), and an interpolated LR depth image. We then use a combination of the local medians in the depth image (corresponding to the colour segments) and bicubic interpolation, followed by bilateral filtering to compute the SR depth image. We performed experiments for higher magnification factors 4, 8 using the Middlebury depth image dataset and evaluate the SR performance using the PSNR and SSIM metrics. The experimental results show that proposed method (including some variants), while being relatively simplistic, shows an average improvement of 1.2dB and 1.7dB on noiseless and noisy data respectively, over the popular method of guided image filtering (GIF) for upsampling factor 8.", "paperid": 2782724259, "normalizedname_level1": "artificial intelligence"}
{"index": 16, "text": "Air pollution is still a big threat to human health particularly for developing countries. It is highly demanding to measure air quality with daily-used devices such as smartphones. On the other hand, it is difficult to estimate the scene depth under the foul weather using traditional vision-based methods. This paper proposes an image-based method for PM2.5 estimation by capturing a single image. We extract high-level features based on convolutional neural network (CNN) and learn the mapping between the features and PM2.5 by support vector regression (SVR). Given a captured image, we can estimate the PM2.5 value in real time. With the estimated PM2.5, we can estimate the depth of scene using sparse prior and nonlocal bilateral kernel. Experimental results demonstrate that the proposed method achieves the same accuracy of PM2.5 estimation as commodity measurement devices, and estimates the accurate depth information that is even better than the “ground-truth” captured by a laser in the no-haze condition.", "paperid": 2885605478, "normalizedname_level1": "artificial intelligence"}
{"index": 17, "text": "With the proliferation of mobile devices, research on image retargeting is becoming ever more important. However, there is little work on image retargeting quality assessment despite its importance. In this work, we focus on evaluating retargeting quality based on line distortion. Generally, image retargeting results in content loss and shape distortion. Line segments, which are fundamental image structures, are hence discarded or distorted in retargeted images. As a result, we formulate a retargeting quality index consisted of three line distortion measures: line loss, line artifact and line rotation. To test its performance, we have validated it on the public dataset RetargetMe. Experimental results demonstrate that our method outperforms many existent ones and line distortion is a good indicator of retargeting quality.", "paperid": 2587443530, "normalizedname_level1": "artificial intelligence"}
{"index": 18, "text": "A covariance alignment and collaborative representation-based classification with Tikhonov regularization based method (CACRT) is proposed to utilize historical training samples to classify new hyperspectral images. Specifically, the new hyperspectral image and the historical hyperspectral image are preprocessed by spectral matching and covariance alignment. Then the corresponding categories are selected. Finally, using the historical training samples or combined the historical samples with the new labeled samples to classify the new hyperspectral data by CRT classifier. Experimental results prove that the proposed method performs well.", "paperid": 2979391341, "normalizedname_level1": "artificial intelligence"}
{"index": 19, "text": "Currently, positioning in indoor environment enjoys heavy demands in many public places. Considering that methods for outdoor positioning such as satellites localization are not applicable in indoor environment, Wi-Fi indoor positioning technology, regarding signal indicators as fingerprints, is a popular approach. However, most prior researches focus on the single device in position identification. As a result, the Euclidean distance similarity method, which is widely used for fingerprint matching of a single device, is not suitable for multiple devices. To solve the problem, this research aims to find a better matching method for multiple devices. An experiment is set to find the characteristics of Wi-Fi Received Signal Strength Indicator (RSSI) and create fingerprints for every position point. Since at least 92% RSSIs at one position point centralize at a specific value in the stable environment, the most centralized value is selected as fingerprints. Using the collected data and fingerprints, two matching methods— Euclidean Distance method and Cosine Similarity method, are compared in fingerprint matching for the same and different devices. The experiment results demonstrate that, by using two methods, the precision for same device matching is similar. However, for different device matching, Cosine similarity method, which has obviously increased the match accuracy, is a better method in fingerprint matching.", "paperid": 2964539785, "normalizedname_level1": "artificial intelligence"}
{"index": 20, "text": "Visual object tracking (VOT) is a computer vision application and has a wide range of use. However, related state of the art algorithms using deep learning methods, are computationally intensive and storage explosive. Whats more, despite many deep learning accelerators have been proposed, many of them are general structure. So, in this paper, we propose a lightweight CNN-based system–-MiniTracker, integration of algorithm and hardware–-particularly efficient for VOT. Because of the fully-convolutional Siamese network we used, the parameters of network do not need online training, which reduces computation consumptions dramatically. We adapt the original Siamese network (SN) into effective hardware implementation by parameter pruning and quantization. Then a lightweight CNN with the 8-bit parameters is produced, which is only 1.939MB. The real tracking rate is 18.6 frames per second at the cost of 1.284W on ZedBoard. Moreover, Compared with other hardware implementations, our system is robust to challenging scenarios, such as occlusions, changing appearance, illumination variations and etc.", "paperid": 2912891814, "normalizedname_level1": "artificial intelligence"}
{"index": 21, "text": "Food delivery service receives increasing attention nowadays, and path planning plays an important role in the related practical applications. To accomplish the delivery tasks in a short time, deliver staffs traverse all the customers in a short tour to guarantee the freshness of food. In addition, they also need diverse good solutions from which they can choose according to their preference. To obtain diverse good solutions, we propose a multi-population ant colony system algorithm. The ant colony system guides the ants towards a promising space, while the multi-population strategy promises to maintain multiple potential candidate solutions at simultaneously. To evaluate the performance of the proposed algorithm, it is applied to four test instances. The experimental results show that the proposed algorithm can obtain diverse good solutions. Furthermore, the proposed algorithm is utilized to deal with a range of practical problems, which indicates that the proposed algorithm is of practical significance.", "paperid": 2914758244, "normalizedname_level1": "artificial intelligence"}
{"index": 22, "text": "In the last years the interest on multimedia services has rapidly increased which leads to requirements of quality assessment, especially in video domain. Compression together with transmission link imperfection are two main factors that influence the quality. This paper deals with the video quality assessment of the impact of VP9 compression standard using both objective and subjective methods for Full HD resolution. Afterwards the correlation between all objective and subjective methods is calculated as well as the mapping procedure of selected objective method into the subjective MOS scale is done.", "paperid": 2515941354, "normalizedname_level1": "artificial intelligence"}
{"index": 23, "text": "Subspace clustering can offer, beside a decomposition of data into homogeneous and distinct clusters, a characterisation of the subspaces in which the clusters live. This paper explores the possibility of capturing the notion of characteristic features in the framework of typicality degrees, as typical features. To that aim, it discusses the notion of typicality degrees for features and proposes an Alternating Cluster Estimation algorithm, named TbSC, to exploit these degrees within subspace clustering. It illustrates their differences experimentally using simple data sets.", "paperid": 3082742922, "normalizedname_level1": "artificial intelligence"}
{"index": 24, "text": "In many real life situations end results and basic starting data are known. To deduce conclusive evidence or to build holistic picture one needs to find out hidden information and missing text. This research paper delivers a novel algorithm (Probabilistic Intent-Action Ontology and Tone Matching Algorithm) to map multiple events on time line by determining their interdependency to predict the most probable series of events that might have occurred. Various aspects of flow of events, continuity, negation, shift of emotions etc. are considered. This algorithm is based on analyzing multidimensional intent and action relationships, application of naive Bayes theorem to text, plotting relative hyperbolic probability and plotting the tone matching graph and calculating deviations. The proposed method shows very promising results. This approach can be used to solve many real life problems like solving criminal cases, completing stories, and identifying gaps in data.", "paperid": 2775135692, "normalizedname_level1": "artificial intelligence"}
{"index": 25, "text": "This paper presents an approach to analysis of multiclass EEG data obtained from the brain computer interface (BCI) applications. The proposed approach comprises two stages including feature extraction using the common spatial pattern (CSP) and classification using fuzzy logic systems (FLS). CSP is used to extract significant features that are then fed into FLS as inputs for classification. The metaheuristic population-based particle swarm optimization method is used to train parameters of the FLS. The multiclass motor imagery dataset IIa from the BCI competition IV is used for experiments to highlight the superiority of the proposed approach against competing methods, which include linear discriminant analysis, naive bayes, k-nearest neighbour, ensemble learning AdaBoost and support vector machine. Results from experiments show the great accuracy of the combination of CSP and FLS. Therefore, the proposed approach can be implemented effectively in the practical BCI systems, which would be helpful for people with impairments and rehabilitation.", "paperid": 2748909806, "normalizedname_level1": "artificial intelligence"}
{"index": 26, "text": "This study proposes a novel dimensionality reduction (DR) method for multi-view datasets. The principal component analysis (PCA) idea of minimising least squares reconstruction errors is extended to consider both data distribution and penalty weights called dictionary to recover outliers free global structures from missing and noisy data points. In this way, PCA is viewed as a special instance of the authors' proposed dictionary induced least squares framework (DLS). Furthermore, to appropriately handle multi-view DR, we combine the DLS with multiple manifold embeddings (DLSME). Therefore it can obtain lower projections while maintaining a balance between preserving global structures with DLS and local structures with multi-manifold embeddings. Extensive experiments on object and face recognition datasets verify that the DLS achieves better classification results with lower dimensional projections than PCA. Also, on many multi-view datasets of visual recognition and web image annotation, the DLSME method demonstrates more effectiveness than Graph-Laplacian PCA (gLPCA), robust PCA-optimal mean, canonical correlation analysis (CCA), bilinear models (BLM), neighbourhood preserving embedding, locality preserving projections, and locality sensitive discriminant analysis.", "paperid": 2890280334, "normalizedname_level1": "artificial intelligence"}
{"index": 27, "text": "Several end-to-end deep learning approaches have been recently presented which extract either audio or visual features from the input images or audio signals and perform speech recognition. However, research on end-to-end audiovisual models is very limited. In this work, we present an end-to-end audiovisual model based on residual networks and Bidirectional Gated Recurrent Units (BGRUs). To the best of our knowledge, this is the first audiovisual fusion model which simultaneously learns to extract features directly from the image pixels and audio waveforms and performs within-context word recognition on a large publicly available dataset (LRW). The model consists of two streams, one for each modality, which extract features directly from mouth regions and raw waveforms. The temporal dynamics in each stream/modality are modeled by a 2-layer BGRU and the fusion of multiple streams/modalities takes place via another 2-layer BGRU. A slight improvement in the classification rate over an end-to-end audio-only and MFCC-based model is reported in clean audio conditions and low levels of noise. In presence of high levels of noise, the end-to-end audiovisual model significantly outperforms both audio-only models.", "paperid": 2963654155, "normalizedname_level1": "artificial intelligence"}
{"index": 28, "text": "With the prevalence of location-based social networks (LBSNs), automated semantic annotation for places plays a critical role in many LBSN-related applications. Although a line of research continues to enhance labeling accuracy, there is still a lot of room for improvement. The crucial problem is to find a high-quality representation for each place. In previous works, the representation is usually derived directly from observed patterns of places or indirectly from calculated proximity amongst places or their combination. In this paper, we also exploit the combination to represent places but present a novel semi-supervised learning framework based on graph embedding, called Predictive Place Embedding (PPE). For place proximity, PPE first learns user embeddings from a user-tag bipartite graph by minimizing supervised loss in order to preserve the similarity of users visiting analogous places. User similarity is then transformed into place proximity by optimizing each place embedding as the centroid of the vectors of its check-in users. Our underlying idea is that a place can be considered as a representative of all its visitors. For observed patterns, a place-temporal bipartite graph is used to further adjust place embeddings by reducing unsupervised loss. Extensive experiments on real large LBSNs show that PPE outperforms state-of-the-art methods significantly.", "paperid": 2767584206, "normalizedname_level1": "artificial intelligence"}
{"index": 29, "text": "Hyperspectral endmembers are the spectra of pure materials that are responsible for generating the mixed pixels in hyperspectral images (HSIs). Hyperspectral endmember extraction (HEE) is essentially an inverse problem, where the unknown endmembers are inferred from the spectral measurements. Efficient extraction of endmembers in HSI relies on a well-defined generative model that captures key factors in HSI generation process, such as the clustering effect in the spatial domain and the noise heterogeneity effect in the spectral domain. This paper presents a weighted fuzzy purified-means (WFP-means) clustering model for HEE, where the endmembers are modeled as mean vectors of individual classes, and the fractional contributions of individual endmembers, called abundances, are treated as soft class membership. Accordingly, an endmember is estimated as the weighted mean of purified pixels in HSI, while the abundances are estimated as the nonnegative regression coefficients. In contrast to a mixed pixel that consists of multiple endmembers, a “purified pixel” is due to a single endmember. The introduction of the concept of “purified pixels” into the fuzzy clustering model leads to an elegant optimization scheme. Moreover, the proposed model accounts for the noise variance heterogeneity issue, which is essential for achieving unbiased abundance estimation. The proposed method is tested on both simulated and real HSI, in comparison with several other HEE methods. The results demonstrate that the proposed method compares favorably with respect to the referenced methods in terms of both endmember and abundance estimation.", "paperid": 2323362148, "normalizedname_level1": "artificial intelligence"}
{"index": 30, "text": "Getting a team of robots to achieve a relatively complex task using manual manipulation through augmented reality (AR) is interesting. However, the true potential of such an approach manifests when the system can learn from humans. We propose a system comprising a team of robots that performs a previously unseen task—a variant, to be specific—by learning from the sequences of actions taken by multiple human beings doing this task in various ways using deep learning (DL). The training inputs can be through actual manipulation of the team of robots using an augmented-reality tablet or through a simulator. Results indicate that the system is able to fulfill the specified variant of the task more than 80% of the time, inaccuracies mainly owing to unrealistic specifications of tasks. This opens up an avenue of training a team of robots, instead of crafting a rule base.", "paperid": 3033789294, "normalizedname_level1": "artificial intelligence"}
{"index": 31, "text": "recently, researchers have devoted prominent machine learning-based anti-phishing models to survive a supreme cyber-security versus phishing evolution on the cyberspace. Yet, such models remain incompetent to detect new phish in a real-time application. In this concern, this paper advocates an empirical analysis with the recently published works via a chronological validation. Chronological validation achieved by testing the works on three benchmarking data sets to appraise the causality between their detection outcomes and their limitations. Throughout chronological validation, the tested works have fallen short at detecting new phish web pages with an accessible detection accuracy. High to moderate faults and misclassifications are resulted as implications for their limitations and fixed real-time settings. Accordingly, this paper infers that by elevating the tested models in terms of using new and hybrid features, robust subset of features, and actively learned classifiers; an adaptive anti-phishing model with adjustable settings will be resilient against the up-to-date and scalable web flows. With such inferences, this paper highlights what future trends to develop along with depicting a taxonomy of current status and open problems as a guide to the researchers for their future achievements.", "paperid": 2947481133, "normalizedname_level1": "artificial intelligence"}
{"index": 32, "text": "In this paper, we propose a Palm print biometric recognition system based on scattering wavelet transform. First a novel approach for extracting Region of Interest (ROI) from palm image is presented. Then, a Scattering Wavelet Transform (SWT) is used to extract discriminative features from the input images that are useful to enhance correct matching. Then, a simple Euclidean distance based matching metric is used to compare with the template database of SWT features. Simulation results show that excellent biometric recognition performance by features extracted from SWT and the performance does not degrade even if the input biometric images are subjected to various degrees of rotation and translation.", "paperid": 2520695126, "normalizedname_level1": "artificial intelligence"}
{"index": 33, "text": "Achieving accurate stock market forecast impacts strongly to investors, like retirement funds and private investors, giving them tools for making better data based decisions. This article studies the applicability of two soft computing methods, Artificial Neural Networks and Support Vector Machines, to forecast Colombian stock market. Technical indicators were selected as inputs of the machine learning techniques, and up/down movement was selected as output. Cross-validation was employed to improve generalization, and automatic parameter tuning was performed to improve model performance. The results showed that Support Vector Machines performance was better than Artificial Neural Networks, and the results are similar to those found in other studies.", "paperid": 2787177992, "normalizedname_level1": "artificial intelligence"}
{"index": 34, "text": "In low light condition, color (RGB) images captured by imaging systems suffer from severe noise causing loss of colors and textures. Near infrared (NIR) images, which tend to ignore interference from external lights, have advantage of capturing invisible information that can not be obtained by regular RGB cameras. In this paper, we propose multispectral fusion of RGB and NIR images using two stage convolutional neural networks (CNNs), called FusionNet. Lack of training data is a huge obstacle to the learning-based fusion. We synthesize noisy RGB images for training by adding multiscale Gaussian noise. We adopt two stage CNNs for RGB-NIR fusion that consists of denoising and fusion. First, we use a compact denoising subnetwork to remove severe noise from the input RGB image. Then, we utilize a fusion subnetwork to recover textures of the denoised RGB image with the help of its corresponding NIR image. We provide a perceptually motivated loss function to ensure color/texture consistency between the input RGB image and the output fusion result. Experimental results show that the proposed method produces natural looking fusion results by successfully recovering colors and textures. Moreover, the proposed method outperforms state-of-the-art fusion methods in terms of visual quality and quantitative measurements.", "paperid": 3002696208, "normalizedname_level1": "artificial intelligence"}
{"index": 35, "text": "In this paper, two different schemes are proposed to add noise in the image. Gaussian Filter or Average Filter has been proposed for blurring the image. Impulse noise is used in two terms namely, salt and pepper (SNP) and random noise (RN). Apply median filter for removing white noise. Switching median filter (SMF) for removing black noise. Using the alternating direction method of multipliers (ADMM) with a Lucy richardson algorithm for restoring original image. Noise robustness of the proposed scheme is tested with different noise strengths. The visual as well as the peak signal to noise ratio(PSNR in dB) of restored pictures are compared with competent recent schemes.", "paperid": 2765346614, "normalizedname_level1": "artificial intelligence"}
{"index": 36, "text": "The location’s determination of an airplane by survey-comparative methods navigation means the identification of landmarks and their correspondence to the standard image with known coordinates. The geometric characteristics of ground landmarks are determined most accurate by the simulation of their features when processing 3D images of LIDAR.", "paperid": 2904000075, "normalizedname_level1": "artificial intelligence"}
{"index": 37, "text": "Glaucoma is an optic neuropathy and it principal cause of blindness in the world. In this paper, a system able to treat and analyze the Visual Field (VF) images and Optical Coherence Tomography of the Ganglion Cell Layer (OCT-GCL) images is proposed, in order to help early detection of glaucoma in its early stages. The proposed approach is based on calculating the percentage of healthy, sick and dead regions of VF and OCT-GCL images. In order to carry out this calculation, we combined the thresholding methods with morphological operators and median filter to extract all regions. These algorithms developed were tested on a set of images of a local database composed of 58 OCT-GCL images and 21 VF images. The results obtained are satisfactory and confirmed by experts in ophthalmology.", "paperid": 2906850376, "normalizedname_level1": "artificial intelligence"}
{"index": 38, "text": "Representing procedure text such as recipe for crossmodal retrieval is inherently a difficult problem, not mentioning to generate image from recipe for visualization. This paper studies a new version of GAN, named Recipe Retrieval Generative Adversarial Network (R2GAN), to explore the feasibility of generating image from procedure text for retrieval problem. The motivation of using GAN is twofold: learning compatible cross-modal features in an adversarial way, and explanation of search results by showing the images generated from recipes. The novelty of R2GAN comes from architecture design, specifically a GAN with one generator and dual discriminators is used, which makes the generation of image from recipe a feasible idea. Furthermore, empowered by the generated images, a two-level ranking loss in both embedding and image spaces are considered. These add-ons not only result in excellent retrieval performance, but also generate close-to-realistic food images useful for explaining ranking of recipes. On recipe1M dataset, R2GAN demonstrates high scalability to data size, outperforms all the existing approaches, and generates images intuitive for human to interpret the search results.", "paperid": 2948037078, "normalizedname_level1": "artificial intelligence"}
{"index": 39, "text": "Research is devoted to synthesis of positioning systems of electromechanical modules with set time, frequency and robust features. Structures and analytical expressions for parameters of static and astatic regulators and input filters are received. Bessel root distribution is tested in position regulators: static, astatic 1st and 2nd order. Parameters of time response, expressions for calculation of established positioning error are calculated at a constant, linearly and parabolically changing mechanical load. The analysis of time and frequency characteristics is made. The fixed adjustment providing robustness of positioning system at a variation of module inertance is defined. Application recommendations of the synthesized systems in machine-tool construction and robotics are developed.", "paperid": 2558134069, "normalizedname_level1": "artificial intelligence"}
{"index": 40, "text": "This chapter contains sections titled: Artificial Intelligence, Industrial Robots, How Do They Do It? What Challenges Are Being Met?, Why So Many Robots All of a Sudden?", "paperid": 2999053125, "normalizedname_level1": "artificial intelligence"}
{"index": 41, "text": "The heart sound classification aims to explore a reasonable method to distinguish normal heart sounds from abnormal heart sounds. In the traditional heart sound classification, their performance is limited because of the baseline feature of heart sound. This paper investigate the factors that affect the performance of classification tasks and extend the corresponding features. In this work, several basic features and extened features of the heart sound are evaluated based on support vector machine (SVM). In the initial stage, a phonocardiogram(PCG) signal is divided into several segments and 64 features in total should be extracted from time domain and frequency domain, these features are divided into 8 groups according to different property. Feature extension is made for the corresponding results, the frequency domain characteristics of diastole and systole are extended as new features, all these new features are added to the original features and compared in different classification method. Finally, an ensemble learning method is proposed, results for the normal and abnormal heart sound signal, the sensitivity, specificity and over all score are 95.9%, 91.7% and 93.8% respectively.", "paperid": 3007344422, "normalizedname_level1": "artificial intelligence"}
{"index": 42, "text": "User behavior modeling is essential in computational advertisement, which builds users' profiles by tracking their online behaviors and then delivers the relevant ads according to each user's interests and needs. Accurate models will lead to higher targeting accuracy and thus improved advertising performance. Intuitively, similar users tend to have similar behaviors towards the displayed ads (e.g., impression, click, conversion). However, to the best of our knowledge, there is not much previous work that explicitly investigates such similarities of various types of user behaviors, and incorporates them into ad response targeting and prediction, largely due to the prohibitive scale of the problem.   To bridge this gap, in this paper, we use bipartite graphs to represent historical user behaviors, which consist of both user nodes and advertiser campaign nodes, as well as edges reflecting various types of user-campaign interactions in the past. Based on this representation, we study random-walk-based local algorithms for user behavior modeling and action prediction, whose computational complexity depends only on the size of the output cluster, rather than the entire graph. Our goal is to improve action prediction by leveraging historical user-user, campaign-campaign, and user-campaign interactions. In particular, we propose the bipartite graphs AdvUserGraph accompanied with the ADNI algorithm. ADNI extends the NIBBLE algorithm to AdvUserGraph, and it is able to find the local cluster consisting of interested users towards a specific advertiser campaign. We also propose two extensions of ADNI with improved efficiencies. The performance of the proposed algorithms is demonstrated on both synthetic data and a world leading Demand Side Platform (DSP), showing that they are able to discriminate extremely rare events in terms of their action propensity.", "paperid": 2742322672, "normalizedname_level1": "artificial intelligence"}
{"index": 43, "text": "With the advent of information and communication technologies, there have been breakthrough developments in the field of Artificial Intelligence (AI). Moreover, increasing computation power and decreasing processing times, new applications are being developed at great speeds. One such application is Deepfakes, which tackles the increased manipulated and forged media content. But these fake images and videos hamper the security and privacy of individuals and can have large-scale religious, communal, or political implications that may prove to be catastrophic for a nation. The face swapped content at times can be identified by human observation, but with the use of Generative adversarial networks (GANs), such forged content can be developed with is hard to be identified even by humans. Hence, detecting such videos and images is a challenging task for researchers. Motivated from these gaps, in this paper, we propose a pipeline for detecting and extracting human faces from videos, process them to extract features from them, and then classify them as real or fake. The results of the proposed model achieved an accuracy of 90.2% for classifying fake images from real ones.", "paperid": 3102016200, "normalizedname_level1": "artificial intelligence"}
{"index": 44, "text": "When human enter the post-genomic era, prediction of protein structure has become the main object of study in bioinformatics. While predicting protein tertiary structural classes has become a new hot research topic in it. In this paper, a noval feature extraction method based on the predicted secondary structure sequence and the corresponding E-H sequence is employed. Two hierarchical classification models are designed and the model which achieves better prediction accuracy is chosen. On the basis of the new hierarchical classification model, ensemble learning is employed to predict protein tertiary structure. To test this method proposed by us, using three datasets with low homology including 640 dataset, 25pdb dataset and 1189 dataset is better option as the examine dataset of prediction of protein tertiary structural classes. The 10-fold cross validation test is employed to examine this method and compare with other existing methods. The overall accuracies of our method are 5.57%, 4.53% and 2.16% higher on the three different datasets, respectively.", "paperid": 2528280566, "normalizedname_level1": "artificial intelligence"}
{"index": 45, "text": "This paper presents a biometric authentication model using the palmprint, in which the data processing is done using textural statistical features and co-occurrence matrices. Several features sets are extracted and then combined with a functional fusion rule, avoiding the commonly used concatenation feature-level fusion. The target application has several security levels in order to accurately identify the most authorized person. The designed system operates in identification mode because the goal is to guess the true identity of a person using the biometric credential without the user-name.", "paperid": 3020122385, "normalizedname_level1": "artificial intelligence"}
{"index": 46, "text": "A new propagation prediction algorithm based on DTED (Digital Terrain Elevation Data) digital map is presented for the prediction of Radar propagation through large scale irregular complex terrain. The computational accuracy has been greatly improved compared with conventional radio propagation models. The calculated results are compared with Longley-Rice model and Lee model.", "paperid": 2462244656, "normalizedname_level1": "artificial intelligence"}
{"index": 47, "text": "The purpose of this paper is to realize the real time correction of geometric distortion of the non-follow-up dome-screen used in the motion simulator. To achieve this goal, the change of the trainer's observation area and the observing position that deviate from eye point are analyzed first, when the relative movement of the dome-screen and platform occurs. Then, based on the analysis above, we use the asymmetric view frustum method to make the image zone always in the center of occupant's view. The geometric distortion caused by the deviation the relative movement between the screen and platform is discussed later. Finally, combined with the motion of the visual system, an adaptive visual adjustment method is proposed to reduce the geometric distortion as well as realize the real time correction. The simulation is built on the Matlab. Results indicate that the geometric distortion is reduced about 70% after correction, the distortion error precision is within 0.2° in the zone about 10° around the line of sight. Also the error of the view edge is decreased partly. It is concluded that the method can realize real-time distortion correction only a few transforms and have an excellent effect for non-follow-up dome screen when the relative movement of platform occurs, which satisfies the requirements of the motion simulator.", "paperid": 2580774751, "normalizedname_level1": "artificial intelligence"}
{"index": 48, "text": "In this paper, we propose an automatic brain tumor segmentation approach (e.g., PixelNet) using pixel level convolutional neural network (CNN). The model extracts feature from multiple convolutional layers and concatenates them to form a hyper-column where samples a modest number of pixels for optimization. Hyper-column ensures both local and global contextual information for pixel wise predictor. The model confirms the statistical efficiency by sampling few number of pixels in training phase where spatial redundancy limits the information learning among the neighboring pixels in conventional pixel-level semantic segmentation approaches. Besides, label skewness in training data leads the convolutional model often converge to the certain classes which is a common problem in the medical dataset. We deal this problem by selecting an equal number of pixels for all the classes in sampling time. The proposed model has achieved promising results in brain tumor and ischemic stroke lesion segmentation datasets.", "paperid": 2799551303, "normalizedname_level1": "artificial intelligence"}
{"index": 49, "text": "We report about the application of state-of-the-art deep learning techniques to the automatic and interpretable assignment of ICD-O3 topography and morphology codes to free-text cancer reports. We present results on a large dataset (more than 80 000 labeled and 1 500 000 unlabeled anonymized reports written in Italian and collected from hospitals in Tuscany over more than a decade) and with a large number of classes (134 morphological classes and 61 topographical classes). We compare alternative architectures in terms of prediction accuracy and interpretability and show that our best model achieves a multiclass accuracy of 90.3% on topography site assignment and 84.8% on morphology type assignment. We found that in this context hierarchical models are not better than flat models and that an element-wise maximum aggregator is slightly better than attentive models on site classification. Moreover, the maximum aggregator offers a way to interpret the classification process.", "paperid": 3039996909, "normalizedname_level1": "artificial intelligence"}
{"index": 50, "text": "Software is highly contextual. While there are cross-cutting `global' lessons, individual software projects exhibit many `local' properties. This data heterogeneity makes drawing local conclusions from global data dangerous. A key research challenge is to construct locally accurate prediction models that are informed by global characteristics and data volumes. Previous work has tackled this problem using clustering and transfer learning approaches, which identify locally similar characteristics. This paper applies a simpler approach known as Bayesian hierarchical modeling. We show that hierarchical modeling supports cross-project comparisons, while preserving local context. To demonstrate the approach, we conduct a conceptual replication of an existing study on setting software metrics thresholds. Our emerging results show our hierarchical model reduces model prediction error compared to a global approach by up to 50%.", "paperid": 2795523340, "normalizedname_level1": "artificial intelligence"}
{"index": 51, "text": "Researchers assess visualizations from multiple aspects, such as aesthetics, memorability, engagement, and efficiency. However, these assessments are mostly carried out through user studies. There is a lack of automatic visualization assessment approaches, which hinders further applications like visualization recommendation, indexing, and generation. In this paper, we propose automating the visualization assessment process with modern machine learning approaches. We utilize a semi-supervised learning method, which first employs Variational Autoencoder (VAE) to learn effective features from visualizations, subsequently training machine learning models for different assessment tasks. Then, we can automatically assess new visualization images by predicting their scores or rankings with the trained model. To evaluate our method, we run two different assessment tasks, namely, aesthetics and memorability, on different visualization datasets. Experiments show that our method can learn effective visual features and achieves good performance on these assessment tasks.", "paperid": 2968970819, "normalizedname_level1": "artificial intelligence"}
{"index": 52, "text": "The problem of multiple group object tracking is a challenging one and has been extensively researched during the last two decades. The problem solution, proposed in this article, is an extension of the well known multi-Bernoulli filter. The model is first formulated generally, then the linear Gaussian-Wishart implementation is proposed. Contrary to many known methods, which track either individual targets or groups, the proposed filter tracks individual objects and combines them into group tracks. The experiments on simulated data have shown a sustainable ability of the method to track group objects.", "paperid": 2735798495, "normalizedname_level1": "artificial intelligence"}
{"index": 53, "text": "Goal : Interictal high-frequency oscillations (HFOs [30–600 Hz]) have proven to be relevant biomarkers in epilepsy. In this paper, four categories of HFOs are considered: Gamma ([30–80 Hz]), high-gamma ([80–120 Hz]), ripples ([120–250 Hz]), and fast-ripples ([250–600 Hz]). A universal detector of the four types of HFOs is proposed. It has the advantages of 1) classifying HFOs, and thus, being robust to inter and intrasubject variability; 2) rejecting artefacts, thus being specific.  Methods  : Gabor atoms are tuned to cover the physiological bands. Gabor transform is then used to detect HFOs in intracerebral electroencephalography (iEEG) signals recorded in patients candidate to epilepsy surgery. To extract relevant features, energy ratios, along with event duration, are investigated. Discriminant ratios are optimized so as to maximize among the four types of HFOs and artefacts. A multiclass support vector machine (SVM) is used to classify detected events. Pseudoreal signals are simulated to measure the performance of the method when the ground truth is known.  Results : Experiments are conducted on simulated and on human iEEG signals. The proposed method shows high performance in terms of sensitivity and false discovery rate.  Conclusion : The methods have the advantages of detecting and discriminating all types of HFOs as well as avoiding false detections caused by artefacts.  Significance : Experimental results show the feasibility of a robust and universal detector.", "paperid": 2558260604, "normalizedname_level1": "artificial intelligence"}
{"index": 54, "text": "Enabling a robot to grasp unknown objects is still an ongoing challenge in robotics. The main problem is to find an appropriate grasp configuration including the position and orientation of the arm relative to the object and fingers configuration. One approach is to recognize an appropriate grasp pose for an object based on one or more grasp demonstrations of the same or other objects. We focus on familiar objects, i.e. unknown objects sharing some features with known objects. The underlying assumption in grasping familiar objects is that, where they are similar to known ones, they may be grasped in a similar way. However finding an object representation and a similarity metric are still the main challenge to transfer grasp experiences to new objects. In this paper, we present an interactive object view recognition approach and a similarity metric to grasp familiar objects. Object view recognition is incrementally capable of recognizing object view labels. The grasp pose learning approach learns a grasp template for a recognized object view using local and global visual features of a demonstrated grasp. In grasp pose recognition, a similarity measure based on Mahalanobis distance is used for grasp template matching. The experimental results reveal the high reliability of the developed template matching approach. We also demonstrate how the proposed grasp learning system can incrementally improve its performance in grasping familiar objects.", "paperid": 2562087194, "normalizedname_level1": "artificial intelligence"}
{"index": 55, "text": "In this paper, we describe a wearable first-person video (FPV) analysis system for evaluating the skill levels of tender dementia-care technique. Using this system, caregivers can evaluate and elevate their care levels by themselves using the systems' feedbacks. From the FPVs of care sessions taken by wearable cameras worn by caregivers, we obtained the 3D facial distance, pose and eye-contact states between caregivers and receivers by using facial landmark detection and deep neural network (DNN)-based eye contact detection. We applied statistical analysis to these features and developed algorithms that provide scores for tender-care skill. To find and confirm our idea, we conducted chronological study to observe the progression of tender care-skill learning using care learners. First, we took FPVs while care training scenes involving novice caregivers, tender-care experts and middle-level students, and found major behavioural differences among them. Second, we performed the same experiments for the participants before and after training sessions of the care. As the result, we found the same behavioural difference between 1) novices and experts and 2) novices before and after taking training sessions. These results indicate that our FPV-based behavior analysis can evaluate the skill progression of the tender dementia-care.", "paperid": 3010422801, "normalizedname_level1": "artificial intelligence"}
{"index": 56, "text": "Superpixels are a powerful device to characterize the spatial–contextual information in remotely sensed hyperspectral image (HSI) interpretation. However, the exploitation of superpixels in classification problems is not straightforward, often leading to unbearable NP-hard discrete integer optimization problems. In this paper, we attack this hurdle by leveraging on a convex relaxation of the original integer optimization problem, which opens the door to include oversegmented superpixel-based regularizers. Specifically, we develop a new method for generating oversegmented superpixels. Then, we introduce a family of convex regularizers in the form of graph total variation, which promotes the same labeling in each superpixel. Vectorial total variation is also included in order to promote piecewise smoothness and align discontinuities along the class boundaries. The solution of the obtained convex optimization problem is computed with the split-augmented Lagrangian shrinkage algorithm. Experiments on HSIs yield classification maps with precise boundaries and inner consistency inside oversegmented superpixels, leading to the state-of-the-art classification accuracies.", "paperid": 2782281103, "normalizedname_level1": "artificial intelligence"}
{"index": 57, "text": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "paperid": 3091850269, "normalizedname_level1": "artificial intelligence"}
{"index": 58, "text": "Source azimuth can be estimated via the complex sound intensity method based on a single vector hydrophone, which exploits the physical properties of acoustic pressure and particle velocity components. Deep learning has been successfully used to estimate source depth and distance via training and prediction; herein it is adapted to estimate the source azimuth by analyzing the sound fields provided by a single vector hydrophone. This study compares the estimation results of the two abovementioned approaches that applied to the data due to a moving ship circling around a moored vector hydrophone. Preliminary results demonstrate that these two approaches generally agree; however their accuracies are unsatisfactory because of a low signal-to-noise ratio and strong interference. To increase the estimation accuracy, herein, cross-spectral processing of input data is used for deep learning. The proposed deep-learning method with appropriate input data can effectively suppress interference and accurately estimate source azimuth.", "paperid": 3002907852, "normalizedname_level1": "artificial intelligence"}
{"index": 59, "text": "Collecting labeled samples is quite costly and time-consuming for hyperspectral image (HSI) classification task. Semisupervised learning framework, which combines the intrinsic information of labeled and unlabeled samples, can alleviate the deficient labeled samples and increase the accuracy of HSI classification. In this letter, we propose a novel semisupervised learning framework that is based on spectral–spatial graph convolutional networks (   $\\text{S}^{2}$   GCNs). It explicitly utilizes the adjacency nodes in graph to approximate the convolution. In the process of approximate convolution on graph, the proposed method makes full use of the spatial information of the current pixel. The experimental results on three real-life HSI data sets, i.e., Botswana Hyperion, Kennedy Space Center, and Indian Pines, show that the proposed    $\\text{S}^{2}$   GCN can significantly improve the classification accuracy. For instance, the overall accuracy on Indian data is increased from 66.8% (GCN) to 91.6%.", "paperid": 2892621946, "normalizedname_level1": "artificial intelligence"}
{"index": 60, "text": "Internet + platforms lead the application of big data and artificial intelligence to ordinary users, with reduced costs of technology. Meanwhile, they have driven professional education to update courses and promote efficiency of talents cultivation. The curriculum system of vocational education needs to consider the application of new technologies comprehensively to ensure the availability of knowledge and ability structure of personnel training. To achieve the goal, the application methods and approaches of teaching and practice with big data and artificial intelligence in vocational education are explored and researched; practice of innovative application in software technology are illustrated. It is expected to help promote the reform and development of vocational education and speedup cultivation of innovative and entrepreneurial talents.", "paperid": 2999502793, "normalizedname_level1": "artificial intelligence"}
{"index": 61, "text": "Accurate channel state information (CSI) feedback plays a vital role in improving the performance gain of massive multiple-input multiple-output (m-MIMO) systems, where the dilemma is excessive CSI overhead versus limited feedback bandwith. By considering the noisy CSI due to imperfect channel estimation, we propose a novel deep neural network architecture, namely AnciNet, to conduct the CSI feedback with limited bandwidth. AnciNet extracts noise-free features from the noisy CSI samples to achieve effective CSI compression for the feedback. Experimental results verify that the proposed AnciNet approach outperforms the existing techniques under various conditions.", "paperid": 3075999494, "normalizedname_level1": "artificial intelligence"}
{"index": 62, "text": "The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by industry practitioners and solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address industry practitioners' needs.", "paperid": 2904233591, "normalizedname_level1": "artificial intelligence"}
{"index": 63, "text": "Surface electromyography(sEMG) is a reliable physiological electrical signal, which represents real-time human motion intents. And the EMG-based motion recognition has the characteristics of convenient operation, non-invasion and noninterference, which has broad application prospects. This paper focuses on composite motion(including multiple actions) recognition, such as sign language motions and handwritten motions. We proposed a novel method for composite motion recognition by using deep learning. To begin with, we defined a novel data structure called sEMG image and established convolution Neural Network designed for sEMG images. In order to reduce the demand of training data, we proposed to pre-train the network by MNIST data set based on the thought of transfer learning. To verify the methods that we proposed, we acquired and preprocessed the surface EMG signals of composite motions, including handwritten number motions and sign language motions. From the results, it can be concluded that deep learning methods perform better than traditional methods, including support vector machine(SVM) and Dynamic Time Warping(DTW). Especially in different sizes handwritten number recognition experiments, the deep learning methods is still very excellent, while accuracies of traditional methods are greatly reduced. In addition, we discovered that transfer learning can help ConvNet to quickly converge and reduce the demand for data.", "paperid": 2973561488, "normalizedname_level1": "artificial intelligence"}
{"index": 64, "text": "Understanding driver activity is vital for in-vehicle systems that aim to reduce the incidence of car accidents rooted in cognitive distraction. Automating  real-time  behavior recognition while ensuring actions classification with  high accuracy  is however challenging, given the multitude of circumstances surrounding drivers, the unique traits of individuals, and the computational constraints imposed by in-vehicle embedded platforms. Prior work fails to jointly meet these runtime/accuracy requirements and mostly rely on a single sensing modality, which in turn can be a single point of failure. In this paper, we harness the exceptional feature extraction abilities of deep learning and propose a dedicated Interwoven Deep Convolutional Neural Network (InterCNN) architecture to tackle the problem of accurate classification of driver behaviors in real-time. The proposed solution exploits information from multi-stream inputs, i.e., in-vehicle cameras with different fields of view and optical flows computed based on recorded images, and merges through multiple fusion layers abstract features that it extracts. This builds a tight ensembling system, which significantly improves the robustness of the model. In addition, we introduce a temporal voting scheme based on historical inference instances, in order to enhance the classification accuracy. Experiments conducted with a dataset that we collect in a mock-up car environment demonstrate that the proposed InterCNN with MobileNet convolutional blocks can classify 9 different behaviors with 73.97% accuracy, and 5 ‘aggregated’ behaviors with 81.66% accuracy. We further show that our architecture is highly computationally efficient, as it performs inferences within 15 ms, which satisfies the real-time constraints of intelligent cars. Nevertheless, our InterCNN is robust to lossy input, as the classification remains accurate when two input streams are occluded.", "paperid": 2900883569, "normalizedname_level1": "artificial intelligence"}
{"index": 65, "text": "Opinion Mining aims to identify people feelings about some item of interest based on content available on the Web, without the user having to find and read all the news about it. As opinions are related to feelings that are often described by imprecise terms, Fuzzy Systems appear as an alternative to treat the information subjectivity. An important task in developing Fuzzy Systems is define the rule base usually based on textual databases in case of opinion mining. However, these databases are extensive and the algorithms used to generate the rule base often result in many rules, making it difficult to achieve accuracy with a low computational cost. To deal with this problem, instance selection can be applied to reduce databases in order to save only relevant data. Thus, the aim of the present study is optimize a Fuzzy System, using instance selection to generate a reduced rule base. As the issue mentioned is a multiobjective problem, which seeks to increase accuracy and reduce the number of rules, we have chosen to apply a Multiobjective Genetic Algorithm, since it has been acknowledged as a promising approach in the literature. The results demonstrate that the Multiobjective Genetic Algorithms can be applied in instance selection for opinion classification problems, presenting a reduction in the number of instances and execution time, without significant changes in accuracy.", "paperid": 3029242188, "normalizedname_level1": "artificial intelligence"}
{"index": 66, "text": "We consider the problem of aggregating pairwise comparisons to obtain a consensus ranking order over a collection of objects. We use the popular Bradley–Terry–Luce (BTL) model, which allows us to probabilistically describe pairwise comparisons between objects. In particular, we employ the Bayesian BTL model, which allows for meaningful prior assumptions and to cope with situations where the number of objects is large and the number of comparisons between some objects is small or even zero. For the conventional Bayesian BTL model, we derive information-theoretic lower bounds on the Bayes risk of estimators for norm-based distortion functions. We compare the information-theoretic lower bound with the Bayesian Cramer–Rao lower bound we derive for the case when the Bayes risk is the mean squared error. We illustrate the utility of the bounds through simulations by comparing them with the error performance of an expectation-maximization-based inference algorithm proposed for the Bayesian BTL model. We draw parallels between pairwise comparisons in the BTL model and interplayer games represented as edges in an Erdős–Renyi graph and analyze the effect of various graph structures on the lower bounds. We also extend the information-theoretic and Bayesian Cramer–Rao lower bounds to the more general Bayesian BTL model, which takes into account home-field advantage.", "paperid": 2758192787, "normalizedname_level1": "artificial intelligence"}
{"index": 67, "text": "In order to achieve a more accurate deep learning model, we need large amount of data. For imaging application, color data augmentation is usually required. Color jittering is a common current practice for such augmentation where color values in image are slightly adjusted. Unfortunately, color values between two cameras may be significantly different. This makes the current practice ineffective. This work proposes to map color values among cameras by using deep learning to learn color-mapping parameters. In this way, we can augment color data by converting an image from one camera to another image whose colors seemingly are taken from another camera. This allows a machine to learn a model that can deal with input images from multiple cameras without actually using training data from multiple cameras. These parameters can also be employed to calibrate colors in order that all cameras produce the same color tone. The proposed neural network architecture which employs fully connected layers and batch normalization outperforms an existing method and can be systematically performed for any camera pairs to extend its applications in other scenarios.", "paperid": 2890137306, "normalizedname_level1": "artificial intelligence"}
{"index": 68, "text": "The coupling between perception and action has seldom been explored in sophisticated motor behaviour such as 3D pointing. In this study, we investigated how 3D pointing accuracy, measured by a depth estimation task, could be affected by the target appearing in different visual eccentricities. Specifically, we manipulated the visual eccentricity of the target and its depth in virtual reality. Participants wore a head-mounted-display with an integrated eye-tracker and docked a cursor into a target. We adopted a within-participants factorial design with three variables. The first variable is Eccentricity: the location of the target on one of five horizontal eccentricities (left far periphery, left near periphery, foveal, right near periphery and right far periphery). The second variable is Depth at three levels and the third variable is Feedback Loop with two levels: open/closed. Eccentricity is refactored into Motion Correspondence between the starting location of the cursor and the target location with four levels: periphery to fovea, fovea to periphery, periphery to periphery, fovea to fovea. The results showed that the pointing accuracy is modulated mainly by the target locations rather than the initial locations of the effector (hand). Visible feedback during pointing improved performance.", "paperid": 2980603758, "normalizedname_level1": "artificial intelligence"}
{"index": 69, "text": "Wireless links are often prone to performance degradation due to signal diffraction, interference from other sources or even radars. To identify the various causes when they occur in an operational network, we have analysed the involved MAC protocols and data forwarding mechanisms, and studied an extensive amount of logging information to derive a set of monitoring data. We then investigate if and which machine learning algorithms can be applied to automate the processing of the monitoring data to accurately determine the cause of a link degradation in near real-time. We train and test neural networks, decision trees, support vector machines, and K-nearest neighbours. We also describe the process of data synchronisation, data set creation, and the numerical variable selection for the classification of link degradation causes. Our findings show that decision trees achieve the highest accuracy, while neural network and support vector machines also achieve high performance.", "paperid": 3092588598, "normalizedname_level1": "artificial intelligence"}
{"index": 70, "text": "As the development of data collection techniques, complicated objects are described with more than one aspects as well as possess multiple concepts, so as many data mining approaches face the issues of dual-heterogeneity, i.e., feature heterogeneity and task heterogeneity. Traditional multi-task learning methods and multi-view learning methods may be not optimal for such a complicated learning problem since they only capture one type of heterogeneity. Then some works concentrate on a new direction where there are multiple related tasks with multi-view data. However, most existing MTMV methods focus on proposing linear models for fitting the specific application requirements while they are not suitable for common large-scale real-world problems in real environments. In this paper, we propose a unified learning framework for a deep multi-task multi-view neural network. In our approach, there are three kinds of networks called shared feature network, specific feature network and task network, each of which focus on the feature heterogeneity, unified feature representations, and task heterogeneity, respectively. Meanwhile, we employ a layer-by-layer regularization strategy for learning the relationships between tasks in multi-task multi-view learning. Moreover, the DMTMV method is naturally convenient for multi-class heterogeneous tasks as well. Finally, experiments on four real-world datasets successfully show that the proposed framework can significantly improve the prediction performance in multi-task multi-view learning while it can also discover inherent relationships among different tasks.", "paperid": 2906841683, "normalizedname_level1": "artificial intelligence"}
{"index": 71, "text": "Benefitting from large-scale training datasets and the complex training network, Convolutional Neural Networks (CNNs) are widely applied in various fields with high accuracy. However, the training process of CNNs is very time-consuming, where large amounts of training samples and iterative operations are required to obtain high-quality weight parameters. In this paper, we focus on the time-consuming training process of large-scale CNNs and propose a Bi-layered Parallel Training (BPT-CNN) architecture in distributed computing environments. BPT-CNN consists of two main components: (a) an outer-layer parallel training for multiple CNN subnetworks on separate data subsets, and (b) an inner-layer parallel training for each subnetwork. In the outer-layer parallelism, we address critical issues of distributed and parallel computing, including data communication, synchronization, and workload balance. A heterogeneous-aware Incremental Data Partitioning and Allocation (IDPA) strategy is proposed, where large-scale training datasets are partitioned and allocated to the computing nodes in batches according to their computing power. To minimize the synchronization waiting during the global weight update process, an Asynchronous Global Weight Update (AGWU) strategy is proposed. In the inner-layer parallelism, we further accelerate the training process for each CNN subnetwork on each computer, where computation steps of convolutional layer and the local weight training are parallelized based on task-parallelism. We introduce task decomposition and scheduling strategies with the objectives of thread-level load balancing and minimum waiting time for critical paths. Extensive experimental results indicate that the proposed BPT-CNN effectively improves the training performance of CNNs while maintaining the accuracy.", "paperid": 3105668694, "normalizedname_level1": "artificial intelligence"}
{"index": 72, "text": "Abstract—In this paper, a translation model based on Convolutional Neural Network (CNN) architecture is introduced into the Mongolian-Chinese translation task. Mongolian language has rich morphology structure, so we use byte-pair encoding (BPE) to segment the Mongolian word. In addition, the Mongolian Correction approach is adopted to reduce coding errors occurred in Mongolian corpus. The statistics data show that BPE and Mongolian Correction are alleviate the data sparsity that results from very low-resource Mongolian-Chinese parallel corpus. On Mongolian-Chinese translation task, we achieve the best result 35.37 BLEU that exceeds the baseline system by 1.4 BLEU. In the experiments, effect of different translation granularity on the translation result is investigated. The experiment results show that sub-word unit is more suitable than word unit for Mongolian-Chinese translation.", "paperid": 2794857614, "normalizedname_level1": "artificial intelligence"}
{"index": 73, "text": "We tackle the problem of large scale visual place recognition, where the task is to quickly and accurately recognize the location of a given query photograph. We present the following three principal contributions. First, we develop a convolutional neural network (CNN) architecture that is trainable in an end-to-end manner directly for the place recognition task. The main component of this architecture, NetVLAD, is a new generalized VLAD layer, inspired by the \"Vector of Locally Aggregated Descriptors\" image representation commonly used in image retrieval. The layer is readily pluggable into any CNN architecture and amenable to training via backpropagation. Second, we develop a training procedure, based on a new weakly supervised ranking loss, to learn parameters of the architecture in an end-to-end manner from images depicting the same places over time downloaded from Google Street View Time Machine. Finally, we show that the proposed architecture significantly outperforms non-learnt image representations and off-the-shelf CNN descriptors on two challenging place recognition benchmarks, and improves over current state of-the-art compact image representations on standard image retrieval benchmarks.", "paperid": 2179042386, "normalizedname_level1": "artificial intelligence"}
{"index": 74, "text": "In this paper, we compare and analyze the prediction performance of existing ANFIS (Adaptive Neuro Fuzzy Inference System) models. The ANFIS model is a fusion of neural networks with learning ability, adaptability, and computational ability, and a fuzzy system with human-like thinking ability and reasoning ability. In this paper, we analyze the prediction performance of ANFIS models using different input space partitioning methods. ANFIS 1 uses SC (Subtractive Clustering), a clustering method based on the density of data, to calculate the center of the cluster by calculating potential values inversely proportional to the distances of the different inputs. ANFIS 2 uses Fuzzy C-Means (FCM) clustering, which is a clustering method based on degree of belonging to data, and classifies each data belonging to each cluster according to degree of affiliation. ANFIS 3 is a method of using Context based Fuzzy C-Means (CFCM) clustering, which is a clustering method considering characteristics of input and output space based on FCM clustering. It creates clusters for each context generated according to characteristics of output space, to classify the data. To evaluate these ANFIS models, we use short term electricity price forecasting data and Boston housing data. The prediction performance is based on the Root Mean Squared Error (RMSE) method. Experimental results show that the prediction performance of the ANFIS model is different depending on the characteristics of each data. Furthermore, we confirmed that the prediction performance of ANFIS model using CFCM clustering method is constant.", "paperid": 2909665320, "normalizedname_level1": "artificial intelligence"}
{"index": 75, "text": "Even though there exist significant advances in recent studies, existing methods for pedestrian detection still have shown limited performances under challenging illumination conditions especially at nighttime. To address this, cross-spectral pedestrian detection methods have been presented using color and thermal, and shown substantial performance gains on the challenging circumstances. However, their paired cross-spectral settings have limited applicability in real-world scenarios. To overcome this, we propose a novel learning framework for cross-spectral pedestrian detection in an unpaired setting. Based on an assumption that features from color and thermal images share their characteristics in a common feature space to benefit their complement information, we design the separate feature embedding networks for color and thermal images followed by sharing detection networks. To further improve the cross-spectral feature representation, we apply an adversarial learning scheme to intermediate features of the color and thermal images. Experiments demonstrate the outstanding performance of the proposed method on the KAIST multi-spectral benchmark in comparison to the state-of-the-art methods.", "paperid": 2971016330, "normalizedname_level1": "artificial intelligence"}
{"index": 76, "text": "Robust and accurate visual tracking is one of the most challenging computer vision problems. Due to the inherent lack of training data, a robust approach for constructing a target appearance model is crucial. Recently, discriminatively learned correlation filters (DCF) have been successfully applied to address this problem for tracking. These methods utilize a periodic assumption of the training samples to efficiently learn a classifier on all patches in the target neighborhood. However, the periodic assumption also introduces unwanted boundary effects, which severely degrade the quality of the tracking model. \r\nWe propose Spatially Regularized Discriminative Correlation Filters (SRDCF) for tracking. A spatial regularization component is introduced in the learning to penalize correlation filter coefficients depending on their spatial location. Our SRDCF formulation allows the correlation filters to be learned on a significantly larger set of negative training samples, without corrupting the positive samples. We further propose an optimization strategy, based on the iterative Gauss-Seidel method, for efficient online learning of our SRDCF. Experiments are performed on four benchmark datasets: OTB-2013, ALOV++, OTB-2015, and VOT2014. Our approach achieves state-of-the-art results on all four datasets. On OTB-2013 and OTB-2015, we obtain an absolute gain of 8.0% and 8.2% respectively, in mean overlap precision, compared to the best existing trackers.", "paperid": 3102624093, "normalizedname_level1": "artificial intelligence"}
{"index": 77, "text": "Until now there have been few formalized methods for conducting systematic benchmarking aiming at reproducible results when it comes to computer vision algorithms. This is evident from lists of algorithms submitted to prominent datasets, authors of a novel method in many cases primarily state the performance of their algorithms in relation to a shallow description of the hardware system where it was evaluated. There are significant problems linked to this non-systematic approach of reporting performance, especially when comparing different approaches and when it comes to the reproducibility of claimed results. Furthermore how to conduct retrospective performance analysis such as an algorithm’s suitability for embedded real-time systems over time with underlying hardware and software changes in place. This paper proposes and demonstrates a systematic way of addressing such challenges by adopting containerization of software aiming at formalization and reproducibility of benchmarks. Our results show maintainers of broadly accepted datasets in the computer vision community to strive for systematic comparison and reproducibility of submissions to increase the value and adoption of computer vision algorithms in the future.", "paperid": 3004202299, "normalizedname_level1": "artificial intelligence"}
{"index": 78, "text": "Robots are becoming popular in Computer Science outreach to K-12 students. Easy-to-program toy robots already exist as commercial educational products. These toys take advantage of the increased interest and engagement resulting from the ability to write code that makes a robot physically move. However, toy robots do not demonstrate the potential of robots to carry out useful everyday tasks. On the other hand, functional robots are often difficult to program even for professional software developers or roboticists. In this work, we apply end-user programming tools for functional robots to the Computer Science outreach context. This experience report describes two offerings of a week-long introductory workshop in which students with various disabilities learned to program a Clearpath Turtlebot, capable of delivering items, interacting with people via touchscreen, and autonomously navigating its environment. We found that the robot and the end-user programming tool that we developed in previous work were successful in provoking interest in Computer Science among both groups of students and in establishing confidence among students that programming is both accessible and interesting. We present key observations from the workshops, lessons learned, and suggestions for readers interested in employing a similar approach.", "paperid": 2605135109, "normalizedname_level1": "artificial intelligence"}
{"index": 79, "text": "We present here a moving target detection method so-called local detection of moving target by focusing. The term local implies that the method only works with areas of interest but not whole SAR scene whereas the term focusing indicates that the method is based on the concept of relative movement. The mathematical background of the method is presented in details. The introduced method is then examined with simulated and experimental SAR data to evaluate the method as well as to show the practicality of the method. The reference SAR system for this study is CARABAS, an airborne UWB low frequency SAR system. The method shows a number of advantages in comparison to the original version.", "paperid": 2420998294, "normalizedname_level1": "artificial intelligence"}
{"index": 80, "text": "This paper describes the pulling and steering of magnetic therapeutic microparticles for drug delivery based on a macro-micro manipulator system. The micromanipulation system is composed of a 6 Degree Of Freedom (6 DOF) serial manipulator while a linear permanent-based actuator (1 DOF) is equipped at the end-effector as a micropart to precisely steer and pull magnetic microparticles. Using the classical mathematical tools of robotics, we developed the global kinematic model of the robot-device assembly, thus defining a reference trajectory to propel the microparticle. A novel actuator-based permanent magnet has been designed and realized as a robot micro end-effector to control the trajectory of a microparticle along a millimeter-sized workspace. Simulation and experiments were conducted to show the ability of the macro-micro manipulator system to steer particles on a viscous fluid simulating a biological media.", "paperid": 2725630117, "normalizedname_level1": "artificial intelligence"}
{"index": 81, "text": "Cytological samples provide useful data for cancer diagnostics but their visual analysis under a microscope is tedious and time-consuming. Moreover, some scientific tests indicate that various pathologists can classify the same sample differently or the same pathologist can classify the sample differently if there is a long interval between subsequent examinations. We can help pathologists by providing tools for automatic analysis of cellular structures. Unfortunately, cytological samples usually consist of clumped structures, so it is difficult to extract single cells to measure their morphometric parameters. To deal with this problem, we are proposing a nuclei detection approach, which combines convolutional neural network and Bayesian inference. The input image is preprocessed by the stain separation procedure to extract a blue dye (hematoxylin) which is mainly absorbed by nuclei. Next, a convolutional neural network is trained to provide a semantic segmentation of the image. Finally, the segmentation results are post processed in order to detect nuclei. To do that, we model the nuclei distribution on a plane using marked point process and apply the Besag's iterated conditional modes to find the configuration of ellipses that fit the nuclei distribution. Thanks to this we can represent clusters of occluded cell nuclei as a set of an overlapping ellipses. The accuracy of the proposed method was tested on 50 cytological images of breast cancer. Reference data was generated by the manual labeling of cell nuclei in images. The effectiveness of the proposed method was compared with the marker-controlled watershed. We applied our method and marker controlled watershed to detect nuclei in the semantic segmentation maps generated by the convolutional neural network. The accuracy of nuclei detection is measured as the number of true positive (TP) detections and false positive (FP) detections. It was recorded that the method can detect correctly 93.5% of nuclei (TP) and at the same time it generates only 6.1% of FP. The proposed approach has led to better results than the marker-controlled watershed both in the number of correctly detected nuclei and in the number of false detections.", "paperid": 2979917888, "normalizedname_level1": "artificial intelligence"}
{"index": 82, "text": "Typically, cropped and aligned face images are required as the input of a face recognition model. In contrast, popular object detectors based on deep convolutional network usually locate and classify objects simultaneously, which eliminates redundant computation. This work presents a single-network model called Uniface network for simultaneous face detection, landmark localization and recognition. We develop a feature sharing infrastructure for seamlessly integrate both the detection/localization module and the recognition module. To facilitate large-scale end-to-end training, we propose a method by encouraging top-level features of our model to mimic those of a well-trained single-task face recognition model. Comprehensive experiments on face detection, landmark localization and verification tasks demonstrate that the proposed network achieves competing performance in both face recognition benchmark (99.0% on LFW for a single model) and face detection benchmark (86.4% against 2000 false positives on FDDB for a single model).", "paperid": 2903185397, "normalizedname_level1": "artificial intelligence"}
{"index": 83, "text": "The Nearest Neighbor Classification (NNC) has been widely used as classification method, due to its simplicity, classification efficiency and its ability to deal with different classification problems. Despite its good classification accuracy, the NNC suffers from many shortcomings on the execution time, noise sensitivity, high storage requirements and lack of interpretability. In this paper, we propose a new prototype learning algorithm for NNC method. This new algorithm derives a small subset of relevant prototypes from the training set by the means of clustering algorithms. The obtained prototypes enable the NNC method to deal with the aforementioned issues. Moreover, using clustering algorithm involve an interpretable set of prototypes that can describes the application domain. The proposal is experimented on various datasets and compared to other prototypes learning methods. The results show the effectiveness of our approach compared to the existed methods.", "paperid": 2757230299, "normalizedname_level1": "artificial intelligence"}
{"index": 84, "text": "Sampling-based planners are effective in many real-world applications such as robotics manipulation, navigation, and even protein modeling. However, it is often challenging to generate a collision-free path in environments where key areas are hard to sample. In the absence of any prior information, sampling-based planners are forced to explore uniformly or heuristically, which can lead to degraded performance. One way to improve performance is to use prior knowledge of environments to adapt the sampling strategy to the problem at hand. In this work, we decompose the workspace into local primitives, memorizing local experiences by these primitives in the form of local samplers, and store them in a database. We synthesize an efficient global sampler by retrieving local experiences relevant to the given situation. Our method transfers knowledge effectively between diverse environments that share local primitives and speeds up the performance dramatically. Our results show, in terms of solution time, an improvement of multiple orders of magnitude in two traditionally challenging high-dimensional problems compared to state-of-the-art approaches.", "paperid": 2922572893, "normalizedname_level1": "artificial intelligence"}
{"index": 85, "text": "This paper explores the through-the-wall inverse scattering problem via machine learning. The reconstruction method seeks to discover the shape, location, and type of hidden objects behind simulated walls. We use RF sources and receivers placed outside the room to generate observation data with objects randomly placed inside the room.", "paperid": 2981714225, "normalizedname_level1": "artificial intelligence"}
{"index": 86, "text": "This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.", "paperid": 2598104261, "normalizedname_level1": "artificial intelligence"}
{"index": 87, "text": "Integration of rich sensor technologies with everyday applications, such as gesture recognition and health monitoring, has raised the importance of the ability to effectively search and analyze multi-variate time series data. Consequently, various time series distance measures (such as Euclidean distance, edit distance, and dynamic time warping) have been extended from uni-variate to multi-variate time series. In this paper, we note that the naive extensions of these measures may not necessarily be effective when analyzing multi-variate time series data. We present several algorithms, some of which leverage external metadata describing the potential relationships, either learned from the data or captured from the metadata, among the variates. We then experimentally study the effectiveness of multi-variate time series distance measures against human motion data sets.", "paperid": 2617509057, "normalizedname_level1": "artificial intelligence"}
{"index": 88, "text": "Promoting and developing English language skills are essential for second language learners. This paper presents the design and development of a mobile application for promoting learners' experiences in learning the English vocabularies by formulating the compound words generated from images. The proposed system is based on the multi-agent system (MAS) covering three main agents: matching learners agent, combination vocabulary agent, and feedback agent. The innovation of the proposed approach is that many learners (matching learners agent) can formulate the new vocabulary that is formed from the combination algorithm (combination vocabulary agent) and learners can experience new vocabulary represented by using the image results (feedback agent). The two experiments of the system performance evaluation are reported. The experimental results show that the performance of the vocabularies' detection and the sub processes execution were achieved the high accuracy.", "paperid": 2979329197, "normalizedname_level1": "artificial intelligence"}
{"index": 89, "text": "In the Internet, ubiquitous presence of redundant, unedited, raw videos has made video summarization an important problem. Traditional methods of video summarization employ a heuristic set of hand-crafted features, which in many cases fail to capture subtle abstraction of a scene. This paper presents a deep learning method that maps the context of a video to the importance of a scene similar to that is perceived by humans. In particular, a convolutional neural network (CNN)-based architecture is proposed to mimic the frame-level shot importance for user-oriented video summarization. The weights and biases of the CNN are trained extensively through off-line processing, so that it can provide the importance of a frame of an unseen video almost instantaneously. Experiments on estimating the shot importance is carried out using the publicly available database TVSum50. It is shown that the performance of the proposed network is substantially better than that of commonly referred feature-based methods for estimating the shot importance in terms of mean absolute error, absolute error variance, and relative F-measure.", "paperid": 2962870687, "normalizedname_level1": "artificial intelligence"}
{"index": 90, "text": "Vibration wave motion acting on a structure travels throughout the whole structure at a given instance. Instead of using many Convolutional Neural Networks (CNNs) to test every part of the structure in different testing sessions, one CNN is adopted to detect damage for the whole structure in one testing session. The fundamental goal of using CNN in structural damage detection is to answer the question of to what extent (severity of damage) the structure under observation is damaged. The proposed approach successfully uses the vibration signal from two measurement sessions to train only one dedicated CNN in order to know when the structure is damaged. The two measurement sessions are done by taking vibration signal data from a four floor steel structure when it is undamaged and when the structure is fully damaged. The CNN then predicts the degree of structural damage in respect to a given scale during testing. This approach is convenient for large structures since it involves using only two measurement sessions for training and also fuses all the sensor data into one CNN. The experiment results prove that the CNN accurately predicts the severity of damage of the structure as well as supporting the real-time vibration signal processing and the use of few resources since the method requires only one CNN for feature extraction and classification.", "paperid": 2997219578, "normalizedname_level1": "artificial intelligence"}
{"index": 91, "text": "Deep Affinity Network (DAN) is a novel approach in multi-object tracking (MOT) designed to jointly modeling object appearances and affinities end to end. But tracking accuracy of DAN tracker is greatly limited since it neglects unreliable detection. Exploiting predictions of tracks has emerged as a popular approach to tackle the task of tracking-by-detection. However, it's observed that missing detection has not been solved well enough which would significantly influence tracking accuracy. Thus, obtaining more reliable tracking candidates is concerned to further address the problem of missing detection. In this paper, we propose Candidate Selection-based Deep Affinity Network (CSDAN) tracker for MOT. It collects candidates from detection, predictions of tracks and backward tracking simultaneously so that they can complement each other in different scenarios. Moreover, we propose a deep learned candidate selection model (DCSM) with a unified scoring function suitable for CSDAN, which can well handle candidates from three sources separately and select those for data association. Experiments conducted on MOT17 benchmark demonstrate that our extensions can significantly address the unreliable detection problem in DAN tracker, and our CSDAN tracker demonstrates competitive tracking performance.", "paperid": 3081808492, "normalizedname_level1": "artificial intelligence"}
{"index": 92, "text": "Human visual perception in terms of spectral properties of light is influenced by three basic components, which are the light source and its spectral distribution of the radiant power, observed object and its spectral properties of surfaces and human eye and its spectral sensitivity. The resultant visual perception is influenced by the interaction of these three components. In the case of street lighting, where the spectral sensitivity of the human eye is changing and where the light sources with very different spectral distribution are used, the real perception is significantly influenced by the choice of light source. The paper describes the influence of different light sources on the visual perception in terms of street lighting.", "paperid": 2552578709, "normalizedname_level1": "artificial intelligence"}
{"index": 93, "text": "The recent increase in the spreading of Virtual Reality allows a large number of consumers to experience this technology in several fields, from gaming to learning. In this paper we propose a framework that allows the user to freely move and interact in a virtual museum implemented with the HTC Vive. The goals of this work are: to investigate the possibility of using this approach for providing the user with a personalized and educative exploration of an artistic content, and to measure the immersivity and usability of the proposed system by means of a subjective experiment.", "paperid": 2910351284, "normalizedname_level1": "artificial intelligence"}
{"index": 94, "text": "The registration of multi-source remote sensing images is a challenging and crucial problem in remote sensing field. An automatic registration based on genetic algorithm is presented in this paper. Firstly, Scale-Invariant Feature Transform Modification (SIFT-M) and global matching are used to initialize the candidate points. Next, Genetic Algorithm (GA) is utilized to exclude the mismatch pairs and find the best set of corresponding points. The objective function is calculated by the similarity of Delaunay graphs generated by the selected points from candidates. Compared with several other algorithms, the proposed algorithm is demonstrated to achieve high accuracy and robustness for various real remote sensing images even with significant gray-scale differences.", "paperid": 2411620888, "normalizedname_level1": "artificial intelligence"}
{"index": 95, "text": "One of the challenging research topics is a fast, accurate, and human-like image processing method. The convolutional neural network recently shows optimistic results, but it needs a vast amount of computational resources. Utilizing feature extraction and dimensionality reduction algorithm might be a solution to increase computational efficiency. In this paper, we implemented a convolutional autoencoder for performing feature extraction and dimensionality reduction which not only can solve nonlinear problems but also easily combine the convolutional neural network. The implemented convolutional autoencoder derives remarkable reconstruction error in the experiments using the two-dimensional radar data.", "paperid": 2945641903, "normalizedname_level1": "artificial intelligence"}
{"index": 96, "text": "Retinal diseases can be manifested in optical coherence tomography (OCT) images since many signs of retina abnormalities are visible in OCT. Fluid regions can reveal the signs of age-related macular degeneration (AMD) and diabetic macular edema (DME) diseases and automatic segmentation of these regions can help ophthalmologists for diagnosis and treatment. This work presents a fully-automated method based on graph shortest path layer segmentation and fully convolutional networks (FCNs) for fluid segmentation. The proposed method has been evaluated on a dataset containing 600 OCT scans of 24 subjects. Results showed that the proposed FCN model outperforms 3 existing fluid segmentation methods by the improvement of 4.44% and 6.28% with respect to dice cofficients and sensitivity, respectively.", "paperid": 3036540742, "normalizedname_level1": "artificial intelligence"}
{"index": 97, "text": "Fuzzy cognitive map (FCM) is an effective tool for modeling and simulating complex dynamic systems. Research on the problem of learning FCM from available time series is outstanding. Many batch FCM learning methods have been proposed to address this issue and the performance of these methods is satisfactory. However, these batch-learning methods are difficult to cope with large-scale datasets (for example, the memory in computers is not enough to store all instances) and real-time streaming data, leading to the failure of real-time and online analysis of complex systems. In this paper, unlike the existing batch learning methods, such as evolutionary-based and regression-based methods, we first extend FCM learning to an online setting, and then develop an effective algorithm based on a follow-the-regularized-leader (FTRL)-Proximal style learning algorithm to address the online FCM learning problem, termed as OFCM. The performance of OFCM is validated on constructed benchmark datasets, including synthetic datasets and gene regulatory network reconstruction datasets. The experimental results demonstrate the merits of OFCM, which can effectively solve online FCM learning problems.", "paperid": 3018119790, "normalizedname_level1": "artificial intelligence"}
{"index": 98, "text": "We present a novel event embedding algorithm for crime data that can jointly capture time, location, and the complex free-text component of each event. The embedding is achieved by regularized Restricted Boltzmann Machines (RBMs), and we introduce a new way to regularize by imposing a ` 1  penalty on the conditional distributions of the observed variables of RBMs. This choice of regularization performs feature selection and it also leads to efficient computation since the gradient can be computed in a closed form. The feature selection forces embedding to be based on the most important keywords, which captures the common modus operandi (M.O.) in crime series. Using numerical experiments on a large-scale crime dataset, we show that our regularized RBMs can achieve better event embedding and the selected features are highly interpretable from human understanding.", "paperid": 2963851395, "normalizedname_level1": "artificial intelligence"}
{"index": 99, "text": "Human target detection and tracking have great potential in military, safety, security and entertainment applications. In this paper, a complete processing procedure is proposed for human tracking in foliage-penetration environment by multistatic radar. It consists of five main steps, including clutter suppression, target detection, measurement estimation, target localization and target tracking. Exponential average background subtraction is applied for clutter suppression. Ordered statistics constant false alarm rate (OS-CFAR) detector is used to detect targets in the range profile. The range measurement estimation is realized by a window filter. The S-D assignment algorithm is introduced for multi-target localization. Target tracking is realized by a Kalman filter based multi-target tracking (MTT) system. The experimental results verify the effectiveness of the proposed human tracking procedure.", "paperid": 2548025777, "normalizedname_level1": "artificial intelligence"}
{"index": 100, "text": "With the rapid development of artificial intelligence (AI), it has gradually integrated into people’s lives, and uses its own advantages to help people do things that cannot be done. It seems that AI will continue to develop more comprehensively in the future with more functions and technologies to help people and take some occupations.", "paperid": 3108308475, "normalizedname_level1": "artificial intelligence"}
{"index": 101, "text": "Advanced driver-assisting systems (ADAS) performs a crucial role for the safety and ease of transportation. Finding of lane markings is an essential step of ADAS. For the protection of automated vehicles, the precise results of lane detection are compulsory. In this study, we present an innovative approach based on structural analysis of lane and Computer Vision Technique such as Hough Transform (HT) for the detection of lane markers. Firstly, a stage of preprocessing is applied to remove the pavement area that develops the lane markings background. Next, an edge detection technique is applied to generate the map of the edge and masking is performed to obtain edges in our region of interest (ROI). Then, using HT to find lanes, important lines are analyzed in the area of interest. In end, the concept of vanishing point used to predict lane has been explained. Experimental result states that the proposed system can find boundaries of the lane and exact lane departure alert in the existence of several image artefacts, such as light change, bad lane mark. The proposed technique displays more efficiency.", "paperid": 3008128670, "normalizedname_level1": "artificial intelligence"}
{"index": 102, "text": "Fake news detection has gained growing interest from both the industry and research community all around the world, including Indonesia. Based on recent surveys, people could receive fake news daily, if not more than once. The research community and practitioners, supported by the government, are trying to fight back the spreading of fake news. This paper aims to implement a supervised machine learning approach using the Multi-Layer Perceptron (MLP) for classifying news article in order to detect fake news articles and differentiate them from the valid ones, via a binary text classification approach. Furthermore, this paper uses TF-IDF in comparison with the Bag of Words model to extract features along with the use of the n-gram model. Based on the result, our final model could achieve a hoax precision and recall score of 0.84 and 0.73, respectively, and a macro-averaged F1-score of 0.82. Furthermore, our paper shows that some preprocessing methods such as stemming and stop-word removal could be very time-consuming while only barely affecting the performance of our classifier model using the dataset in this research for identifying fake news.", "paperid": 3080997347, "normalizedname_level1": "artificial intelligence"}
{"index": 103, "text": "Signal processing of brain activity is becoming challenging to various researchers from different areas, including medical, biomedical, and engineering researchers. In this paper, investigations of brain activity are made from experimental works, with optical flow based on spatiotemporal analysis and wavelet over the equipment of Near Infrared Spectroscopy (NIRS). Ant Colony Optimization (ACO) algorithm is employed for obtaining the distributions of the intensity of the targeted image. The major outcomes of this paper from our research are the following items: (a) optical flow can be a proper technology for the investigation of brain activity based on NIRS; (b) the analyses of the temporal domain, the spatial domain, and the wavelet domain underpinned coherently to our experimental results; (c) our wavelet analysis can define the most brain activity image, denoted as targeted image; (d) the details of the intensity distributions on the targeted image show the most significant brain activity via ACO algorithm; (e) we can clearly observe, via our algorithm technology, the existence of the so-called Dominant Channel (DC) based on spatiotemporal analysis and it plays a critical role in brain activity. The spatial distribution of the origin of cortical activity can be described by hemodynamic response in the cerebral cortex after evoked stimulation using near infrared spectroscopy. Further application of this research is expected in the next step research outcomes.", "paperid": 2529507224, "normalizedname_level1": "artificial intelligence"}
{"index": 104, "text": "This paper proposes a new application that the object can be determined by the optimal model. To extract the target from the clutter background accurately, Mask-RCNN (Mask-Region Convolutional Neural Network) model is utilized for the segmentation process. Meanwhile, target object in front of the camera can be localized with the help of the Mask-RCNN segmentation and the geometric stereo matching method. Experiments show that distance values are calculated efficiently. And then the robot manipulator is performed to grasp the target object effectively.", "paperid": 3004043377, "normalizedname_level1": "artificial intelligence"}
{"index": 105, "text": "With the rapid development of smart cities and the advance of city safety and defense demands, the question that how to accurately discover and retrieve the data that users request from VideoGIS data faces a series of bottleneck problems. VideoGIS data retrieval is one of the important ways to solve above problems. In order to accelerate the rate of feature matching and improve the efficiency of the video retrieval, a new method of VideoGIS data retrieval based on multi-feature fusion is proposed in this paper. The method firstly use video frame difference based on Euclidean distance to extract the key frames under the spatial and temporal sampling of the video. On the basis of this, the global features (e.g. color, shape, texture) are fused by different weighted coefficients, then the feature vector, as the video multi-feature fusion representation, can be constructed by fusing the global features and local features. Based on the multi-feature fusion, correlation between video features is made full use. Compared with the method of single feature and two-feature fusion, the experimental results indicate that the proposed retrieval method has better retrieval effect.", "paperid": 2783280600, "normalizedname_level1": "artificial intelligence"}
{"index": 106, "text": "Deep learning models often use a flat softmax layer to classify samples after feature extraction in visual classification tasks. However, it is hard to make a single decision of finding the true label from massive classes. In this scenario, hierarchical classification is proved to be an effective solution and can be utilized to replace the softmax layer. A key issue of hierarchical classification is to construct a good label structure, which is very significant for classification performance. Several works have been proposed to address the issue, but they have some limitations and are almost designed heuristically. In this article, inspired by fuzzy rough set theory, we propose a deep fuzzy tree model which learns a better tree structure and classifiers for hierarchical classification with theory guarantee. Experimental results show the effectiveness and efficiency of the proposed model in various visual classification datasets.", "paperid": 2969574611, "normalizedname_level1": "artificial intelligence"}
{"index": 107, "text": "In this research we study the specific task of image-to-video retrieval, in which static pictures are used to find a specific timestamp or frame within a collection of videos. The inner temporal structure of video data consists of a sequence of highly correlated images or frames, commonly reproduced at rates of 24 to 30 frames per second. To perform large-scale retrieval, it is necessary to reduce the amount of data to be processed by exploiting the redundancy between these highly correlated images. In this work, we explore several techniques to aggregate visual temporal information from video data based on both standard local features and deep learning representations with the focus on the image-to-video retrieval task.", "paperid": 2808170931, "normalizedname_level1": "artificial intelligence"}
{"index": 108, "text": "Taking a look at the number of road accidents, it's noticed that a significant part of these is due to the driver falling asleep at the wheel. This paper will descrive a Web-based plataform capable of storing, processing and analyzing eletroencephalogram (EEG) signals, thus descriving the ability to detect drowsiness that could prevent the occurrence of accidents related to driving. This Web-based platform will allow the user to test various possibilities with the use of different EEG signals, filters, window's sizes and steps, delays and classifiers, in order to find the best combination for the detection of drowsiness while driving.", "paperid": 2737548557, "normalizedname_level1": "artificial intelligence"}
{"index": 109, "text": "A data set of 90 60-cell module images from 5 commercial PV module brands over 6 exposure steps of damp-heat testing were analyzed. An automated data analysis pipeline was developed using the open source coding language Python to parse the module images into individual cell images. As the original raw images are not directly suitable for modeling, this algorithm implements techniques which include filtering, thresholding, convex Hull, regression fitting, and perspective transformation to pre-process the original image. After cell extraction, 5400 individual cell images as a function of brand and exposure time were obtained. From the data set, 3 initial degradation categories were observed: good, cracked, and heavily busbar-corroded. For supervised machine learning classification, these images were manually sorted into these 3 categories yielding 3550 images. To increase the data set size, the cell images were augmented by flipping the images about the x-axis and y-axis as well as rotated 180 degrees. This increased the total sample size to 14,200 images with good, cracked, and heavily corroded counts of 12,004, 492, and 1704, respectively. A training and testing framework was generated using stratified sampling with a training to testing data ratio of 80:20. The statistical learning algorithms Support Vector Machine (SVM), Random Forest (RF), and Artificial Neural Network (ANN), were independently trained on the training set and then given the remaining data images to predict their classification. The results showed model prediction accuracies of 98.77%, 96.60%, and 98.13% for the SVM, RF, and ANN models, respectively.", "paperid": 2903283628, "normalizedname_level1": "artificial intelligence"}
{"index": 110, "text": "A cellular neural network (CNN) with a bipolar stepwise activation function is considered. The influence of the weight quantization levels number on CNN information capacity is investigated. It is shown that the capacity of CNN with quantized weights and the number of quantization levels, sufficient to approach the capacity of CNN version with continuous weights, depend upon CNN training method (Hebb method or local projection method).", "paperid": 2999668200, "normalizedname_level1": "artificial intelligence"}
{"index": 111, "text": "The electricity consumption will continue to increase despite the overall efforts and tendencies of changing the old appliances to less energy intensive ones. The advancements of Electric Vehicles (EV) and public mobility, electric heating, and the abundance of smart appliances that enhance the comfort of modern life lead to an increasing consumption trend. On the other hand, prosumers raising the quota of distributed generation and storage capacity will balance the electricity consumption trend. These changes at the consumption and generation level lead to the necessity to increase the awareness and incentive the consumers' behavior to flatten the consumption curve and improve the savings. Such objectives could be reached by properly setting the Time-of-Use (ToU) tariff rates to encourage the consumption at off-peak hours when the rates are lower and unstress the grid loading. In this paper, we propose a methodology for setting the Time-of-Use (ToU) tariff rates and peak/off-peak intervals using big data technologies and machine learning, and verify the assumptions considering the large volume of consumption data of over 4200 residential consumers recorded in a smart metering implementation trail period that took place in Ireland from January to December 2010. We calculate the contribution to the peak/off-peak of the total consumption and use it in setting the ToU tariff rates starting from the flat tariff. Then, the consumers' sensitivity to tariff change from flat to ToU is considered to identify the consumption change. The results show that using ToU instead of flat tariff, the peak is reduced in average by 5 to 7.5% and annual savings are around 4%. Also, by clustering the consumers a better allocation of the tariffs is possible. Thus, clustering is proposed considering the importance of the tariff allocation in Demand Side Management (DSM).", "paperid": 3004372506, "normalizedname_level1": "artificial intelligence"}
{"index": 112, "text": "We present a machine learning technique for driving 3D facial animation by audio input in real time and with low latency. Our deep neural network learns a mapping from input waveforms to the 3D vertex coordinates of a face model, and simultaneously discovers a compact, latent code that disambiguates the variations in facial expression that cannot be explained by the audio alone. During inference, the latent code can be used as an intuitive control for the emotional state of the face puppet.   We train our network with 3--5 minutes of high-quality animation data obtained using traditional, vision-based performance capture methods. Even though our primary goal is to model the speaking style of a single actor, our model yields reasonable results even when driven with audio from other speakers with different gender, accent, or language, as we demonstrate with a user study. The results are applicable to in-game dialogue, low-cost localization, virtual reality avatars, and telepresence.", "paperid": 2739192055, "normalizedname_level1": "artificial intelligence"}
{"index": 113, "text": "People's travel and traffic safety are affected by low visibility. With the development of transportation in recent years, the detection of license plate area under low visibility has become one of the hot topics of research. This article studies the license plate detection under low visibility based on video images. The research content is divided into two parts: defogging and license plate inspection. First of all, the collected image is processed in grayscale, the related defogging coefficient is set, and the dark channel algorithm is used to remove the fog component in the image, which greatly improves the clarity of the image. Second, using the top hat calculation related theory, combined with the image edge extraction, opening and closing operation steps to detect the license plate area. Finally with the help of MATLAB software for test verification, the results show that the algorithm has a good detection effect.", "paperid": 2897157816, "normalizedname_level1": "artificial intelligence"}
{"index": 114, "text": "A projector is usually coupled with a dedicated projection surface to properly display visual information. This prevents the application of projection in places where a dedicated projection surface is not readily available. This paper presents a method for automatically detecting a good surface in a daily living and working space to support improvisatory projection without a pre-installed projection surface. Our method uses a projector-camera system that scans an environment and evaluates the quality of the environment surface for visual projection in two steps. Our method first excludes non-planar or highly-textured surface through epipolar geometry analysis and texture analysis. For a surface that passes the first test, our method further evaluates its quality for visual projection by quickly projecting the sampled projection content onto the surface and measuring the quality of the projected visual content. Our experiment shows that our method can reliably identify a good surface in a daily environment for high-quality visual projection.", "paperid": 2782302363, "normalizedname_level1": "artificial intelligence"}
{"index": 115, "text": "The concept of \"deception\" in fitness landscapes was introduced in the genetic algorithm (GA) literature to characterize problems where sign epistasis can mislead a GA away from the global optimum. Evolutionary geneticists have long recognized that sign epistasis is the source of the ruggedness of fitness landscapes, and the recent availability of a growing number of empirical fitness landscapes may make it possible for evolutionary biologists to study how deception affects adaptation in a variety of organisms. However, existing definitions of deception are categorical and were developed to characterize landscapes independent of population distributions on the landscape. Here we propose two metrics that quantify deception as continuous functions of the locations of replicators on a given landscape. We develop a discrete population model to simulate within-host evolution on 19 empirical fitness landscapes of Plasmodium falciparum (the most common and deadly form of malaria) under different dosage levels of two anti-malarial drugs. We demonstrate varying levels of deception in malarial evolution, and show that the proposed metrics of deception are predictive of some important aspects of evolutionary dynamics. Our approach can be readily applied to other fitness landscapes and toward an improved understanding of the evolution of antimicrobial drug resistance.", "paperid": 2478726614, "normalizedname_level1": "artificial intelligence"}
{"index": 116, "text": "Recently, low-rank embedding (LRE) has yielded satisfactory results in dimensionality reduction (DR), for which low-rank representation and projection learning are integrated into one model to generate robust low-dimensional features. However, LRE requires to convert samples into vectors even if the data naturally appear in high-order form. Furthermore, LRE fails to take the label information into consideration. To address these problems, this paper proposes a novel supervised DR method based on multilinear algebra, i.e., the algebra of tensors. By the motivation of extending LRE into tensor space and simultaneously combining the tensor discriminant analysis, we establish tensor low-rank discriminant embedding (TLRDE) model for hyperspectral image (HSI) DR. The model of TLRDE is solved by an alternative iteration algorithm, whose convergence is also mathematically proven. The proposed TLRDE method employs the tensor representation to preserve the intrinsic geometrical structure, uses low-rank reconstruction to uncover the potential relationship among the data points, and combines label information to enhance the discriminability of features. Moreover, the proposed TLRDE does not suffer from the small sample size problem. The experimental results on three real HSI data sets validate the effectiveness of our proposed TLRDE method.", "paperid": 2884776009, "normalizedname_level1": "artificial intelligence"}
{"index": 117, "text": "This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation. Experimental study in visually and physically realistic simulation suggests that our method builds effective representations that capture structural regularities and efficiently solve long-horizon navigation problems. We observe a relative improvement of more than 50% over existing methods that study this task.", "paperid": 3034728521, "normalizedname_level1": "artificial intelligence"}
{"index": 118, "text": "Facing the development of the times and technological progress needs new methods and technologies to enrich semantic analysis of scientific & technical literature. Term is the linguistic expression of the concepts in professional knowledge, which is accumulated through incremental exploration and research in specific fields. In the study of semantic analysis, term recognition is an important research subject. This research intended to apply deep neural network in term recognition. And the paper also introduced specific methods of semantic analysis based on the result of Chinese term recognition and implementation using specific scientific & technical literature. It gave an overview of theories and technologies related to the method and used the real and effective corpus for experiments.", "paperid": 2943767929, "normalizedname_level1": "artificial intelligence"}
{"index": 119, "text": "In this paper, we propose a generation method of visually protected images and its application to privacy-preserving machine learning. Images generated by the proposed method hold the gradient direction information of the original images, but have no the information. Histogram-of-Oriented-Gradients (HOG) features are extracted from the protected images, and the features are applied to machine learning algorithms. In addition, the proposed generation method is an irreversible one, so there is no need to manage secret keys, unlike encryption methods. In an experiment, a face classification task is carried out under the use of a support vector machine algorithm with the HOG features to demonstrate the effectiveness of the proposed method.", "paperid": 3005888409, "normalizedname_level1": "artificial intelligence"}
{"index": 120, "text": "Verification code is a human-machine test method that is widely used in the Internet. It can essentially distinguish between human and network robots. However, with the development of technology, more and more problems has been found in the verification code. This paper takes the digital verification codes commonly used in university student management system as the research object. The verification code after scaling and graying is used as the data set. The eight-layer ALexNet convolutional neural network is constructed by using the Google deep learning framework TensorFlow to train the verification code. The data set is tested to obtain a network model that can identify different complexity digital verification codes. The recognition rate of digital verification codes commonly used in college student management systems can reach 99%.", "paperid": 2999232140, "normalizedname_level1": "artificial intelligence"}
{"index": 121, "text": "Sentiment analysis has an important role in social media monitoring as it extracts public opinions, emotions, and feelings about certain products or services. There are several publications in building a system to identify opinions from text using rule-based approach, lexicon-based approach, or machine learning. In this paper, we propose and compare several deep learning models to solve sentiment analysis problem of the Internet Movie Database (IMDb) review sentiment dataset. The feature extractor consists of a convolutional layer, followed by a max pooling layer and a batch normalization layer. To solve the vanishing gradient problem, we use a residual connection to concatenate the input values with the extracted features before feeding the output into a recurrent layer. Our best model has an accuracy of 90.02%.", "paperid": 3000315977, "normalizedname_level1": "artificial intelligence"}
{"index": 122, "text": "Three-dimensional display technologies based on lenticular sheet overlaid onto spatial light modulator screen have been studied for decades. However, the quality of these displays still suffers from insufficient number of views and zone-jumping between views. We present herein a subpixel multiplexing method in this paper. We propose to split mapping and alignment into two separate tasks, processed in parallel threads. Alignment thread deals with the task of computing the geometrical relationship between lenticular sheet and Liquid Crystal Display (LCD) panel for multiplexing. Afterwards, we conduct the multiplexing procedure through a box-constrained integer least squares algorithm. After multiplexing, each subpixel aggregated on the lenticular sheet is a multiplexing one that mixes up a number of subpixels in local region on the LCD plane. As a result, we multiplex subpixels on the synthetic image up to 27 views with a resolution of   $1080 \\times 1920$   and the rendering speed is 73.34 frames per second (fps).", "paperid": 2413941320, "normalizedname_level1": "artificial intelligence"}
{"index": 123, "text": "We propose a novel keypoint detector for 3D RGB Point Clouds (PCs). The proposed keypoint detector exploits both the 3D structure and the RGB information of the PC data. Keypoint candidates are generated by computing the eigenvalues of the covariance matrix of the PC structure information. Additionally, from the RGB information, we estimate the salient points by an efficient adaptive difference of Gaussian-based operator. Finally, we fuse the resulting two sets of salient points to improve the repeatability of the 3D keypoint detector. The proposed algorithm is compared against the state-of-the-art algorithms on two benchmark datasets. The experimental results show that the proposed scheme outperforms the best existing method by 5.35% and 60.98 points on the SHOT-Kinect dataset and by 5.45% and 145.54 points on the SHOT-SpaceTime dataset in terms of relative and absolute repeatability, respectively.", "paperid": 2970402647, "normalizedname_level1": "artificial intelligence"}
{"index": 124, "text": "The 21st century is the age of automatization. While before the millennium day-to-day applications were semi-autonomous since they necessitated human intervention in achieving their goals, now we are living in a society that expects trustworthy autonomous systems in the industrial and business life as well as in their private life that can attain goals independently without any human intervention [1]. The automatons might be on the verge of completion, but are the people ready for them, or will they hesitate to use them because of lack of trust? Present article endeavours the tackle the issue of trust in automatic systems on the basis of a primary research on attitudes toward (semi) automated vehicles.", "paperid": 2766108194, "normalizedname_level1": "artificial intelligence"}
{"index": 125, "text": "In the context of document security systems, there is a growing need for a stable segmentation method. State-of-the-art document image segmentation methods are not stable as they use several parameters and thresholds such as binarization. Hence, this paper presents a new method for segmentation based on a new definition of connected color components and a new model of human vision. Our algorithm produces results that are three to four times more stable than state-of-the-art superpixel segmentation methods while maintaining a similar segmentation accuracy.", "paperid": 2903115243, "normalizedname_level1": "artificial intelligence"}
{"index": 126, "text": "Ear recognition Is still a standing problem In biometrics and has become an open research area in recent years. In this paper, we explore a new local feature extraction technique pyramid histogram of oriented gradients (PHOG) to represent ear images. However, the PHOG descriptor of the ear image is significantly large. To reduce the dimension of the PHOG descriptor, linear discriminant analysis (LDA) has been used to remove noise and avoid over fitting. Finally, the discriminant features are classified using nearest neighbor classifier. The PHOG has inherent properties to efficiently handle the problems of change in pose and partial occlusion of the ear images. The results of the proposed method are evaluated using two public ear databases, namely IIT Delhi ear database and University of Notre Dame ear database (Collections E). Our method with reduced features using LDA offers promising results and largely improves the recognition accuracy over existing methods.", "paperid": 2756505538, "normalizedname_level1": "artificial intelligence"}
{"index": 127, "text": "Medical image analysis is currently experiencing a paradigm shift due to deep learning. This technology has recently attracted so much interest of the Medical Imaging Community that it led to a specialized conference in “Medical Imaging with Deep Learning” in the year 2018. This paper surveys the recent developments in this direction and provides a critical review of the related major aspects. We organize the reviewed literature according to the underlying pattern recognition tasks and further sub-categorize it following a taxonomy based on human anatomy. This paper does not assume prior knowledge of deep learning and makes a significant contribution in explaining the core deep learning concepts to the non-experts in the Medical Community. This paper provides a unique computer vision/machine learning perspective taken on the advances of deep learning in medical imaging. This enables us to single out “lack of appropriately annotated large-scale data sets” as the core challenge (among other challenges) in this research direction. We draw on the insights from the sister research fields of computer vision, pattern recognition, and machine learning, where the techniques of dealing with such challenges have already matured, to provide promising directions for the Medical Imaging Community to fully harness deep learning in the future.", "paperid": 2958150439, "normalizedname_level1": "artificial intelligence"}
{"index": 128, "text": "This paper presents a health monitoring method by estimating vital signs using an RGB camera. The rPPG signal is used to estimate the physical parameters with the help of a non-invasive smartphone camera. The vital signs of human are very important especially in health monitoring applications. In this paper, the deep learning-based algorithm has been used to estimate the vital signs using rPPG signal based on RGB frames camera video. The convolutional neural network (CNN) has been used to estimate the vital sign such as heart rate and breathing rate, their ratio, and Sp02. The features were extracted from the last convolutional layer (C5) of the pre-trained VGG16 model. The average of the blood intensity variation extracted as a feature matrix from the last convolutional layer represents the rPPG signal which further used to estimate the vital signs. The results show that proposed technique produced better performance as compared to existing standard and conventional vital signs estimation techniques.", "paperid": 2972171231, "normalizedname_level1": "artificial intelligence"}
{"index": 129, "text": "Classically, the problems of blind source separation and extraction are tackled by optimizing a single separation criterion which is associated with a given property of the sources of interest. Motivated by the fact that, very often in practice, there is more than one property to be exploited, the present work introduces a novel separation framework that relies on multi-objective optimization. In order to demonstrate the viability of the proposed framework, we test it in a situation in which both the sparsity and temporality of the source of interest are exploited. Numerical experiments suggest that the worst case Pareto-optimal solution has similar performance compared to the cases where each property is exploited separately via a single-objective formulation.", "paperid": 2519666569, "normalizedname_level1": "artificial intelligence"}
{"index": 130, "text": "In this paper, we present SphereDiar, a speaker diarization system composed of three novel subsystems: the Sphere-Speaker (SS) neural network, designed for speaker embedding extraction, a segmentation method called Homogeneity Based Segmentation (HBS) and a clustering algorithm called Top Two Silhouettes (Top2S). The system is evaluated on a set of over 200 manually transcribed multiparty meetings. The evaluation reveals that the system can be further simplified by omitting the use of HBS. Furthermore, we illustrate that SphereDiar achieves state-of-the-art results with two different meeting data sets.", "paperid": 2953619623, "normalizedname_level1": "artificial intelligence"}
{"index": 131, "text": "People re-identification task has seen enormous improvements in the latest years, mainly due to the development of better image features extraction from deep Convolutional Neural Networks (CNN) and the availability of large datasets. However, little research has been conducted on animal identification and re-identification, even if this knowledge may be useful in a rich variety of different scenarios. Here, we tackle cattle re-identification exploiting deep CNN and show how this task is poorly related with the human one, presenting unique challenges that makes it far from being solved. We present various baselines, both based on deep architectures or on standard machine learning algorithms, and compared them with our solution. Finally, a rich ablation study has been conducted to further investigate the unique peculiarities of this task.", "paperid": 2912816240, "normalizedname_level1": "artificial intelligence"}
{"index": 132, "text": "With the recent surge in popularity of Convolutional Neural Networks (CNNs), motivated by their significant performance in many classification and related tasks, a new challenge now needs to be addressed: how to accommodate CNNs in mobile devices, such as drones, smartphones, and similar low-power devices? In order to tackle this challenge we exploit the Vision Processing Unit (VPU) that combines dedicated CNN hardware blocks and very high power efficiency. The lack of readily available training data and memory requirements are two of the factors hindering the training and accuracy performance of 3D CNNs. In this paper, we propose a method for generating synthetic 3D point-clouds from realistic CAD scene models (based on the ModelNet10 dataset), in order to enrich the training process for volumetric CNNs. Furthermore, an efficient 3D volumetric object representation (VOLA) is employed. VOLA (Volumetric Accelerator) is a sexaquaternary (power-of-four subdivision) tree-based representation which allows for significant memory saving for volumetric data. Multiple CNN models were trained and the top performing model was ported to the Fathom Neural Compute Stick (NCS). Among the trained CNN models, the maximum test accuracy achieved is 91.3%. After deployment on the Fathom NCS, it takes 11ms (∼ 90 frames per second) to perform inference on each input volume, with a reported power requirement of 1.2W which leads to 75.75 inference per second per Watt.", "paperid": 2810477194, "normalizedname_level1": "artificial intelligence"}
{"index": 133, "text": "To achieve Automatic Writing of NBA Sports news, Constructing Automatic Writing Template Library of NBA Sports News is a necessary process, normalization of templates is an essential process of constructing template library. This paper uses the Cosine Similarity method and the word2vec word expansion method combined with the Cosine Similarity method to normalize templates respectively. Experimental results show that Using Word2vec word extension method combined with Cosine Similarity method is much more likely to identify the semantics similar sentences, realizing the normalization of the template library, it provide support for that Automatic Writing of NBA Sports News.", "paperid": 2949077305, "normalizedname_level1": "artificial intelligence"}
{"index": 134, "text": "Nowadays environmental changes have frequently occurred all over the world. Among these changes, river changes are also important to be monitored. The accurate river region detection is the primary important step in river change detection. There is a lot of analysis in river regions detection and extraction based on Landsat and Synthetic Aperture Radar (SAR) images, but there are a few approaches for Google Earth RGB images which do not contain multispectral bands. Thus, this paper is proposed to detect and extract the river regions including both river and sandbank using Google earth RGB images. In this paper, the river regions and sandbank regions are firstly segmented using heuristic rules based on Sobel and thresholding methods. And then, HSV histogram features, color autocorrelogram features, color moments features, Gabor wavelet features and wavelet transform features are extracted from the segmented regions. The multi-class Support Vector Machine (SVM) is applied to categorize the river regions, sandbank regions, and others based on the derived features. According to the testing result, the proposed system obtained 94% overall accuracy for river regions detection.", "paperid": 2903468154, "normalizedname_level1": "artificial intelligence"}
{"index": 135, "text": "The generation of word hypotheses for segmentation-free word spotting on document level is usually subject to heuristic expert design. This involves strong assumptions about the visual appearance of text in the document images. In this paper we propose to generate hypotheses with text detectors. In order to do so, we present three detectors that are based on SIFT contrast scores, CNN region classification scores and attribute activation maps. The uncertainty in the detector scores is modeled with the extremal regions method. Retrieving word hypotheses is based on PHOC representations which we compute with the TPP-PHOCNet. We evaluate our method on the George Washington dataset and the ICFHR 2016 KWS competition benchmarks. In the evaluation we show that high word detection rates can be achieved. This is a prerequisite for high retrieval performance that is competitive with the state-of-the-art.", "paperid": 2787542374, "normalizedname_level1": "artificial intelligence"}
{"index": 136, "text": "The technology challenge facing the Internet of Things (IoT) requires a multi‐disciplined approach to artificial intelligence (AI) systems engineering and it is critical that the IoT effort address cyber‐assurance (e.g., embedded, automatic security processing) for rapid responses to significant IoT activities. This chapter briefly provides the possibility of the usage of AI for cyber‐assurance for the IoT. The IoT offers an interactive connection between the physical world and computer systems in order to obtain improved efficiency, accuracy, and economic advantages. An AI approach does not demand the discarding of current IoT systems to start anew. On the contrary, it enables the utilization of existing technology assets by integrating select functionality into the IoT. Although it is highly debated that the technology influence in our daily lives may make us ever more dependent on technology, the growth of AI within the IoT will also continue.", "paperid": 2562053978, "normalizedname_level1": "artificial intelligence"}
{"index": 137, "text": "Most of the researches on Chinese named entity recognition (NER) focus on the general field, and few on NER in the field of science and technology. On one hand, technical terms in the field of science and technology appear in general texts less frequently, with most of which being compound words, and the performance of word segmentation processing on texts in the field of science and technology is poor. On the other hand, texts in the field of science and technology are more accurate and standardized than those in general fields. By analyzing these characteristics of texts in the field of science and technology, this paper attempts to train word vectors by constructing terminology dictionaries and introducing dependency analysis. Referring to the latest NER research results in the current Chinese general field, i.e. the method of merging character vectors with word vectors, we will perform NER on texts in the field of science and technology. Through experiments, it is proved that the proposed method is more effective comparing to existing works. In addition, the effect of introducing attention mechanism on NER results is also studied.", "paperid": 3110398092, "normalizedname_level1": "artificial intelligence"}
{"index": 138, "text": "With the popularity of wearable devices, smart watches containing various sensors have been widely adopted for many healthcare applications. Yet there is rarely any research study on the possible uses of smart watches for learning analytics, particularly for analyzing students’ learning activities through the physiological and/or movement data collected on their smart watches. This paper considers a pioneering and sophisticated learning analytics platform using fine-tuned deep learning models to predict students’ learning activities based on the real-time data, including their heart rates, calories, three-axis accelerometer and gyroscope data, captured on wearable devices and then uploaded onto a cloud server for thorough analyses. To validate on the actual activities conducted by each student, an intelligent mobile application is developed to push instant notifications for students to report their own activities whenever the change of heart rates are deviated significantly from their normal values. Based on students’ heart rates and calories, a long-short term memory (LSTM) model is built to classify students’ learning states as active or not with an impressive prediction accuracy of 95% whereas another hybrid model combining both the LSTM and convolutional neural networks attains the highest prediction accuracy of 74% to predict students’ specific learning activities as based on their physiological and movement data. The prototype implementation clearly demonstrates the feasibility of the proposed framework for learning analytics. More importantly, this work shed lights on various directions including the integration of noise filters to preprocess the collected data for further investigation.", "paperid": 3006390422, "normalizedname_level1": "artificial intelligence"}
{"index": 139, "text": "Learning to Rank (LTR) is one of the current problems in Information Retrieval (IR) that attracts the attention from researchers. The LTR problem is mainly about ranking the retrieved documents for users in search engines, question answering and product recommendation systems. There are a number of LTR approaches from the areas of machine learning and computational intelligence. Most approaches have the limitation of being too slow or not being very effective. This paper investigates the application of evolutionary computation, specifically a (1+1) Evolutionary Strategy called ES-Rank, to tackle the LTR problem. Experimental results from comparing the proposed method to fourteen other approaches from the literature, show that ES-Rank achieves the overall best performance. Three datasets (MQ2007, MQ2008 and MSLR-WEB10K) from the LETOR benchmark collection and two performance metrics, Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG) at top-10 query-document pairs retrieved, were used in the experiments. The contribution of this paper is an effective and efficient method for the LTR problem.", "paperid": 2617306019, "normalizedname_level1": "artificial intelligence"}
{"index": 140, "text": "Down-sampling in the discrete cosine transform (DCT) domain is preferable for images coded by DCT transform, such as JPEG/MJPEG/H.264, etc. Recent researches show that the truncated high-frequency DCT coefficients during the DCT down-sampling process can be estimated by learning the correlations between low-frequency and high-frequency DCT coefficients. In this paper, we propose to utilize the powerful super-resolution framework using sparse dictionaries with anchored neighborhood regression to significantly improve the accuracy of the estimated high-frequency DCT coefficients. Experimental results show that the proposed framework outperforms the state-of-the-art DCT-based up-sampling methods in terms of PSNR (0.3–1.63dB) and SSIM values for standard image datasets Set5 and Set14, while the computational time of the proposed method is 23× times faster than the state-of-the-art learning-based method using k-NN MMSE due to pre-computation of the ridge regression during the training process.", "paperid": 2791754581, "normalizedname_level1": "artificial intelligence"}
{"index": 141, "text": "Depth estimation with monocular cameras is a cheap and promising solution for autonomous vehicles and robots. Even though there are many approaches in the literature, the issue of estimating depth of objects with low optic flow (low parallax) still remains. This work proposes a new two-view monocular depth estimation method that estimates depths with only a monocular camera using two optic flow directions based on the Flat Surface Model, fusing them with optic flow as weights. The proposed method achieves an average depth estimation error of 3.68 m and a maximum error of 107.34 m, which are smaller than those obtained by traditional techniques (22.90 and 9815.44 m, respectively).", "paperid": 2910263088, "normalizedname_level1": "artificial intelligence"}
{"index": 142, "text": "The goal of this work is to develop a novel CMOS camera sensor that provides frameless capture, and has significantly higher dynamic range, finer color sensitivity, and lower noise as compared to the current state-of-the-art sensors. The strength of the approach lies not in developing new types of photodetectors or amplifiers, but in the manner in which information is extracted from the pixel sensor, transported to the processing logic, and processed to yield intensity values. At the heart of the sensor is an asynchronous network to transport events from the pixel sensors to the off-grid processing circuitry. The asynchronous nature of pixel communication is the key to achieving frameless image capture.", "paperid": 2767646933, "normalizedname_level1": "artificial intelligence"}
{"index": 143, "text": "Positron emission tomography (PET) is a molecular medical imaging modality which is commonly used for neurodegenerative diseases diagnosis. Computer-aided diagnosis, based on medical image analysis, could help quantitative evaluation of brain diseases such as Alzheimer’s disease (AD). A novel method of ranking the effectiveness of brain volume of interest (VOI) to separate healthy control from AD brains PET images is presented in this paper. Brain images are first mapped into anatomical VOIs using an atlas. Histogram-based features are then extracted and used to select and rank VOIs according to the area under curve (AUC) parameter, which produces a hierarchy of the ability of VOIs to separate between groups of subjects. The top-ranked VOIs are then input into a support vector machine classifier. The developed method is evaluated on a local database image and compared to the known selection feature methods. Results show that using AUC outperforms classification results in the case of a two group separation.", "paperid": 2793668604, "normalizedname_level1": "artificial intelligence"}
{"index": 144, "text": "In this paper, traditional one-hot encoded network is compared with three deep metric learning methods by using contrastive loss, triplet loss, and quadruplet loss on character classification task. Experimental results show that deep metric learning methods provide similar performance to one-hot encoded network, but have more advantages and less label requirements. On the other hand, by comparing these well-known deep metric learning methods under the same number of parameters, their differences are also summarized.", "paperid": 3108527399, "normalizedname_level1": "artificial intelligence"}
{"index": 145, "text": "The main contribution of this paper is the design of a decentralized and tuning-less high level controller able to maintain without tracking errors a Leader-Follower (LF) configuration in case of lack or degraded communications (latencies, loss …) between the leader and followers UAVs. The high level controller only requires simple tunings and rests on a predictive filtering algorithm and a first order dynamic model to recover an estimation of the leader UAV velocities and avoid the tracking errors.", "paperid": 3006186553, "normalizedname_level1": "artificial intelligence"}
{"index": 146, "text": "The purpose of this study is to determine the optimal wavelet-based feature extraction technique based for rice growth stage classification. Data are obtained from the Badan Pengkajian dan Penerapan Teknologi (BPPT). We implemented two decomposition approach i.e. standard wavelet decomposition and wavelet packet analysis with coif1, coif2, coif3, db2, db3 and haar as the wavelet basis. The level of decomposition on wavelet decomposition begins from 3 to 11, while on wavelet packet analysis starts from the decomposition level 3 to 6. From each subband we extraced the following features: mean, median, skewness, kurtosis, residual energy, energy, standard deviation, and variance. We used k-nearest-neighbor, naive bayes, support vector machine and decision tree as the classifier. The highest accuracy of the wavelet decomposition is 90.41% with db2 as wavelet basis and 11 level of decomposition using support vector machine as the classifier. Wavelet packet analysis approach gives 80.17% accuracy on Haar wavelet basis and 3 level decomposition using decision tree as the classifier. Based on the experimental results, support vector machine and decision tree have better performance than k-nearest-neighbor and Naive Bayes on 77 of total 84 trials.", "paperid": 2599031609, "normalizedname_level1": "artificial intelligence"}
{"index": 147, "text": "This paper proposes a high precision, robust 3D measurement method and a fast, accurate pose estimation method. The RGB-based Gray code Shifting and Positive/Negative coding method (RGB-GSPN) is introduced to improve the structured light measurement system. This coding method is easy to be decoded. It can eliminate the influence of scattered light and reduce the influence of the objects surface color on the measurement precision. Then, we combine 2D and 3D information to perform pose estimation. SIFT features of 2D images are used to roughly match the position. Subsequently, we send this pose to the Iterative Closest Point (ICP) algorithm as its initial matching position and use ICP for accurate estimation. This can avoid getting into a local optimum and speed up the convergence of the algorithm. Experiments show that the system has a high precision and can estimate the pose of the workpiece accurately.", "paperid": 3006345948, "normalizedname_level1": "artificial intelligence"}
{"index": 148, "text": "Breast cancer is the most cancer affecting women. Cases in this disease that continue to increase every year lead to the notion that this cancer cannot be cured. Doing early detection of breast cancer can be very helpful to minimize the effects of this disease on sufferers. This research proposes the classification of breast cancer based on mammographic images using Probabilistic Neural Network (PNN) as a classifier, to optimize PNN work preprocessing steps such as median filters are used to minimize noise, in addition to using Gaussian Mixture Model (GMM) segmentation, and extraction features of Gray Level Co-occurrence Matrix (GLCM). PNN classifier was chosen because it can work effectively on small datasets. Based on testing this method produces very good accuracy that is 100% accuracy.", "paperid": 3096785396, "normalizedname_level1": "artificial intelligence"}
{"index": 149, "text": "The brain-computer interface (BCI) connects the brain and the external world through an information transmission channel by interpreting the physiological information of the brain during thinking activities. The effective classification of electroencephalogram (EEG) signals is the key to improving the performance of the system. To improve the classification accuracy of EEG signals in the BCI system, the transfer learning algorithm and the improved Common Spatial Pattern (CSP) algorithm are combined to construct a data classification model. Finally, the effectiveness of the proposed algorithm is verified. The results show that in actual and imagined movements, the accuracy of the left- and right-hand movements at different speeds is higher than when the speeds are the same. The proposed Adaptive Composite Common Spatial Pattern (ACCSP) and Self Adaptive Common Spatial Pattern (SACSP) algorithms have good classification effects on 5 subjects, with an average classification accuracy rate of 83.58%, which is an increase of 6.96% compared with traditional algorithms. When the training sample size is 10, the classification accuracy of the ACCSP algorithm is higher than that of the traditional CSP algorithm.", "paperid": 3043396847, "normalizedname_level1": "artificial intelligence"}
{"index": 150, "text": "This paper introduces a framework for how to appropriately adopt and adjust machine learning (ML) techniques used to construct electrocardiogram (ECG)-based biometric authentication schemes. The proposed framework can help investigators and developers on ECG-based biometric authentication mechanisms define the boundaries of required datasets and get training data with good quality. To determine the boundaries of datasets, use case analysis is adopted. Based on various application scenarios on ECG-based authentication, three distinct use cases (or authentication categories) are developed. With more qualified training data given to corresponding machine learning schemes, the precision on ML-based ECG biometric authentication mechanisms are increased in consequence. The ECG time slicing technique with the R-peak anchoring is utilized in this framework to acquire ML training data with good quality. In the proposed framework four new measure metrics are introduced to evaluate the quality of the ML training and testing data. In addition, a Matlab toolbox, containing all proposed mechanisms, metrics, and sample data with demonstrations using various ML techniques, is developed and made publicly available for further investigation. For developing ML-based ECG biometric authentication, the proposed framework can guide researchers to prepare the proper ML setups and the ML training datasets along with three identified user case scenarios. For researchers adopting ML techniques to design new schemes in other research domains, the proposed framework is still useful for generating the ML-based training and testing datasets with good quality and utilizing new measure metrics.", "paperid": 2933579063, "normalizedname_level1": "artificial intelligence"}
{"index": 151, "text": "There is a plenty of unorganized data available in various information repositories and examining this data is very necessary for some future analysis. Clustering this kind of data plays a vital role in knowing about formerly unknown and possibly useful data and also the concerns should be widely examined. Here, we are proposing a high level methodology for clustering the data. First of all the proposed methodology utilizes contiguous Fuzzy c-means (FCM) clustering the vertex into consistent regions. For Optimization we are using Gravitational Search Algorithm (GSA) based on law of gravity to overcome integration problems when dealing with Fuzzy C-means (FCM) Clustering. When applying GSA, gives better results by identifying optimum number of clusters and curtails the fitness function.", "paperid": 2765605361, "normalizedname_level1": "artificial intelligence"}
{"index": 152, "text": "In conventional helical computed tomography (CT), the field-of-view is a cylinder centered on the axis of the helix. Here, we consider the situation where all measurement lines are blocked except those intersecting a small cylindrical region-of-interest (ROI) not necessarily centered on the axis of the system. We address the question of image reconstruction inside the ROI. The patient boundary is assumed known, and we avoid the “interior problem” by assuming that the ROI includes part of the patient boundary. By applying analytic image reconstruction theory, we show that the entire cylindrical ROI can be reconstructed provided the pitch of the helix does not violate the well-known Tam–Danielsson detector condition. Using an iterative algorithm, we performed ROI reconstruction from simulated phantom data and from real patient data, and compared the results with full-field reconstructions. Visually, the ROI reconstructed images perfectly matched the full-field reconstructions. However, there were small quantitative discrepancies near the interior boundaries of the ROIs, which we attribute to the known reduced stability at one side of the inverse truncated Hilbert transform. In conclusion, we have demonstrated mathematically that accurate transverse ROI reconstruction is possible for helical CT, although care must be taken near the interior boundary to achieve quantitative accuracy.", "paperid": 2615988362, "normalizedname_level1": "artificial intelligence"}
{"index": 153, "text": "We present RNNbow, an interactive tool for visualizing the gradient flow during backpropagation training in recurrent neural networks. RNNbow is a web application that displays the relative gradient contributions from Recurrent Neural Network (RNN) cells in a neighborhood of an element of a sequence. We describe the calculation of backpropagation through time (BPTT) that keeps track of itemized gradients, or gradient contributions from one element of a sequence to previous elements of a sequence. By visualizing the gradient, as opposed to activations, RNNbow offers insight into how the network is learning. We use it to explore the learning of an RNN that is trained to generate code in the C programming language. We show how it uncovers insights into the vanishing gradient as well as the evolution of training as the RNN works its way through a corpus.", "paperid": 2909239562, "normalizedname_level1": "artificial intelligence"}
{"index": 154, "text": "Brain functional connectivity has been used to investigate the interaction between brain regions. It provides important information related to brain diseases, injuries, and high level cognitive functions. Statistical methods have been widely used to model brain functional connectivity based upon which insights of brain function are expected to be revealed. Most statistical approaches were developed based upon an assumption that connectivity patterns are static during the recording. This is not true because the connectivity changes over time. A dynamical modeling of connectivity patterns allows to characterize these variations. In this work, a simplified dynamic Bayesian modeling approach, parallel Hidden Markov Model (PaHMM), was investigated by characterizing temporal variations of cortical functional connectivity patterns computed using epileptic electroencephalogram (EEG) data. The performance of the PaHMM was evaluated based on an experimental study of epilepsy detection and classification, where multisubject epileptic EEG data from Temple University Hospital EEG Data Corpus were used. Experimental results show that an accuracy of 93.5% was obtained for the epilepsy detection, and an overall accuracy above 81% was achieved for the seizure type classification. This indicates that the method can efficiently capture temporal variations of functional connectivity patterns, and is potentially applicable in clinical settings to detect epilepsy and differentiate seizure types.", "paperid": 2945272472, "normalizedname_level1": "artificial intelligence"}
{"index": 155, "text": "We propose a spatiotemporal attention based deep neural networks for dimensional emotion recognition in facial videos. To learn the spatiotemporal attention that selectively focuses on emotional sailient parts within facial videos, we formulate the spatiotemporal encoder-decoder network using Convolutional LSTM (ConvLSTM) modules, which can be learned implicitly without any pixel-level annotations. By leveraging the spatiotemporal attention, we also formulate the 3D convolutional neural networks (3D-CNNs) to robustly recognize the dimensional emotion in facial videos. The experimental results show that our method can achieve the state-of-the-art results in dimensional emotion recognition with the highest concordance correlation coefficient (CCC) on RECOLA and AV+EC 2017 dataset.", "paperid": 2887068828, "normalizedname_level1": "artificial intelligence"}
{"index": 156, "text": "This project deals with the detection and prevention the damages in the joints and axle failure of heavy load vehicles. Automobiles that travel long distances in all ways of transport require all the parts to be fixed properly and maintained correctly. In special cases the heavy load vehicles that carry more loads and that travel more distances must need a proper check of vehicles at a correct duration of time. The checking of vehicles at correct durations includes the checking of vehicles at first checks. Hence the bearing capacity of the vehicles will get loosen after some days. The application of sensors and the artificial intelligence coding will definitely help the drivers to check the vehicles daily such that the occurrence of damages in the nuts and bolts and in the axle can be reduced efficiently. It is definitely preventive pokayoke that controls or avoids the faults that are done at times of checks of automobiles in the mechanic sheds using manual components by the human.", "paperid": 2952220553, "normalizedname_level1": "artificial intelligence"}
{"index": 157, "text": "This paper presents a summary of the 2019 Unconstrained Ear Recognition Challenge (UERC), the second in a series of group benchmarking efforts centered around the problem of person recognition from ear images captured in uncontrolled settings. The goal of the challenge is to assess the performance of existing ear recognition techniques on a challenging large-scale ear dataset and to analyze performance of the technology from various viewpoints, such as generalization abilities to unseen data characteristics, sensitivity to rotations, occlusions and image resolution and performance bias on sub-groups of subjects, selected based on demographic criteria, i.e. gender and ethnicity. Research groups from 12 institutions entered the competition and submitted a total of 13 recognition approaches ranging from descriptor-based methods to deep-learning models. The majority of submissions focused on ensemble based methods combining either representations from multiple deep models or hand-crafted with learned image descriptors. Our analysis shows that methods incorporating deep learning models clearly outperform techniques relying solely on hand-crafted descriptors, even though both groups of techniques exhibit similar behavior when it comes to robustness to various covariates, such presence of occlusions, changes in (head) pose, or variability in image resolution. The results of the challenge also show that there has been considerable progress since the first UERC in 2017, but that there is still ample room for further research in this area.", "paperid": 3006425815, "normalizedname_level1": "artificial intelligence"}
{"index": 158, "text": "Functional magnetic resonance imaging (fMRI) is commonly used to better understand brain function. Data becomes contaminated with motion artifact when a subject moves during an fMRI acquisition. Numerous methods have been suggested to target motion artifacts in fMRI. One of these methods, “scrubbing”, removes motion-corrupted volumes but must be performed after temporal filtering since it creates temporal discontinuities. Thus, it does not prevent the spread of corrupted time samples from high motion volumes to their neighbors during temporal filtering. To mitigate this spread, which we refer to as “leakage”, we propose a novel method, Dynamic Missing-data Completion (DMC), that replaces motion-corrupted volumes with synthetic data before temporal filtering. We analyzed the effect of DMC on an exemplary timeseries from a resting state fMRI (rsfMRI) and compared functional connectivity results of six rsfMRI scans from a single subject with different levels of subject motion. Our results suggest that DMC provides added benefit in further reduction of motion contamination that remains after scrubbing. DMC reduced the standard deviation of signal near scrubbed volumes by about 10% compared to scrubbing only, yielding this average closer to that of uncorrupted no motion volumes.", "paperid": 3026943301, "normalizedname_level1": "artificial intelligence"}
{"index": 159, "text": "Sparse representation has shown its merits in solving some classification problems and delivered some impressive results in face recognition. However, the unsupervised optimization of the sparse representation may result in undesired classification outcome if the variations of the data population are not well represented by the training samples. In this paper, a method of class-wise sparse representation (CSR) is proposed to tackle the problems of the conventional sample-wise sparse representation and applied to face recognition. It seeks an optimum representation of the query image by minimizing the class-wise sparsity of the training data. To tackle the problem of the uncontrolled training data, this paper further proposes a collaborative patch (CP) framework, together with the proposed CSR, named CSR-CP. Different from the conventional patch-based methods that optimize each patch representation separately, the CSR-CP approach optimizes all patches together to seek a CP groupwise sparse representation by putting all patches of an image into a group. It alleviates the problem of losing discriminative information in the training data caused by the partition of the image into patches. Extensive experiments on several benchmark face databases demonstrate that the proposed CSR-CP significantly outperforms the sparse representation-related holistic and patch-based approaches.", "paperid": 2324450140, "normalizedname_level1": "artificial intelligence"}
{"index": 160, "text": "For both the automatic and manual reconstruction of neural circuits from electron microscopy (EM) images, the detection and identification of intracellular structures provide useful cues. This is particularly true for microtubules which are indicative of the scaffold of neuronal morphology. However, to our knowledge, the automated reconstruction of microtubules from EM images of neural tissue has received no attention so far. In this paper, we present an automatic method for the tracking of microtubules in 3D EM volumes of neural tissue. We formulate an energy-based model on short candidate segments of microtubules found by a local classifier. We enumerate and score possible links between candidates, in order to find a cost-minimal subset of candidates and links by solving an integer linear program. The model provides a way to incorporate biological priors including both hard constraints (e.g. microtubules are topologically chains of links) and soft constraints (e.g. high curvature is unlikely). We test our method on a challenging EM dataset of Drosophila neural tissue and show that our model reliably tracks microtubules spanning many image sections.", "paperid": 2430091856, "normalizedname_level1": "artificial intelligence"}
{"index": 161, "text": "Visual data such as images and videos are easily accessible nowadays, and they play critical roles in many real-world applications like surveillance. This raises a series of technological demands for automatic visual understanding and content summarization, which has guided the research community to move towards a better achievement of such capabilities. Meanwhile, it presents the big challenge of semantic understanding of video content and automatically translating them into human language. When developing such automatic translation systems, one critical issue is how to bridge the gap between low level features and high level semantic information. Furthermore, as a large amount of videos are captured under unconstrained conditions by nonprofessional users, this issue becomes even more serious. Therefore, brand new sets of technologies are required to address these difficulties and narrow the semantic gap effectively. These thoughts drive us to survey the complete state-of-the-art techniques in the visual to text topic. Existing methods, popular datasets, technical difficulties, and promising future directions are discussed systematically. In particular, we classify existing methods by their mechanism to link visual information (including both images and videos) and text descriptions, and emphasize the latest advances on deep learning based approaches. The quantitative evaluations of representative approaches on benchmark dataset are also presented and discussed. Finally, we provide with the promising research directions on this topic.", "paperid": 2914306086, "normalizedname_level1": "artificial intelligence"}
{"index": 162, "text": "In this paper, a method to segment out gas or steam plumes in IR videos collected from fixed cameras is presented. We propose a spatio-temporal U-Net architecture that captures deforming blobs of gas/steam plumes that have a unique temporal signature. In this task, the blob shapes are not semantically meaningful and change from frame to frame with no consistency across different exemplar plumes; however, there is spatial and temporal continuity in the way blobs deform suggesting a need for a low-level spatio-temporal segmentation network. The proposed method is compared to an LSTM-based segmentation network on a challenging IR video dataset collected in a controlled environment. In the controlled dataset there is motion due to steam plumes with deforming blob patterns as well as due to walking people with more structured high-level patterns. The experiments show that plume patterns are successfully segmented out with no confusion to moving people and the proposed spatiotemporal U-Net outperforms LSTM-based network in terms of pixelwise accuracy of output masks.", "paperid": 2966832627, "normalizedname_level1": "artificial intelligence"}
{"index": 163, "text": "We propose a novel marker for robot's grasping task which has the following three aspects: (i) it is easy-to-find in a cluttered background, (ii) it is calculable for its posture (iii) its size is compact. The proposed marker is composed of a random dots pattern, and uses keypoint detection and a scale estimation by Spectral SIFT for dots detection and data decoding. The data is encoded by the scale size of dots, and the same dots in the marker work for both marker detection and data decoding. As a result, the proposed marker size can be compact. We confirmed the effectiveness of the proposed marker through experiments.", "paperid": 2604250520, "normalizedname_level1": "artificial intelligence"}
{"index": 164, "text": "Automatic identification of potholes on roads is needed to avoid traffic accidents or to ensure better driving comfort. This paper presents a strategy which focuses on the detection of major distress present on a road surface using stereo vision. The proposed strategy performs road-plane modelling directly in the image-disparity space, without back-projecting a disparity image into 3D space. The modelling is based on a RANSAC process that finds the dominating plane for locating potholes being below surface level. We also formulate an alternative implementation using the v-disparity technique. Both implementations are evaluated on an urban dataset which indicates a very high accuracy of our dominating-plane method in terms of pothole detection.", "paperid": 2878996696, "normalizedname_level1": "artificial intelligence"}
{"index": 165, "text": "Transfer learning has proven to be a successful technique to train deep learning models in the domains where little training data is available. The dominant approach is to pretrain a model on a large generic dataset such as ImageNet and finetune its weights on the target domain. However, in the new era of an ever-increasing number of massive datasets, selecting the relevant data for pretraining is a critical issue. We introduce Neural Data Server (NDS), a large-scale search engine for finding the most useful transfer learning data to the target domain. NDS consists of a dataserver which indexes several large popular image datasets, and aims to recommend data to a client, an end-user with a target application with its own small labeled dataset. The dataserver represents large datasets with a much more compact mixture-of-experts model, and employs it to perform data search in a series of dataserver-client transactions at a low computational cost. We show the effectiveness of NDS in various transfer learning scenarios, demonstrating state-of-the-art performance on several target datasets and tasks such as image classification, object detection and instance segmentation. Neural Data Server is available as a web-service at http://aidemo s.cs.toronto.edu/nds/.", "paperid": 3035272520, "normalizedname_level1": "artificial intelligence"}
{"index": 166, "text": "We present a novel radar-based indoor human motion classifier, which employs L1-norm Linear Discriminant Analysis (L1-LDA) to identify low-rank subspaces whereon Doppler signatures from distinct motions are most differentiable. In contrast to standard LDA, L1-LDA exhibits resistance against any outliers that may lie among the training data, e.g., due to mislabeling. Using real data experiments, we show that the proposed method exhibits enhanced performance compared to LDA when the training data are corrupted and similar performance under nominal training.", "paperid": 2886509145, "normalizedname_level1": "artificial intelligence"}
{"index": 167, "text": "Social learning in particle swarm optimization (PSO) helps collective efficiency, whereas individual reproduction in genetic algorithm (GA) facilitates global effectiveness. This observation recently leads to hybridizing PSO with GA for performance enhancement. However, existing work uses a mechanistic parallel superposition and research has shown that construction of superior exemplars in PSO is more effective. Hence, this paper first develops a new framework so as to organically hybridize PSO with another optimization technique for “learning.” This leads to a generalized “learning PSO” paradigm, the *L-PSO. The paradigm is composed of two cascading layers, the first for exemplar generation and the second for particle updates as per a normal PSO algorithm. Using genetic evolution to breed promising exemplars for PSO, a specific novel *L-PSO algorithm is proposed in the paper, termed genetic learning PSO (GL-PSO). In particular, genetic operators are used to generate exemplars from which particles learn and, in turn, historical search information of particles provides guidance to the evolution of the exemplars. By performing crossover, mutation, and selection on the historical information of particles, the constructed exemplars are not only well diversified, but also high qualified. Under such guidance, the global search ability and search efficiency of PSO are both enhanced. The proposed GL-PSO is tested on 42 benchmark functions widely adopted in the literature. Experimental results verify the effectiveness, efficiency, robustness, and scalability of the GL-PSO.", "paperid": 2187537484, "normalizedname_level1": "artificial intelligence"}
{"index": 168, "text": "Online semantic 3D segmentation in company with real-time RGB-D reconstruction poses special challenges such as how to perform 3D convolution directly over the progressively fused 3D geometric data, and how to smartly fuse information from frame to frame. We propose a novel fusion-aware 3D point convolution which operates directly on the geometric surface being reconstructed and exploits effectively the inter-frame correlation for high-quality 3D feature learning. This is enabled by a dedicated dynamic data structure that organizes the online acquired point cloud with local-global trees. Globally, we compile the online reconstructed 3D points into an incrementally growing coordinate interval tree, enabling fast point insertion and neighborhood query. Locally, we maintain the neighborhood information for each point using an octree whose construction benefits from the fast query of the global tree. The local octrees facilitate efficient surface-aware point convolution. Both levels of trees update dynamically and help the 3D convolution effectively exploits the temporal coherence for effective information fusion across RGB-D frames.", "paperid": 3034324855, "normalizedname_level1": "artificial intelligence"}
{"index": 169, "text": "Pulmonary tuberculosis assisted diagnosis technology mainly faces the problems of poor resistance to overfitting due to the small training dataset and the low accuracy of lung tissue interference detection. This paper mainly solves the current problems from two aspects. First, this paper uses the RetinaNet[l] network structure combined with the DenseNet [2] feature extraction network to perform image detection on lung CT targets. Second, this paper enhance the training dataset by increasing the size of the dataset with the method of generative adversarial network to reduce the phenomena such as overfitting in experimental results. After testing on the existing dataset, it was found that the accuracy rate of target detection based on the improved model is 87.32%, which is 70.1% on the original model. Besides, the accuracy rate can be increased to 90.1% by the enhancement of the dataset using generative adversarial network.", "paperid": 3089154071, "normalizedname_level1": "artificial intelligence"}
{"index": 170, "text": "In this work, we propose a regression method to predict the popularity of an online video measured by its number of views. Our method uses Support Vector Regression with Gaussian radial basis functions. We show that predicting popularity patterns with this approach provides more precise and more stable prediction results, mainly thanks to the nonlinear character of the proposed method as well as its robustness. We prove the superiority of our method against the state of the art using datasets containing almost 24 000 videos from YouTube and Facebook. We also show that using visual features, such as the outputs of deep neural networks or scene dynamics’ metrics, can be useful for popularity prediction before content publication. Furthermore, we show that popularity prediction accuracy can be improved by combining early distribution patterns with social and visual features and that social features represent a much stronger signal in terms of video popularity prediction than the visual ones.", "paperid": 3105117297, "normalizedname_level1": "artificial intelligence"}
{"index": 171, "text": "This paper presents novel video feature-based favorite video estimation method. In the proposed method, we use three features, videos, users' viewing behavior and users' evaluation scores for these videos. In order to calculate the novel video features, Multiset Canonical Correlations Analysis (MCCA) is applied to these features to integrate the different types of features. Specifically, MCCA maximizes the sum of three kinds of correlations between three pairs of these features. Then the novel video features that represent the users' individual preference can be obtained by using the projection maximizing the three correlations. Finally, Supported Vector Ordinal Regression (SVOR) is trained by using the novel video features to estimate favorite videos. Experimental results show the effectiveness of our method.", "paperid": 2564213080, "normalizedname_level1": "artificial intelligence"}
{"index": 172, "text": "In the evolving technology of big data, high velocity data streams play a vital role since pattern of data is being changed over time. The temporal pattern change in data stream leads to a concept evolution called concept drift where statistical properties of data differs from time to time and the drift is taken into account in order to update old and outdated classifier and make it adaptable to new data arrival and pattern change over. In order to classify the stream data, a scalable efficient classification algorithm is to be designed which perfectly classifies the data with minimizing misclassification rate in presence of concept drift due to high velocity data. Training time of the classifier must be reduced in order to reduce computational complexity. In this work, a novel algorithm has been implemented using Random Forest with stratified random sampling and Bloom filtering in order to reduce the training time and to handle high velocity data. Experimental results are shown by performing classification with sampling, classification with filtering and classification with sampling and filtering. This enhances the performance of the algorithm by decreasing the training time and testing time of the classifier with negligible compromise in accuracy of classification.", "paperid": 2520303392, "normalizedname_level1": "artificial intelligence"}
{"index": 173, "text": "Visual terrain classification can provide crucial and important information for motion control and autonomous navigation for mobile robots in complex terrain environment, becoming an important but challenging task. This paper uses a novel hybrid coding architecture, Deep Filter Banks (DFB), combining stacked denoising sparse autoencoder (SDSAE) and Fisher Vector (FV) for visual terrain classification. Then, we propose a terrain dataset, termed \"Terrain8\", which is the first publicly available benchmark for visual terrain classification. This dataset contains 2400 terrain images, covering 8 terrain classes with 300 images in each class. Our method achieves superior performance on the Terrain8 dataset. Moreover, we design the framework to deal with terrain videos and carry out the field experiments in arc-legged mobile robot. The field experimental results also indicate the effectiveness of our proposed methods.", "paperid": 3005002749, "normalizedname_level1": "artificial intelligence"}
{"index": 174, "text": "Bees are agents of nature that help provide about one third of the food we eat through a process called pollination. The primary aim of this work is to classify bee species and this was achieved by employing different feature vectors and machine learning algorithms for gathering foraging pattern data, with radio frequency electronic tags glued to the bees' thoraxes. Each time a bee entered or left the hive, the timestamp was stored. The data were analyzed in a time series format, in which the bees' activities were grouped into different categories. The Random Forest algorithm achieved the best results with the area under a ROC curve of 0.94 and 87.41% degree of accuracy, by grouping 12 bees and using 72 attributes.", "paperid": 2897878270, "normalizedname_level1": "artificial intelligence"}
{"index": 175, "text": "Tracking multiple people in a video poses many challenges due to frequent occlusion and false detection. Classification-based methods have proven to increase the accuracy of multiple object tracking algorithms. However, we propose that instead of training person specific classifiers, we can train video specific classifiers for the classification task. We propose a joint classification method for tracking each object as a class. First, we adopt an offline approach that generates tracklets, classify and cluster them for multi-object tracking using the tracklet affinity framework. Typically, clustering is done after the classification to ensure that objects belong to the same class and are linked temporally. Secondly, to determine the identity of each tracklet cluster, we formulate it as a multi-class classification problem with a Bayesian constraint and solve it using the Gaussian pattern classes algorithm. Finally, we perform experiments using four widely used multi-object tracking sequences. The results of our experiment show that our proposed method outperforms several state-of-the-art multi-object tracking algorithms.", "paperid": 2792916839, "normalizedname_level1": "artificial intelligence"}
{"index": 176, "text": "This work presents a superpixel based computer aided diagnosis (CAD) system for brain tumor segmentation, classification, and identification of glioma tumors. It utilizes superpixel and fuzzy c-means clustering concept for tumor segmentation. At first, dataset images are preprocessed by anisotropic diffusion and dynamic stochastic resonance-based enhancement technique and further segmented through the proposed concept. The run length of centralized patterns are extracted from the segmented regions and classified with naive Bayes classifier. The performance of the system is examined on two brain magnetic resonance imaging datasets for segmentation and identification of glioma tumors. Accuracy for tumor detection is observed 99.89% on JMCD dataset and 100% on BRATS dataset. For glioma identification average accuracies are observed as 97.94% and 98.67% on JMCD and BRATS dataset, respectively. The robustness of the system is examined by 10-fold cross validation and statistical testing. Outcomes are also verified by domain experts in real time.", "paperid": 2947151077, "normalizedname_level1": "artificial intelligence"}
{"index": 177, "text": "Evaluating motion quality has many applications in health promotion and exercise coaching. This study aimed to develop an approach for automatic and cost-efficient evaluation on motion quality using the Nintendo Wii Balance Board (WBB) and machine learning techniques. We conducted a pilot study with twelve participants to collect data of chest rotation and hip joint rotation. We used support vector machine for automatic classification of good and poor motions. The preliminary results suggested that using WBB for motion quality evaluation is feasible. Future studies are needed to improve the accuracy of the classification model and to investigate the health impact of the proposed approach.", "paperid": 2775927507, "normalizedname_level1": "artificial intelligence"}
{"index": 178, "text": "The development of Brain-Computer Interface technology nowadays has spread out in a case of classifying emotions based on brain signal (EEG) in human. One of the emotion parameters being focused in this research is arousal with the range from low (uninterested) to high (excited). A total of 32 EEG signals were observed in this study, consisting of 20 signals representing excited conditions and the other 12 being uninterested. This study was applied Principal Component Analysis (PCA) as feature extraction from both EEG signal groups. Then, statistical calculations are applied to reduce the dimensions of features. The support vector machine (SVM) algorithm was used for classification. The results of this preliminary study obtained the highest accuracy of 60% with PCA, entropy, and kurtosis as features.", "paperid": 2997454599, "normalizedname_level1": "artificial intelligence"}
{"index": 179, "text": "Discrepancy check is a well-known task in industrial Augmented Reality (AR). In this paper we present a new approach consisting of three main contributions: First, we propose a new two-step depth mapping algorithm for RGB-D cameras, which fuses depth images with given camera pose in real-time into a consistent 3D model. In a rigorous evaluation with two public benchmarks we show that our mapping outperforms the state-of-the-art in accuracy. Second, we propose a semi-automatic alignment algorithm, which rapidly aligns a reference model to the reconstruction. Third, we propose an algorithm for 3D discrepancy check based on pre-computed distances. In a systematic evaluation we show the superior performance of our approach compared to state-of-the-art 3D discrepancy checks.", "paperid": 2563181633, "normalizedname_level1": "artificial intelligence"}
{"index": 180, "text": "Radiomics-based researches have shown predictive abilities with machine-learning approaches. However, it is still unknown whether different radiomics strategies affect the prediction performance. The aim of this study was to compare the prediction performance of frequently utilized radiomics feature selection and classification methods in glioma grading. Quantitative radiomics features were extracted from tumor regions in 210 Glioblastoma (GBM) and 75 low-grade glioma (LGG) MRI subjects. Then, the diagnostic performance of sixteen feature selection and fifteen classification methods were evaluated by using two different test modes: ten-fold cross-validation and percentage split. Balanced accuracy and area under the curve (AUC) of the receiver operating characteristic were used to evaluate prediction performance. In addition, the roles of the number of selected features, feature type, MRI modality, and tumor sub-region were compared to optimize the radiomics-based prediction. The results indicated that the combination of feature selection method L\n 1\n-based linear support vector machine (L\n 1\n-SVM) and classifier multi-layer perceptron (MLPC) achieved the best performance in the differentiation of GBM and LGG in both ten-fold cross validation (balanced accuracy:0.944, AUC:0.986) and percentage split (balanced accuracy:0.953, AUC:0.981). For radiomics feature extraction, the enhancing tumor region (ET) combined with necrotic and non-enhancing tumor (NCR/NET) regions in T1 post-contrast (T1-Gd) modality provided more considerable tumor-related phenotypes than other combinations of tumor region and MRI modality. Our comparative investigation indicated that both feature selection methods and machine learning classifiers affected the predictive performance in glioma grading. Also, the cross-combination strategy for comparison of radiomics feature selection and classification methods provided a way of searching optimal machine learning model for future radiomics-based prediction.", "paperid": 2962316502, "normalizedname_level1": "artificial intelligence"}
{"index": 181, "text": "Opacity of discrete event systems (DESs) has been well investigated in recent years. However, all the existing researches only focus on crisp models. Note that a lot of practical systems are filled with uncertainties that cannot be accurately characterized by crisp models but can be well handled by fuzzy models. Therefore, the researches of opacity of DESs should be extended to fuzzy models. In this paper, we investigate the opacity of fuzzy DESs, in which both system behaviors and secrets are fuzzy sets rather than crisp sets, and intruders make inferences by means of fuzzy logic instead of classic logic.", "paperid": 2972824175, "normalizedname_level1": "artificial intelligence"}
{"index": 182, "text": "Motivated by the growing evidence for Bayesian computation in the brain, we show how a two-layer recurrent network of Poisson neurons can perform both approximate Bayesian inference and learning for any hidden Markov model. The lower-layer sensory neurons receive noisy measurements of hidden world states. The higher-layer neurons infer a posterior distribution over world states via Bayesian inference from inputs generated by sensory neurons. We demonstrate how such a neuronal network with synaptic plasticity can implement a form of Bayesian inference similar to Monte Carlo methods such as particle filtering. Each spike in a higher-layer neuron represents a sample of a particular hidden world state. The spiking activity across the neural population approximates the posterior distribution over hidden states. In this model, variability in spiking is regarded not as a nuisance but as an integral feature that provides the variability necessary for sampling during inference. We demonstrate how the network can learn the likelihood model, as well as the transition probabilities underlying the dynamics, using a Hebbian learning rule. We present results illustrating the ability of the network to perform inference and learning for arbitrary hidden Markov models.", "paperid": 2466244790, "normalizedname_level1": "artificial intelligence"}
{"index": 183, "text": "To meet the growing electricity demand for consumers, it is necessary to use more efficient systems. The solar trackers stand out among the applications that can improve the efficiency of photovoltaic panel generation by increasing their solar uptake. For solar trackers to be more efficient, they can base their position update on a generation forecast and thus perform the control action only when there is greater efficiency in this update. For generation forecast, the long–short-term memory (LSTM) can handle a large volume of non-linear data. Furthermore, to improve the analysis, it is possible to apply signal filtering techniques. The wavelet energy coefficient is a technique used to reduce signal noise and extract features; this technique performs the filter and preserves the signal characteristic. In this study, the authors present a combination of wavelet energy coefficient and LSTM, defined as wavelet LSTM, to perform photovoltaic power forecasting in the dual-axis solar trackers.", "paperid": 3097203985, "normalizedname_level1": "artificial intelligence"}
{"index": 184, "text": "Long-term visual localization is the problem of estimating the camera pose of a given query image in a scene whose appearance changes over time. It is an important problem in practice that is, for example, encountered in autonomous driving. In order to gain robustness to such changes, long-term localization approaches often use segmantic segmentations as an invariant scene representation, as the semantic meaning of each scene part should not be affected by seasonal and other changes. However, these representations are typically not very discriminative due to the very limited number of available classes. In this paper, we propose a novel neural network, the Fine-Grained Segmentation Network (FGSN), that can be used to provide image segmentations with a larger number of labels and can be trained in a self-supervised fashion. In addition, we show how FGSNs can be trained to output consistent labels across seasonal changes. We show through extensive experiments that integrating the fine-grained segmentations produced by our FGSNs into existing localization algorithms leads to substantial improvements in localization performance.", "paperid": 2981381717, "normalizedname_level1": "artificial intelligence"}
{"index": 185, "text": "Subretinal stimulators help restoring vision to blind people, suffering from degenerative eye diseases. This work aims to reduce patient’s efforts to continuously tune his device, by implementing a physiological ambient illumination adaptation system. The parameters of the adaptation to changing illumination conditions are highly customizable, to best fit individual patients requirements.", "paperid": 3081690977, "normalizedname_level1": "artificial intelligence"}
{"index": 186, "text": "Prediction of the response to cardiac resynchronization therapy (CRT) is still uncertain. On our previous CRT clinical research, we have found that a decrease in the ratio between the two principal axes of the 3D trajectory of the electrode at the pacing site (S 1 /S 2 ) recorded before and after pacing could define a marker between responders and non-responders to CRT. The aim of this work is to design a framework to map the S 1 /S 2  marker on the 3D ventricular anatomy as a preliminary test to verify if the concept of the S 1 /S 2  may predict the response to CRT in a pre-implant scenario. Based on MR images of a CRT candidate, the 3D mesh of the left ventricle geometry is constructed. Using image registration we are able to track the deformation of the mesh throughout the cardiac cycle and to compute the trajectory of each point of the mesh. Then the S/S 2  is calculated for every trajectory and mapped on a 3D geometry representation. We have applied this framework to one CRT patient, highlighting that in the area in which the electrode was placed the S/S 2  was low. This value suggests a poor possibility of a pacing-induced decrease for the S 1 /S 2  ratio after implant. Consistently the patient was classified as non-responder at the clinical follow-up. Ongoing work focuses on the clinical validation of S 1 /S 2  as a tool for the prediction of CRT response and the acquisition of MR data of potential candidates to CRT for the assessment of the presented framework.", "paperid": 2794648843, "normalizedname_level1": "artificial intelligence"}
{"index": 187, "text": "In this paper, a new collaborative tracking algorithm is put forward to track multiple objects in video streams. First, we suggest a robust color-based tracker whose model is updated by online learned contextual information. A recursive method is performed to improve the estimation accuracy and the robustness to cluttered environment. Then, we extend this tracker to multiple targets. To avoid the problem of id-switch in long-term occlusion, we design a hierarchical tracking system with different tracking priorities. First, the algorithm employs an adaptive collision prevention model to separate the nearby trajectories. When the inter-occlusion happens, the holistic model of tracker splits into several parts, and we use the visible parts to perform tracking as well as occlusion reasoning. In the case where the targets have close appearance models, a trajectory monitoring approach is employed to handle the occlusion. Once the tracker is fully occluded, the algorithm will reinitialize particles around the occluder to capture the reappeared target. Experimental results using open dataset demonstrate the feasibility of our proposal. In addition, comparison with several state-of-the-art trackers has also been performed.", "paperid": 2057293215, "normalizedname_level1": "artificial intelligence"}
{"index": 188, "text": "The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.", "paperid": 2579161546, "normalizedname_level1": "artificial intelligence"}
{"index": 189, "text": "Studying behaviors of members during small group interaction provides objective insights in improving the efficiency of the decision making process in our daily working life. By introducing the use of the graph structure in modeling the natural inter-member conversational ties during such an interaction, we aim to advance the state-of-art computational approach in predicting group performance scores. Specifically, we proposed a Conversational Graph Convolutional Network (CGCN) that utilizes conversation dynamic as the graph to aggregate group member's speech and lexical behaviors in predicting the group performance. Our result shows that Speech CGCN achieves the state-of-the-art performance at MSE 3.896 (0.323 Pearson correlation) outperform the current best method in ELEA dataset. Our model additionally reveals that an imbalance conversational graph structure is positively correlated to group performances.", "paperid": 3015447373, "normalizedname_level1": "artificial intelligence"}
{"index": 190, "text": "Spectral cameras are a valuable tool for anomaly detection because the spectral information provides more opportunities than a monochrome or color camera to distinguish targets from the background. We are currently working on the adaptation of a spectral line camera for outdoor use and for anomaly detection. This requires consideration of spectral calibration, lighting variation and adaptation of detection algorithms. When effective, this may provide a low coast alternative for full spectral detection.", "paperid": 2536164950, "normalizedname_level1": "artificial intelligence"}
{"index": 191, "text": "Image segmentation is a ubiquitous step in almost any medical image study. Deep learning-based approaches achieve state-of-the-art in the majority of image segmentation benchmarks. However, end-to-end training of such models requires sufficient annotation. In this paper, we propose a method based on conditional Generative Adversarial Network (cGAN) to address segmentation in semi-supervised setup and in a human-in-the-loop fashion. More specifically, we use the generator in the GAN to synthesize segmentations on unlabeled data and use the discriminator to identify unreliable slices for which expert annotation is required. The quantitative results on a conventional standard benchmark show that our method is comparable with the state-of-the-art fully supervised methods in slice-level evaluation, despite of requiring far less annotated data.", "paperid": 3016052689, "normalizedname_level1": "artificial intelligence"}
{"index": 192, "text": "Motion blur and out-of-focus blur are two main components of image blur in most cases. Blur classification and parameter identification are very important for image processing such as image restoration. In this paper, a novel method based on cepstrum peak detection is presented to classify and identify three types of image blur including motion blur, out-of-focus blur and mixed blur. First, frequency information of detected image is utilized to determine the image blur. Then we classify the image blur in cepstrum domain. Next the parameters of image blur are identified according to the peak distribution of blurred image in cepstrum domain. Lastly, extensive experiments are carried out to verify the performance of our algorithm. Experiment results show that our method leads to performance improvements over state-of-the-arts methods.", "paperid": 2507910640, "normalizedname_level1": "artificial intelligence"}
{"index": 193, "text": "Research into deep learning techniques for stock price trend identification is limited. This can partly be attributed to the aversion of technical analysis within the academic community. One popular investment strategy that has been accepted by both academics and professionals, based purely on historical prices, is price momentum. However, the recent performance of this strategy has been disappointing. In this paper, we construct a new framework integrating state-of-the-art deep learning and machine learning methods to identify price trends of US equities: a \"deep learning price momentum\" portfolio. We first replicate the conventional price momentum calculations and compare the results with the market benchmarks and standard implementations of deep learning. We examine the issues of applying standard deep learning techniques to a limited noisy data set. Then we propose a new modular approach, built on deep learning clustering methods and recurrent neural networks that shows significant improvement on conventional price momentum while addressing the deficiencies of conventional deep learning methods. While the best-performing conventional price momentum portfolio yields 12.88% annual return and -0.49% market neutral annual returns for the 15-year period (2003 - 2017), our model improves these to 15.44% and +1.93% respectively with a significantly enhanced Sharpe ratio.", "paperid": 2978685566, "normalizedname_level1": "artificial intelligence"}
{"index": 194, "text": "With the advancement of science and the development of the times, the role of identity authentication technology in living society has become increasingly prominent. Palm vein recognition has become a popular research in biometric recognition due to its unforgeable characteristics. Aiming at the complex design of palm vein recognition based on traditional feature engineering methods, this paper proposes to use the deep features of convolutional neural network fused with hog features to identify palm vein. Experiments show that this method has achieved both higher speed and accuracy on two different databases, which achieves the recognition accuracy of 99.25% on CASIA and 99.90% on PolyU respectively.", "paperid": 3106673152, "normalizedname_level1": "artificial intelligence"}
{"index": 195, "text": "Our research aims at making a mock-up of a multi grip tool for a robotic assistive device and a camera system which enable frail elderly to live more independently and to keep track of their food intake. In this research, the development of a vision-based feature extraction for food intake report for a robotic assistive eating device is introduced. The proposed vision system is composed by a RGB-D camera and the eating aid device Bestic. In this paper, the authors proposed an algorithm for estimating the amount of intake food (e.g. candies) after the end of the meal. The proposed vision-based feature extraction was designed and implemented in order to take pictures of the plate during the meal as well as estimate the amount of intake food. A set experiments were carried out in order to verify the performance of the proposed vision system while estimating the amount of intake food with different amount of multicoloured candies as well as different light conditions. Based on the experimental results, we could verify the system performance is not affected by the amount of candies as well as the light conditions.", "paperid": 2905294891, "normalizedname_level1": "artificial intelligence"}
{"index": 196, "text": "The Microsoft Kinect RGB-D sensor has been proven to be a reliable tool for gait analysis and rehabilitation purposes. Although it is accurate for detecting upper body part movements, even the second iteration of the Kinect sensor lacks the accuracy when it comes to lower extremities. while detecting foot-off and foot contact phases of a gait cycle is an important part of a gait performance analysis, The Kinect's intrinsic inaccuracies make it an unreliable tool to detect them accurately. We propose a new Kinect based technique for detecting foot-off and foot contact phases in a gait cycle that solely relies on a subject's knee joint relative angle. The system was tested on 11 healthy subjects walking in pre-defined pathways in 12 walking sessions while the Kinect v2 camera was placed at different heights ranging from 0.65 to 1.57 and angles ranging from 0 to 45 degrees to the ground. The algorithm's accuracy was also compared to another footstep detection method based on the subject's ankle joints height to the ground. The results showed 86.52% accuracy in detecting foot-off and foot contact events on average for both feet.", "paperid": 2607433989, "normalizedname_level1": "artificial intelligence"}
{"index": 197, "text": "Unsupervised learning is of growing interest because it unlocks the potential held in vast amounts of unlabeled data to learn useful representations for inference. Autoencoders, a form of generative model, may be trained by learning to reconstruct unlabeled input data from a latent representation space. More robust representations may be produced by an autoencoder if it learns to recover clean input samples from corrupted ones. Representations may be further improved by introducing regularization during training to shape the distribution of the encoded data in the latent space. We suggest  denoising adversarial autoencoders  (AAEs), which combine denoising and regularization, shaping the distribution of latent space using adversarial training. We introduce a novel analysis that shows how denoising may be incorporated into the training and sampling of AAEs. Experiments are performed to assess the contributions that denoising makes to the learning of representations for classification and sample synthesis. Our results suggest that autoencoders trained using a denoising criterion achieve higher classification performance and can synthesize samples that are more consistent with the input data than those trained without a corruption process.", "paperid": 2964049407, "normalizedname_level1": "artificial intelligence"}
{"index": 198, "text": "In this paper, we introduce a novel recommendation model, which harnesses a convolutional neural network to mine meaningful information from customer reviews, and integrates it with matrix factorization algorithm seamlessly. It is a valid method to improve the transparency of CF algorithms.", "paperid": 2790271700, "normalizedname_level1": "artificial intelligence"}
{"index": 199, "text": "An end-to-end CNN-LSTM network with salient feature attention and context-guided feature selection mechanism for robust visual odometry (VO) on monocular image sequence is developed in this paper. Deep learning-based visual odometry methods have drawn significant concerns comparing with traditional methods. Existing learning-based VO methods usually ignored the redundant features would increase error accumulation, and their rotational and translational motion parameters coupling would enlarge trajectory drift. A scheme on enhancing the visual salient features and decoupling motion parameters to alleviate these problems is investigated in our approach. The classical FlowNet paralleled with a VGG-based salient feature model to reinforce perceptive fields is designed based on an attention mechanism to extract the prominent geometric features from successive monocular images. Furthermore, to reduce the coupling of different motion patterns, a motion decoupled dual Long Short-Term Memory (LSTM) scheme based on guided feature selection mechanism is designed to select guided features to separately regress rotational and translational parameters. Experiments on KITTI dataset show competitive performance of the proposed approach compared with state-of-the-art deep learning based visual odometry methods.", "paperid": 3002320576, "normalizedname_level1": "artificial intelligence"}
{"index": 200, "text": "Virtual Reality (VR), which brings immersive experiences to viewers, has been gaining popularity in recent years. A key feature in VR systems is the use of omnidirectional content, which provides 360-degree views of scenes. In this work, we study the human quality perception of omnidirectional images, focusing on different zones surrounding the foveation point. For that purpose, an extensive subjective experiment is carried out to assess the perceptual quality of omnidirectional images with non-uniform quality. Through experimental results, the impacts of different zones are analyzed. Moreover, twenty-five objective quality metrics, including foveal quality metrics, are evaluated using our database. It is quantitatively shown that the zones corresponding to the fovea and parafovea of human eyes are extremely important for quality perception, while the impacts of the other zones corresponding to the perifovea and periphery are small. Besides, most of the investigated metrics are found to be not effective enough to reflect the quality perceived by viewers. Our database has been made available to the public.", "paperid": 2968943126, "normalizedname_level1": "artificial intelligence"}
{"index": 201, "text": "To verify and validate networks, it is essential to gain insight into their decisions, limitations as well as possible shortcomings of training data. In this work, we propose a post-hoc, optimization based visual explanation method, which highlights the evidence in the input image for a specific prediction. Our approach is based on a novel technique to defend against adversarial evidence (i.e. faulty evidence due to artefacts) by filtering gradients during optimization. The defense does not depend on human-tuned parameters. It enables explanations which are both fine-grained and preserve the characteristics of images, such as edges and colors. The explanations are interpretable, suited for visualizing detailed evidence and can be tested as they are valid model inputs. We qualitatively and quantitatively evaluate our approach on a multitude of models and datasets.", "paperid": 2982560934, "normalizedname_level1": "artificial intelligence"}
{"index": 202, "text": "Due to the increase in the number of people participating online on reviewing travel related entities such as hotels, cities and attractions, there is a rich corpus of textual information available online. However, to make a decision on a certain entity, one has to read many such reviews manually, which is inconvenient. To make sense of the reviews, the essential first step is to understand the semantics that lie therein. This paper discusses a system that uses machine learning based classifiers to label the entities found in text into semantic concepts defined in an ontology. A subject classifier with a precision of 0.785 and a sentiment classifier with a correlation coefficient of 0.9423 was developed providing sufficient accuracy for subject categorization and sentiment evaluation in the proposed system.", "paperid": 2410328719, "normalizedname_level1": "artificial intelligence"}
{"index": 203, "text": "Deep neural network based methods have made a significant breakthrough in salient object detection. However, they are typically limited to input images with low resolutions (400×400 pixels or less). Little effort has been made to train neural networks to directly handle salient object segmentation in high-resolution images. This paper pushes forward high-resolution saliency detection, and contributes a new dataset, named High-Resolution Salient Object Detection (HRSOD) dataset. To our best knowledge, HRSOD is the first high-resolution saliency detection dataset to date. As another contribution, we also propose a novel approach, which incorporates both global semantic information and local high-resolution details, to address this challenging task. More specifically, our approach consists of a Global Semantic Network (GSN), a Local Refinement Network (LRN) and a Global-Local Fusion Network (GLFN). The GSN extracts the global semantic information based on downsampled entire image. Guided by the results of GSN, the LRN focuses on some local regions and progressively produces high-resolution predictions. The GLFN is further proposed to enforce spatial consistency and boost performance. Experiments illustrate that our method outperforms existing state-of-the-art methods on high-resolution saliency datasets by a large margin, and achieves comparable or even better performance than them on some widely used saliency benchmarks.", "paperid": 2989161706, "normalizedname_level1": "artificial intelligence"}
{"index": 204, "text": "Tumor refers to the swelling of particular region which is caused due to the excessive growth of tissue. The initial stage is refereed as benign stage and the developed stage of tumor is called as malignant stage. In this work, an efficient segmentation followed by the classification of MRI is done with the aid of Self Organizing Map is proposed, the accuracy is quantified using classification accuracy. The classification accuracy obtained using Self Organizing Map is 97% which is comparatively better than the existing technique such as Random Forest Classifier.", "paperid": 2981997307, "normalizedname_level1": "artificial intelligence"}
{"index": 205, "text": "Prevalent techniques in zero-shot learning do not generalize well to other related problem scenarios. Here, we present a unified approach for conventional zero-shot, generalized zero-shot and few-shot learning problems. Our approach is based on a novel Class Adapting Principal Directions (CAPD) concept that allows multiple embeddings of image features into a semantic space. Given an image, our method produces one principal direction for each seen class. Then, it learns how to combine these directions to obtain the principal direction for each unseen class such that the CAPD of the test image is aligned with the semantic embedding of the true class, and opposite to the other classes. This allows efficient and class-adaptive information transfer from seen to unseen classes. In addition, we propose an automatic process for selection of the most useful seen classes for each unseen class to achieve robustness in zero-shot learning. Our method can update the unseen CAPD taking the advantages of few unseen images to work in a few-shot learning scenario. Furthermore, our method can generalize the seen CAPDs by estimating seen-unseen diversity that significantly improves the performance of generalized zero-shot learning. Our extensive evaluations demonstrate that the proposed approach consistently achieves superior performance in zero-shot, generalized zero-shot and few/one-shot learning problems.", "paperid": 2724492314, "normalizedname_level1": "artificial intelligence"}
{"index": 206, "text": "The change information of sea ice is important for navigation safety and natural resource extraction, and polar sea ice monitoring has drawn increasing attentions. In this paper, we focus on the problem of sea ice change detection from Synthetic Aperture Radar (SAR) images. Existing works usually treat the problem as a classification task. Recently, researchers noticed that humans and animals learn much better when the examples are organized in a meaningful order, and proposed Self-Paced Boost Learning (SPBL) to simulate the process. Inspired by this, we proposed a novel sea ice change detection method based on SPBL. First, log-ratio operator is utilized for difference image generation. Then, a hierarchical fuzzy c-means (FCM) clustering algorithm is employed to select reliable samples. Finally, based upon these samples, SPBL is employed to classify pixels from the original SAR images into unchanged and changed class. The quantitative and qualitative analysis on two real SAR datasets has demonstrated the effectiveness of the proposed method.", "paperid": 2910728227, "normalizedname_level1": "artificial intelligence"}
{"index": 207, "text": "Cytogenetics plays significant role in the diagnosis, prognosis and treatment evaluation of genetic disorders through chromosome image analysis technique called karyotyping. Karyotyping is the way by which chromosomes are classified into 24 classes. Digital image processing techniques and machine learning algorithms found its scope in automated karyotyping since they ease or eliminate manual efforts in chromosome classification and its analysis. Even though, researchers were putting great efforts in the design of Automated Karyotyping System (AKS), for the last three decades, a fully automated system is not yet routinely accepted in practice. These days, deepnets exhibit improved performance in computer vision tasks, they are progressively utilized for automating classification tasks as well. Here, two variants of deep Convolutional Neural Networks (CNNs) for chromosome classification are modelled. A preliminary study on the hyperparameters of these models has been conducted. Other state-of-the-art CNN models are experimented and analyzed for chromosome classification. Performance measures of all these CNN deep models are compared to formulate hypotheses on hyperparameters to classify chromosomes efficiently.", "paperid": 3092047358, "normalizedname_level1": "artificial intelligence"}
{"index": 208, "text": "People suffering from mild cognitive impairment (MCI) are at an increased risk of developing Alzheimer’s disease (AD) or another dementia. High prevalence will possibly be reduced if early interventions could be applied to the stage of early MCI (eMCI). In network-based classification, brain functional networks are often constructed, relying on the entire time series. It can lead to the neglect of the complex and dynamic interaction relationships among brain regions. As a result, the features derived from this type of functional network may fail to serve as an effective disease biomarker. To address this problem, we proposed a multi-scale feature combination framework for the eMCI classification. In this framework, global static features, time-varying features, and more refined features could be able to flexibly extract from static functional networks, dynamic functional networks, and high-order functional networks, respectively. Then, they are utilized to train and test the classification model in the form of feature combination. The experimental results have verified that the proposed method achieves superior classification accuracy than other competed methods in the eMCI classification, indicating a great potential in understanding the dysfunction of the brain regions.", "paperid": 2948884513, "normalizedname_level1": "artificial intelligence"}
{"index": 209, "text": "In this paper we present an embedded smart cameras system that performs multiple objects tracking for the control of an automated conveying system. The smart cameras automatically extract scene description models of the conveying environment from underlying motion structure, as observed over time. In particular, the ROI mask and the conveyor's pathways model are used to improve the tracking performance during on-line inference. An efficient parallelization strategy of background subtraction is proposed. Our approach takes advantage of multi-core embedded platforms. We provide an evaluation of the proposed method on videos coming from an industrial application.", "paperid": 2768445591, "normalizedname_level1": "artificial intelligence"}
{"index": 210, "text": "3D ultrasound (US) requires expensive transducers comprising thousands of elements and complicated hardware. This complexity originates from the classical idea on spatial sampling requirements for US imaging. The discovery of compressive sensing allows to ease this sampling constraint, enabling smarter ways of recording the required information. Inspired by this work we introduce a US imager that can perform 3D imaging using one acoustic sensor. Our device sends and detects US waves through a random coding mask that enables unique signals at every voxel. Rotation of the mask allows for several compressed measurements. By knowing the voxel signals, a full 3D reconstruction of the object can be obtained, as we demonstrate in this work.", "paperid": 2770055606, "normalizedname_level1": "artificial intelligence"}
{"index": 211, "text": "A comparative analysis to determine the most effective video watermarking algorithm between SVD/DWT hybrid and Singular Value Decomposition (SVD) is reported in this paper. Blind video watermarking schemes are simulated and attempts made to recover the watermark after some signal processing attacks such as median filtering and Histogram equalization. The quality of the extracted watermark was then measured using the SSIM index. From the computer simulation results using a diverse set of standard video clips the SVD/DWT hybrid performed better than the reference. An average value of the SSIM index of 0.98 was obtained. The SVD transform values varied from 0.57 to 0.78 for histogram equalization attacks and 0.83 to 0.9 for median filtering attacks. The results reveal the superiority of the SVD/DWT hybrid technique over SVD for digital rights enforcement.", "paperid": 2768485876, "normalizedname_level1": "artificial intelligence"}
{"index": 212, "text": "The prevalence of sleep apnea hypopnea syndrome (SAHS) is increasing year by year and up to 14% in 2016. The disease poses a threat to human sleep safe. To detect the disease effectively and pre-alert, a method for the diagnosis of SAHS using respiratory signals was proposed. According to the characteristics of respiratory signal, nonlinear characteristics fractal dimension and sample entropy were introduced based on time-domain characteristics variance and clinical zero passing numbers as well as frequency-domain characteristics wavelet coefficients and wavelet energy. Then a 6-dimension feature vector was structured and input into the support vector machine (SVM), back propagation neural network (BPNN) and improved back propagation neural network (IBPNN) based on morphology. The method was verified by the 8 sets data including 3840 samples of the Physionet Apnea Database. Experimental results showed that classification accuracy of SVM and BPNN was 71.2% and 84.5% respectively. The IBPNN based on morphology improved the 85% of classification results and increased accuracy by 7.3%. It is very effective to detect the SAHS using the feature vector and IBPNN based on morphology proposed in this paper and provide an efficient and convenient method for the diagnosis of diseases.", "paperid": 2910072397, "normalizedname_level1": "artificial intelligence"}
{"index": 213, "text": "In this paper, we presented a novel solution using ensemble empirical mode decomposition and support vector machine joint approach to efficiently identify the multiple coexisting faults in the operational rotational machinery. To further improve the performance of SVM models, the EEMD is used to decompose the collected field vibration signals into a set of intrinsic mode functions (IMFs). The presented approach is validated using simulation experiments based on the benchmark vibration data. The numerical result confirmed the feasibility and effectiveness of the proposed solution..", "paperid": 3006665494, "normalizedname_level1": "artificial intelligence"}
{"index": 214, "text": "We propose an end-to-end place recognition model based on a novel deep neural network. First, we propose to exploit the spatial pyramid structure of the images to enhance the vector of locally aggregated descriptors (VLAD) such that the enhanced VLAD features can reflect the structural information of the images. To encode this feature extraction into the deep learning method, we build a spatial pyramid-enhanced VLAD (SPE-VLAD) layer. Next, we impose weight constraints on the terms of the traditional triplet loss (T-loss) function such that the weighted T-loss (WT-loss) function avoids the suboptimal convergence of the learning process. The loss function can work well under weakly supervised scenarios in that it determines the semantically positive and negative samples of each query through not only the GPS tags but also the Euclidean distance between the image representations. The SPE-VLAD layer and the WT-loss layer are integrated with the VGG-16 network or ResNet-18 network to form a novel end-to-end deep neural network that can be easily trained via the standard backpropagation method. We conduct experiments on three benchmark data sets, and the results demonstrate that the proposed model defeats the state-of-the-art deep learning approaches applied to place recognition.", "paperid": 2940791172, "normalizedname_level1": "artificial intelligence"}
{"index": 215, "text": "Reward engineering is crucial to high performance in reinforcement learning systems. Prior research into reward design has largely focused on Markovian functions representing the reward. While there has been research into expressing non-Markov rewards as linear temporal logic (LTL) formulas, this has focused on task specifications directly defined by the user. However, in many real-world applications, task specifications are ambiguous, and can only be expressed as a belief over LTL formulas. In this letter, we introduce planning with uncertain specifications (PUnS), a novel formulation that addresses the challenge posed by non-Markovian specifications expressed as beliefs over LTL formulas. We present four criteria that capture the semantics of satisfying a belief over specifications for different applications, and analyze the qualitative implications of these criteria within a synthetic domain. We demonstrate the existence of an equivalent Markov decision process (MDP) for any instance of PUnS. Finally, we demonstrate our approach on the real-world task of setting a dinner table automatically with a robot that inferred task specifications from human demonstrations.", "paperid": 3103548289, "normalizedname_level1": "artificial intelligence"}
{"index": 216, "text": "This paper presents a method for identification of fuzzy classifiers by means of data analysis. The method is based on the assumption that the data of the same classes form compact regions (clusters) in the input space. The algorithms for structure generation and parameter optimization of the fuzzy classifiers are proposed.", "paperid": 2744802393, "normalizedname_level1": "artificial intelligence"}
{"index": 217, "text": "Real-time 6DOF (6 Degree of Freedom) pose estimation of an uncooperative spacecraft is an important part of proximity operations, e.g., space debris removal, spacecraft rendezvous and docking, on-orbit servicing, etc. In this article, a novel efficient deep learning based approach is proposed to estimate the 6DOF pose of uncooperative spacecraft using monocular-vision measurement. Firstly, we introduce a new lightweight YOLO-liked CNN to detect spacecraft and predict 2D locations of the projected keypoints of a prior reconstructed 3D model in real-time. Then, we design two novel models for predicting the bounding box (bbox) reliability scores and the probability of keypoints existence. The two models not only significantly reduce the false positive, but also speed up convergence. Finally, the 6DOF pose is estimated and refined using Perspective-n-Point and geometric optimizer. Results demonstrate that the proposed approach achieves 73.2% average precision and 77.6% average recall for spacecraft detection on the SPEED dataset after only 200 training epochs. For the pose estimation task, the mean rotational error is 0.6812°, and the mean translation error is 0.0320m. The proposed approach achieves competitive pose estimation performance and extreme lightweight (   $\\sim ~0.89$    million learnable weights in total) on the SPEED dataset while being efficient for real-time applications.", "paperid": 3108463056, "normalizedname_level1": "artificial intelligence"}
{"index": 218, "text": "Currently, the most widely adopted fall prediction methods use kinematic sensors for data collection and set thresholds to identify a fall based on artificial experience or neural network learning algorithms. These methods require classification and calibration in advance. Striking a balance between sensitivity and specificity is difficult when setting thresholds. Backpropagation (BP), support vector machines (SVMs) and other neural network algorithm models require professional expertise and are too complicated, difficult to understand, and computationally expensive, which renders embedded development with these models difficult. In response to these problems, this paper builds a fuzzy logic-enhanced adaptive neural network classifier (FLEANN); uses the prior knowledge of experts to construct fuzzy rules; employs neural networks to drive the underlying data to confirm and optimize logical rules; and utilizes an adaptive fuzzy neural network. The parameters of the algorithm are modified and optimized using a large amount of data training to improve the heuristics, transparency, and robustness of the neural network. The enhanced adaptive fuzzy neural network is applied in rehabilitation training for the classification of imprecise, uncertain, and nonlinear falls; abnormal gait; and normal gait. The experimental results confirm that the accuracy of this classifier is better than that of conventional neural network classifiers and that its logical structure is clear, which enables its application to embedded development. The reduction in computational demand enables the elimination of high-configuration PCs and reliance on a single chip microcomputer.", "paperid": 3011102476, "normalizedname_level1": "artificial intelligence"}
{"index": 219, "text": "Feedback data from the environment regulate the control systems in characterization and decision making in the applications of robotics and automation in industries. Machine vision being non-touching in nature, provides useful information about the targets and surroundings, catering to a variety of applications. Closed loop robotic applications find visual servoing as a potent and efficient tool interactions with the environment. This paper aims at developing a process control-like model for visual servoing. The inherent drawbacks of image based visual servoing can be explained with variable interaction and Relative Gain Array (RGA) is a useful tool for evaluating the system.", "paperid": 3020640946, "normalizedname_level1": "artificial intelligence"}
{"index": 220, "text": "Deep structures consisting of many layers of nonlinearities have a high potential of expressing complex relations if properly initialized. Autoencoders play a complementary role in training a deep structure by initializing each layer in a greedy unsupervised manner. Due to the high capacity presented by autoencoders, these structures need to be regularized. While mathematical regularizers (based on weight decay, sparsity, etc.) and structural ones (by way of, e.g., denoising and dropout) have been well studied in the literature, quite a few papers have addressed the problem of training autoencoder with non-smooth regularization. In this paper, we address the problem of training autoencoder with non-smooth regularization. We propose an efficient algorithm and mathematically prove that it is convergent, where the regularizer needs to be proximable. As one of major applications of the proposed method, we get focused on the problem of sparse autoencoders and show that the new training method leads to better disentangling of factors of variation.", "paperid": 2912744108, "normalizedname_level1": "artificial intelligence"}
{"index": 221, "text": "Robustness and discrimination are two of the most important objectives in image hashing. We incorporate ring partition and invariant vector distance to image hashing algorithm for enhancing rotation robustness and discriminative capability. As ring partition is unrelated to image rotation, the statistical features that are extracted from image rings in perceptually uniform color space, i.e., CIE L*a*b* color space, are rotation invariant and stable. In particular, the Euclidean distance between vectors of these perceptual features is invariant to commonly used digital operations to images (e.g., JPEG compression, gamma correction, and brightness/contrast adjustment), which helps in making image hash compact and discriminative. We conduct experiments to evaluate the efficiency with 250 color images, and demonstrate that the proposed hashing algorithm is robust at commonly used digital operations to images. In addition, with the receiver operating characteristics curve, we illustrate that our hashing is much better than the existing popular hashing algorithms at robustness and discrimination.", "paperid": 2183964636, "normalizedname_level1": "artificial intelligence"}
{"index": 222, "text": "As massive open online courses (MOOCs) and online intelligent tutoring systems(ITS) have become increasingly widespread, the number of learners enrolled in online courses has shown explosive growth. However, these learners are likely to have acquired knowledge from diverse educational and vocational backgrounds. Therefore, it is unwise to apply the same criteria and assessment questions to assess all learners' abilities without differentiation. Therefore, the demand for the adaptive arrangement of questions for online learners is ever critical. Deep learning is a new increasingly popular approach for handling extraordinarily complex problems such as image recognition and natural language processing. In this research, we use neural networks to forecast learners' multi-question performance on new test questions and propose a new concept called predictable property for the first time to explain the reasons why neural networks can be applied to predict learners' multi-question performance based on their previous question responses. This approach means that fewer questions need to be answered by learners although more information can be gathered about them through the use of deep-learning-based techniques. Finally, we use both artificial datasets generated by cognitive models and three real-world datasets to validate the algorithm's performance. Experiments show a promising research result when using deep learning to predict learner performance in multi-question tasks and can ultimately provide more accurate adaptive tests for learners.", "paperid": 2800468020, "normalizedname_level1": "artificial intelligence"}
{"index": 223, "text": "The number of mobile devices used in the K-12 learning space has been growing steadily. Most school-issued devices that connect to the Internet are required to have web filters installed on them. These web filters are designed to filter out inappropriate content and log student activity online. This study investigates student web query logs and classifies their web queries as either school related or non-school related to provide potentially valuable information on student learning. This process is similar to that used by the major search engines - Google, Yahoo and Bing - that generate billions of dollars in ad revenue by classifying web queries into appropriate categories to display advertisements. A new algorithm, Student Web Query Classifier, is presented for the binary classification of high school student web queries as school related or non-school related. Additionally, a proposed procedure is presented to build a corpus of school-related terms and to compare it against students' online activity. The new algorithm presented in this paper yielded 90.68% accuracy, far superior than results obtained from supervised learning algorithms Naive Bayes and Support Vector Machines.", "paperid": 2594378697, "normalizedname_level1": "artificial intelligence"}
{"index": 224, "text": "Metacognition has been used in artificial intelligence to increase the level of autonomy of intelligent systems. However the design of systems with metacognitive skills is a difficult task due to the number and complexity of processes involved. This paper describes a MOF-based visual metacognitive modeling tool named MetaThink. MetaThink has a core based on a metacognitive metamodel named MISM. MetaThink was validated using the Tracing technique and the metacognitive models obtained from the validation process were consistent with MISM.", "paperid": 2591274117, "normalizedname_level1": "artificial intelligence"}
{"index": 225, "text": "In this paper, we investigate and compare multiple data augmentation techniques in image classification targeting SAR images. Previous research showed that simple data augmentation techniques are still proven to be effective such as Affine transformations, cropping, flipping and color inverting training images. We use the SDMS MSTAR Public dataset, apply data augmentation techniques once at a time and record the results for the same convoluted neural network. Traditional transformations are powerful, however there is still no clear way to choose among infinitely many ways to augment the training data. A comparative study of simple Affine and color based augmentation techniques for SAR images is proposed. Finally we discuss the reasons why some strategies are more successful than others for the case of radar images.", "paperid": 2965878283, "normalizedname_level1": "artificial intelligence"}
{"index": 226, "text": "Monitoring cattle motion is essential, since it helps farmers to take a comprehensive view of the cattle's health and estrus time. However, the issue is not able to supervise the cattle in a long time and raising many cattle especially. Therefore, this paper aim to build a device which can sense the states of behavior actives and researches a method to prognosticate the cattle's health by using a cattle monitoring device that can record the 3-axis acceleration to analyze. This sensor is used to measure three-axis accelerometer data on the natural behavior of Vietnamese Yellow cows that live in a cage. The data of the accelerometer output signal are used to modify a simple behavioral classification such as: lying, standing and feeding. Therefore, we can identify some of cattle health events like lameness and estrus cycle. The classification results were tested with the model of the cow.", "paperid": 2561900463, "normalizedname_level1": "artificial intelligence"}
{"index": 227, "text": "The best algorithm for a computational problem generally depends on the \"relevant inputs,\" a concept that depends on the application domain and often defies formal articulation. While there is a large literature on empirical approaches to selecting the best algorithm for a given application domain, there has been surprisingly little theoretical analysis of the problem.   This paper adapts concepts from statistical and online learning theory to reason about application-specific algorithm selection. Our models capture several state-of-the-art empirical and theoretical approaches to the problem, ranging from self-improving algorithms to empirical performance models, and our results identify conditions under which these approaches are guaranteed to perform well. We present one framework that models algorithm selection as a statistical learning problem, and our work here shows that dimension notions from statistical learning theory, historically used to measure the complexity of classes of binary- and real-valued functions, are relevant in a much broader algorithmic context. We also study the online version of the algorithm selection problem, and give possibility and impossibility results for the existence of no-regret learning algorithms.", "paperid": 2273828870, "normalizedname_level1": "artificial intelligence"}
{"index": 228, "text": "Recent compressed sensing (CS) approaches utilize the similarity and redundancy of image patches of the magnetic resonance (MR) image to enable reconstruction from highly undersampled k-space measurements. In this paper, the patches similarity and redundancy is exploited by assuming that the image patches sample a low-dimensional manifold embedded in a high dimensional space. The MR image is then reconstructed by keeping the dimension of the patch manifold as small as possible. This is achieved by using the dimension of the patch manifold of a MR image as a regularizer in the objective function. Results show that the proposed method is superior to state-of-the-art patch-based MRI reconstruction methods. The algorithm is evaluated on two datasets containing 100 MR images each. The reconstruction quality of the algorithm, gauged using the three quality metrics: peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM) and normalized root mean square error (NRMSE), is better than the comparison methods.", "paperid": 2972914664, "normalizedname_level1": "artificial intelligence"}
{"index": 229, "text": "We present a method to incorporate global orientation information from the sun into a visual odometry pipeline using only the existing image stream, where the sun is typically not visible. We leverage recent advances in Bayesian Convolutional Neural Networks to train and implement a sun detection model that infers a three-dimensional sun direction vector from a single RGB image. Crucially, our method also computes a principled uncertainty associated with each prediction, using a Monte Carlo dropout scheme. We incorporate this uncertainty into a sliding window stereo visual odometry pipeline where accurate uncertainty estimates are critical for optimal data fusion. Our Bayesian sun detection model achieves a median error of approximately 12 degrees on the KITTI odometry benchmark training set, and yields improvements of up to 42% in translational ARMSE and 32% in rotational ARMSE compared to standard VO. An open source implementation of our Bayesian CNN sun estimator (Sun-BCNN) using Caffe is available at https://github.com/utiasSTARS/sun-bcnn-vo.", "paperid": 3103233796, "normalizedname_level1": "artificial intelligence"}
{"index": 230, "text": "Clinical Brain-Computer Interface (BCI) systems seek to enable paralyzed individuals to operate devices with their brain activity. Non-invasive systems based on electroen-cephalographic (EEG) signals are popular since they avoid risks associated with invasive procedures, but unfortunately EEG signals are inherently noisy, making effective classifiers challenging to develop. Commonly, new classifiers are benchmarked on signals from healthy subjects executing physical movements, under the assumption that the performance will transfer to clinical cases where only imagined movements are possible. Here, we show in contrast that classifiers trained on signals associated with actual movements perform erratically when applied to signals associated with imagined movements. We suggest that this is because the signals lay in different domains. Then, to exploit the different statistical distributions, we apply a domain adaptation technique, Frustratingly Easy Domain Adaptation (FEDA), improving classifier performance accuracy by a third on a discrimination task that simulates the clinical condition.", "paperid": 2575406329, "normalizedname_level1": "artificial intelligence"}
{"index": 231, "text": "Track-before-detect (TBD) is an efficient approach for tracking a target with low signal-to-noise-ratio. Unlike classic detection methods, TBD does not require thresholding. TBD integrates the signal of the target over space and time. This paper follows the one we published last year. A new particle filter has been proposed where the proposal density is constructed thanks to local Laplace approximations at the modes of the posterior density. An improved and fast version of this filter is proposed which includes also a sequential target detection test. Some results on simulated and experimental infrared images are presented.", "paperid": 2508699232, "normalizedname_level1": "artificial intelligence"}
{"index": 232, "text": "In recent years, the application of surface electromyography (sEMG) has increasingly more prominent, while the development of deep learning algorithms cannot be ignored. In this paper, a deep neural network that combined 3D-convolutional layers and a long short-term memory layer (LSTM) is proposed. Meanwhile, we propose data augmentation methods and a transfer learning algorithm to improve our performance. This proposed method is shown to outperform the other networks in sEMG-based recognition of lower limb abnormality. The experiments with 94.12% accuracy show that our method is effective for recognition of lower limb abnormality.", "paperid": 3009350775, "normalizedname_level1": "artificial intelligence"}
{"index": 233, "text": "Due to the increasing interest in physical-based rendering in High Dynamic Range (HDR) in game development and the lack of commercial HDR displays, tone mapping the HDR game content to match the capabilities of Standard Dynamic Range (SDR) displays is currently a topic of high importance. In this paper, we propose a global Tone-Mapping Operator (TMO) for video gaming applications which takes advantage of the unique characteristics of the rendered HDR content to reproduce a tone-mapped scene that best matches the appearance of the original HDR scene in terms of preserved global contrast and texture details. This results in a more appealing game and increases players' quality of experience.", "paperid": 2795182063, "normalizedname_level1": "artificial intelligence"}
{"index": 234, "text": "Cerebrum Tumor is the unusual or unrestrained cell division within the brain. The remedial problems are serious if tumors are not diagnosed at early stage inevitably most timely examination is necessary. This paper deals with detection of tumor region by Morphological Operators based segmentation approach. It contains upgrade, partition and positioning stages. To extract the tumor region the images are partitioned and order by categorizing them into Benign and Malignant. In case if there are more number of images, doctors could save time by using this approach.", "paperid": 2979785910, "normalizedname_level1": "artificial intelligence"}
{"index": 235, "text": "In this paper we propose a new powerful face recognition method to increase the performance of face recognition algorithms. In our idea we integrate two dissimilarity measures namely City-block and Mahalanobis Cosine distance. The experiments are performed on the ORL database and YALE database. The results indicate the interest of the proposed technique compared to others methods of literature.", "paperid": 2362131543, "normalizedname_level1": "artificial intelligence"}
{"index": 236, "text": "It has been shown that by combining the acoustic and articulatory information significant performance improvements in automatic speech recognition (ASR) task can be achieved. In practice, however, articulatory information is not available during recognition and the general approach is to estimate it from the acoustic signal. In this paper, we propose a different approach based on the generalized distillation framework, where acoustic-articulatory inversion is not necessary. We trained two DNN models: one called “teacher” learns from both acoustic and articulatory features and the other one called “student” is trained on acoustic features only, but its training process is guided by the “teacher” model and can reach a better performance that can't be obtained by regular training even without articulatory feature inputs during test time. The paper is organized as follows: Section 1 gives the introduction and briefly discusses some related works. Section 2 describes the distillation training process, Section 3 describes ASR system used in this paper. Section 4 presents the experiments and the paper is concluded by Section 5.", "paperid": 2555561649, "normalizedname_level1": "artificial intelligence"}
{"index": 237, "text": "Virtual reality applications prefer real walking to provide highly immersive presence than other locomotive methods. Mapping-based techniques are very effective for supporting real walking in small physical workspaces while exploring large virtual scenes. However, the existing methods for computing real walking maps suffer from poor quality due to distortion. In this paper, we present a novel divide-and-conquer method, called Smooth Assembly Mapping (SAM), to compute real walking maps with low isometric distortion for large-scale virtual scenes. First, the input virtual scene is decomposed into a set of smaller local patches. Then, a group of local patches is mapped together into a real workspace by minimizing a low isometric distortion energy with smoothness constraints between the adjacent patches. All local patches are mapped and assembled one by one to obtain a complete map. Finally, a global optimization is adopted to further reduce the distortion throughout the entire map. Our method easily handles teleportation technique by computing maps of individual regions and assembling them with teleporter conformity constraints. A large number of experiments, including formative user studies and comparisons, have shown that our method succeeds in generating high-quality real walking maps from large-scale virtual scenes to small real workspaces and is demonstrably superior to state-of-the-art methods.", "paperid": 2769552638, "normalizedname_level1": "artificial intelligence"}
{"index": 238, "text": "A tracked mobile robot with multiple robotic arms is useful for working in a disaster area because it can perform handling tasks such as object gripping and carrying by the use of the arms. To reduce burden of remote control on an operator for such tasks, this study presents a method for detecting gripping positions of an object for the two arms using an RGB-D sensor. The method is based on plane detection of a polyhedron object. Plane information of an object is detected by the depth sensor, and two planes having opposing normal vectors are selected as a set of candidate for gripping planes. Joint angles of both arms to grip the planes are calculated with position and posture of the robot using inverse kinematics. If the robot can grip the planes by both arms, they are selected as the gripping planes, then the robot moves to the obtained gripping position and performs gripping and lifting up the object. Several experimental results for the tracked mobile robot with two manipulators developed by the authors verified the validity of this method.", "paperid": 2753019968, "normalizedname_level1": "artificial intelligence"}
{"index": 239, "text": "Template matching methods are widely used to recognize instances of an untextured object and determine the poses. But in many practical cases the false positive rate is high because of similar interference characteristic in images especially in complex and clutter scene. A method based on multiple appearance features is presented in the paper to recognize poorly textured 3D objects and estimate their 6D pose in single color image. The object is distinguished from cluttered environment by multi-features which include the color, size and aspect ratio. Image pyramid is introduced here to improve efficiency. And the CAD model of the object is used to generate a hierarchical shape model in the offline phase for estimating the 6D pose accurately. Lastly the approach is evaluated in our application and publicly available dataset, and achieves good performance both in speed and recognition rate compared with state-of-the-art methods.", "paperid": 2889104122, "normalizedname_level1": "artificial intelligence"}
{"index": 240, "text": "The advancements in wireless communication technology and micro electro mechanical system (MEMS) based sensor technology led to the rise of body area communication in healthcare field. The bio signals acquired through this on-body communication mainly suffers from motion artifacts caused by shadowing due to the body shape and body movement. These noises may lead to wrong prediction on data. Therefore, it is important to consider denoising the bio signals in order to perform accurate diagnosis and analysis. This paper proposes regularized denoising autoencoder (DAE) to reconstruct the clean signal from its noisy form. Here two regularization terms L1 and L2 which updates the cost function to avoid over fitting problem. This paper proves that L1 is better than L2 in terms of recovering the signal quality and it is measured by Signal to Noise Ratio (SNR). The dataset used here are taken from a neurokit a python tool box for statistics and neurophysiological signal processing.", "paperid": 3011599133, "normalizedname_level1": "artificial intelligence"}
{"index": 241, "text": "For the visual navigation system of unmanned aerial vehicles (UAV), it is of importance to estimate the relative time delay between camera and inertial measurement unit (IMU) because the image data with undetermined delay cannot meet the synchronous requirement with other sensors of UAV indoor navigation. In this paper, an image delay estimation is designed a method that can effectively estimate. By using extended Kalman filter (EKF), the fusion between the IMU data and the visual data is performed with delay compensation so that the real-time pose and velocity of UAV can be effectively estimated. Simulation and experimental results conducted on a UAV prototype show that the delay can be accurately estimated so that the control performance of real-time indoor navigation is obviously improved on the UAV prototype.", "paperid": 2970503291, "normalizedname_level1": "artificial intelligence"}
{"index": 242, "text": "These days, data-driven soft sensors have been widely applied to estimate the difficult-to-measure quality variables in the industrial process. How to extract effective feature representations from complex process data is still the difficult and hot spot in the soft sensing application field. Deep learning (DL), which has made great progresses in many fields recently, has been used for process monitoring and quality prediction purposes for its outstanding nonlinear modeling and feature extraction abilities. In this work, deep stacked autoencoder (SAE) is introduced to construct a soft sensor model. Nevertheless, conventional SAE-based methods do not take information related to target values in the pretraining stage and just use the feature representations in the last hidden layer for final prediction. To this end, a novel gated stacked target-related autoencoder (GSTAE) is proposed for improving modeling performance in view of the above two issues. By adding prediction errors of target values into the loss function when executing a layerwise pretraining procedure, the target-related information is used to guide the feature learning process. Besides, gated neurons are utilized to control the information flow from different layers to the final output neuron that take full advantage of different levels of abstraction representations and quantify their contributions. Finally, the effectiveness and feasibility of the proposed approach are verified in two real industrial cases.", "paperid": 3081318531, "normalizedname_level1": "artificial intelligence"}
{"index": 243, "text": "The Internet has resulted in cyber-threats and cyber-crimes, which can occur anywhere at any time. Among various cyber threats, modern malware with applied metamorphosis and polymorphic technology is a concern as it can proliferate to advanced variants from its original shape. The typical malware analysis methods, including signature-based approach, remain vulnerable to such advanced variants. This paper proposes a visualization-based approach for malware analysis using the state-of-the-art Convolution Neural Network (CNN) model such as ResNeXt, which had achieved outstanding performance in image classifications with competitive computational complexity. The proposed method transforms the attributes of raw malware binary executable files to greyscale images for further analysis by well-established deep learning models. The greyscale images, which result of data transformation for visualization, are classified using ResNeXt. The experiment results show that the proposed solution achieves 98.32% and 98.86% of accuracy in malware classification on Malimg dataset and modified Malimg dataset, respectively. The proposed method outperforms other comparable methods in terms of classification accuracy and requires similar level of computational power.", "paperid": 3083139378, "normalizedname_level1": "artificial intelligence"}
{"index": 244, "text": "The traditional target tracking algorithm based on sparse representation only considers the whole information of the target template without considering the information of the background. Tracking drift is easily happened when the target is disturbed by cluttered background, occlusion and illumination. Aiming at the existing problems, this paper proposes a sparse representation target tracking method based on null-space discriminative projection. On the one hand, the model increases the reconstruction error of the target sample by introducing the null-space discriminative projection method, thus improving the discriminative ability of the algorithm to the target and the background; On the other hand, using the L1 norm as the loss function reduces the sensitivity of the template to the outlier data. In addition, the model designs an online learning algorithm using to update the target tracking template. The tracking algorithm performs the best in the scene with high similarity between target and background. It can also deal with occlusion, illumination changes and other issues. The experimental results show that the proposed method is more stable, reliable and robust than the popular tracking algorithms. The specific experimental results are demonstrated in this paper.", "paperid": 2792610201, "normalizedname_level1": "artificial intelligence"}
{"index": 245, "text": "Many existing color image denoising methods process color channels individually and fail to consider their cross-channel correlations. To solve this problem, in this paper, we employ the quaternion representation of the color image and propose a novel Quaternion Non-local Total Variation (QNLTV) model to remove Gaussian noise from color images. We first introduce the coupled quaternion distance to measure the color image patch similarity. Decomposing the color image into brightness and chromaticity components in quaternion domain, we then divide the QNLTV model into two quaternion optimizaiton problems and solve them alternatively. Experiment results show that QNLTV has the significantly better denoising performance than competing methods in terms of visual and quantitative evaluations.", "paperid": 2989935588, "normalizedname_level1": "artificial intelligence"}
{"index": 246, "text": "Diabetes is one of the most common disease in individuals. \\textit{Diabetic retinopathy} (DR) is a complication of diabetes, which could lead to blindness. Automatic DR grading based on retinal images provides a great diagnostic and prognostic value for treatment planning. However, the subtle differences among severity levels make it difficult to capture important features using conventional methods. To alleviate the problems, a new deep learning architecture for robust DR grading is proposed, referred to as SEA-Net, in which, spatial attention and channel attention are alternatively carried out and boosted with each other, improving the classification performance. In addition, a hybrid loss function is proposed to further maximize the inter-class distance and reduce the intra-class variability. Experimental results have shown the effectiveness of the proposed architecture.", "paperid": 3090987843, "normalizedname_level1": "artificial intelligence"}
{"index": 247, "text": "Discriminative correlation filters (DCF) have aroused great interests in visual object tracking in recent years due to the accuracy and computation efficiency. However, occlusion is still the main factor that affects performance. In this paper, a spatial-temporal consistent correlation filter utilizes the rich features extracted from a pre-trained convolutional neural network (CNN) is proposed to tackle this problem. We reformulate the conventional loss function and update classifier coefficients adaptively according to object appearance change rather than a constant learning rate. To acquire more accurate target location, this work combines correlation filter respond maps from different CNN layers together lie on their reliability. The experimental results evaluated on extensive challenging benchmark sequences demonstrate the proposed algorithm significantly improves the performance compared to state-of-the-art trackers.", "paperid": 2751022902, "normalizedname_level1": "artificial intelligence"}
{"index": 248, "text": "To improve the recognition accuracy and to solve the overfitting problem of traditional face recognition methods, this paper proposed an adaptive histogram normalization algorithm to reduce brightness effect in training data and designing loss function. The proposed algorithm can adaptive adjustment training images and inference parameters based on the real-time captured images data. In experimental results, the proposed algorithm has higher accuracy than other algorithms and has higher testing accuracy to improve overfitting.", "paperid": 3005582281, "normalizedname_level1": "artificial intelligence"}
{"index": 249, "text": "Some obsolete — but common — practices in the application of fertilizers and pesticides are causing serious environmental problems in Colombia; a situation that could be addressed by combining robotics and modern farming management principles, for example, the Precision Agriculture. This paper describes a novel application of Plexil — an experimental synchronous programming language developed by NASA-for robot automation in agriculture, supported by a simulation platform that allows quick prototyping of an automation plan, and a transparent integration of it on a physical robot. As a result, a methodology for evolutive robot development, and a case study with a real six-wheeled multipurpose agricultural robot are presented. Further applications of the simulation platform as a mean to easily introduce robotics engineers to alternative — and less error prone-programming models are also discussed.", "paperid": 2574167146, "normalizedname_level1": "artificial intelligence"}
{"index": 250, "text": "We investigate and improve self-supervision as a drop-in replacement for ImageNet pretraining, focusing on automatic colorization as the proxy task. Self-supervised training has been shown to be more promising for utilizing unlabeled data than other, traditional unsupervised learning methods. We build on this success and evaluate the ability of our self-supervised network in several contexts. On VOC segmentation and classification tasks, we present results that are state-of-the-art among methods not using ImageNet labels for pretraining representations. Moreover, we present the first in-depth analysis of self-supervision via colorization, concluding that formulation of the loss, training details and network architecture play important roles in its effectiveness. This investigation is further expanded by revisiting the ImageNet pretraining paradigm, asking questions such as: How much training data is needed? How many labels are needed? How much do features change when fine-tuned? We relate these questions back to self-supervision by showing that colorization provides a similarly powerful supervisory signal as various flavors of ImageNet pretraining.", "paperid": 2599837529, "normalizedname_level1": "artificial intelligence"}
{"index": 251, "text": "The Internet and WWW have turned today's world into global village. Over the years technology has significantly changed the way people communicate. How they feel, what they like or dislike, people like to share it online. Proper mining and analysis of public feelings or opinions can bring a miracle to existing business profit. For the same purpose instead of exclusive public opinion polling, machine learning tools are preferred. Few researchers are trying to interpret it with the help of linguistic approach. But the reviews or opinion of the customers' also known as user-generated content has the characteristics such as incomplete, grammatically incorrect, weakly structured etc. This causes degradation in the performance of the opinion mining task. Whereas, few researchers are trying to apply statistical measures for the same. Both the methods have their own pros and cons. In this paper, we have proposed a hybrid approach by integrating both the linguistic as well as statistics approach into a single unified framework. The key objective of our task is to co-extract the feature and opinion pair from customers reviews. Let's view the unstructured corpus a combination of a set of grammatically correct and a set of grammatically incorrect sentences. For the grammatically correct sentence, use syntactic pattern-based rules to extract the features and opinion pairs. For the set of sentences not interpreted by the syntactic parser, apply word alignment technique to extract probable feature opinion pair. Further, we determine the aspect of each probable feature and calculate the opinion association among these words. Finally, we calculate the soundness of extracted feature opinion pair with the document. For experimentation purpose, we used customer review dataset of five different products. Through the analysis, a high accuracy is achieved by the hybrid approach.", "paperid": 2900572330, "normalizedname_level1": "artificial intelligence"}
{"index": 252, "text": "This paper proposes a new approach for classifying ground moving targets captured by pulsed Doppler radar. Radar echo signals express the Doppler effect that moving targets produce. A learned feature representation extracted from spectrogram images using a transfer learning paradigm is proposed. A discrimination power analysis that derives highly discriminative features used to train a robust classifier was conducted. The extensive experiments performed on the public RadEch dataset show that the proposed method produces a significant boost in performance when compared to other state-of-the-art methods.", "paperid": 2975483804, "normalizedname_level1": "artificial intelligence"}
{"index": 253, "text": "We explore four different technology and design options for transistors and library cells for a low power supply voltage of 0.4 V and circuit statistics representative of artificial intelligence (AI) applications. The design rules correspond to 2nm node with cell heights of 100~110 nm and 30 nm gate pitch. Holistic analysis of the RO (Ring Oscillator) behavior, including MOL parasitics, all major variability sources, and stress proximity effects suggests that different FinFET and nanoslab transistor design options exhibit a wide range of power and performance differences. The key to improve FinFET PPA is to avoid fin cuts to maintain strong PMOS performance, and a key to improve SS corner delay is to use nanoslabs with tighter variability control.", "paperid": 2965129052, "normalizedname_level1": "artificial intelligence"}
{"index": 254, "text": "Recently, owing to the outstanding capability of deep learning in solving ill-posed problems, the single-frame super-resolution (SR) researches tend to focus on deep learning methods largely. However, related researches are implemented and evaluated through various datasets and different deep learning frameworks, which hinders the comparison of performance among different methods and heavily hampers the progress of SR techniques. In this study, we present GeoSR, an open source computer vision package for deep learning based single-frame remote sensing imagery super-resolution to facilitate the development of the SR community. As a unified, simple, and flexible package, GeoSR contains pipeline-like integrated tools from data retrieval to final result evaluation, which enables users to develop self-defined models conveniently; several state-of-the-art models trained through the same high-quality dataset are provided as the baseline in the package as well. Moreover, the proposed package could potentially serve as a viable backend for other related packages such as image segmentation with high efficiency.", "paperid": 2984968099, "normalizedname_level1": "artificial intelligence"}
{"index": 255, "text": "Fine-grained recognition is still a difﬁcult task in pattern recognition applications due to the challenge of accurate localization of discriminative parts. Recent CNN-based methods generally utilize attention mechanism to produce attention masks without part labels/annotations and extract corresponding image parts from them. However, these methods extract the attention parts by using ﬁxed-size rectangles to crop images regardless of the size of objects to be recognized, which will hinder the feature expression of the following Part-CNNs. In this paper, we propose an adaptive cropping module based on the information of attention masks to adjust size of cropping rectangles. The trainingprocessofadaptivecroppingmoduleandPart-CNNscan reinforce each other with the proposed rank loss and the classic softmax loss. To further balance and fuse all attention parts, we propose a part weighting module to evaluate part contributions. Under the optimization of sort loss, the part weighting module will produce part weights in the same order as prediction scores learned by attention parts. The backbone of our network is MA-CNN. Different from MA-CNN, the new proposed adaptive cropping module and part weighting module can jointly guide the framework to produce a more discriminative ﬁne-grained feature. Experiments show that the AMA-CNN outperforms MA-CNN by 1.1% on CUB200-2011 bird dataset.", "paperid": 3011256619, "normalizedname_level1": "artificial intelligence"}
{"index": 256, "text": "Automatic Target Recognition (ATR) aims at detecting the presence and at recognizing the typology and the orientation of targets within a scenario, by using an unsupervised approach. In Syntethic Aperture Radar imaging this turns to be a difficult task due to the specific characteristics of clutter and background noise. Within this manuscript a new two-steps ATR algorithm based on Kolmogorov-Smirnov test is presented. The method has been tested on real MSTAR datasets showing interesting performances.", "paperid": 2771270720, "normalizedname_level1": "artificial intelligence"}
{"index": 257, "text": "The Automatic Vehicle Identification (AVI) is the process of detecting and recognizing vehicle on the road automatically. In this work, we propose a design of an automatic vehicle identification system using machine learning approach with Robot Operating System (ROS). The work is based on detecting and recognizing license plate number of any moving vehicle by processing images from a camera. In this work, we trained and used three different classifiers. Two Haar cascade classifier is used for detecting and recognizing license plates of cars. Another classifier trained using K-nearest neighbor technique is used for recognizing the characters of the license plate. The purpose of the work is to create the whole system with separate different parts and each part can be easily integrated with other systems with the similar purpose, which is why the Robot Operating System is used for building the system. Each of the three classifiers is tested in different conditions and each of them has an overall efficiency of over 90 percent.", "paperid": 2782592065, "normalizedname_level1": "artificial intelligence"}
{"index": 258, "text": "In this paper, we propose an approach to interpret the prediction process of the BP-sLDA model, which is a supervised Latent Dirichlet Allocation model trained by Back Propagation over a deep architecture. The model is shown to achieve state-of-the-art prediction performance on several large-scale text analysis tasks. To interpret the prediction process of the model, often demanded by business data analytics applications, we perform evidence analysis on each pair-wise decision boundary over the topic distribution space, which is decomposed into a positive and a negative components. Then, for each element in the current document, a novel evidence score is defined by exploiting this topic decomposition and the generative nature of LDA. Then the score is used to rank the relative evidence of each element for the effectiveness of model prediction. We demonstrate the effectiveness of the method on a large-scale binary classification task on a corporate proprietary dataset with business-centric applications.", "paperid": 2408544667, "normalizedname_level1": "artificial intelligence"}
{"index": 259, "text": "We present a strategic model of network creation that satisfies all known theoretically verifiable properties of the small-world phenomenon. We consider a population that is uniformly distributed in a low-dimensional space, and show that in such a society if each individual follows the status of a subset of others by investing attention in order to satisfy curiosity, then small-world properties appear naturally as a side effect.", "paperid": 2486541299, "normalizedname_level1": "artificial intelligence"}
{"index": 260, "text": "Image-based localization plays an important role in today's autonomous driving technologies. However, in large scale outdoor environments, challenging conditions, e.g., lighting changes or different weather, heavily affect image appearance and quality. As a key component of feature-based visual localization, image feature detection and matching deteriorate severely and cause worse localization performance. In this paper, we propose a novel method for robust image feature matching under drastically changing outdoor environments. In contrast to existing approaches which try to learn robust feature descriptors, we train a deep network that outputs the low-rank representations of the images where the undesired variations on the images are removed, and perform feature extraction and matching on the learned low-rank space. We demonstrate that our learned low-rank images largely improve the performance of image feature matching under varying conditions over a long period of time.", "paperid": 2970541970, "normalizedname_level1": "artificial intelligence"}
{"index": 261, "text": "The abrasion of milling cutters is an important factor that affects the accuracy of a workpiece. The intervals between cutter changes is based on the burr condition of the edges on the finished products as well as their dimensional precision. Delayed replacement of cutters will result in a degradation of workpiece quality and it is important that the wear of cutters be monitored in a timely manner. In this study the actual vibration signals generated in a milling process were measured using an Automatic Intelligent Diagnosis Mechanism (AIDM) to determine cutter wear. The AIDM included two feature extraction approaches and three classification methods. The first approach used the Finite Impulse Response Filter (FIR) with Approximate Entropy (ApEn) for feature extraction. The second approach was nonlinear feature mapping using a fractional order Chen-Lee chaotic system. This used chaotic dynamic error centroids and chaotic dynamic error mapping for status identification. After feature extraction the results were substituted into a Back Propagation Neural Network (BPNN), Support Vector Machine (SVM), and a Convolutional Neural Network (CNN) for identification. The results of the experiments showed that a Chaotic Dynamic Error Map of the fractional order Chen-Lee chaotic system in the AIDM had an identification rate of 96.33% using a convolutional neural network. In addition, it was shown that the AIDM model could automatically select the most suitable feature extraction and classification model from the input signal and could determine the wear level milling cutters.", "paperid": 3105782360, "normalizedname_level1": "artificial intelligence"}
{"index": 262, "text": "Cardiovascular diseases are the biggest threat to human being’s health all over the world, and carotid atherosclerotic plaque is the leading cause of ischemic cardiovascular diseases. To determine the location and shape of the plaque, it is of great significance to detect the intima-media (IM). In this paper, a new IM detection method based on convolution neural network (IMD-CNN) is proposed for the detection of IM of blood vessels in longitudinal ultrasonic images. In IMD-CNN, firstly the region of interest (ROI) is automatically extracted by morphological processing, then the patch-wise training data are constructed, and finally a simple CNN is trained to detect the IM. The experimental results obtained on 23 images show that the test accuracy of IMD-CNN is over 86% and the performance of IMD-CNN is also visually proved to be effective.", "paperid": 3081930896, "normalizedname_level1": "artificial intelligence"}
{"index": 263, "text": "The quality of life of patients with refractory epilepsy can be significantly improved by designing algorithms capable of forecasting seizures and implementing them into closed-loop advisory/intervention devices. Over the last decade, several algorithms based on neural networks and deep learning have been proposed and showed promising performances. Nevertheless, the computational requirements of such algorithms were major obstacles towards their use in clinical devices. In this work, we overview recently proposed neural network-based seizure forecasting algorithms and summarize the state of the art regarding advancement in hardware design and implementation of deep neural network inferences. The paper ends with a list of recommendation for future seizure forecasting endeavors.", "paperid": 3048219503, "normalizedname_level1": "artificial intelligence"}
{"index": 264, "text": "This paper proposes a novel visual measurement framework, multi-module cascaded deep neural network (MMC-DNN), to achieve accurate, reliable and cost-effective vehicle positioning in complex urban environments. The MMC-DNN is inspired by the mechanism of human eyes' lateral positioning, which consists of three modules called siamesed fully convolutional network (S-FCN), skip-connection fully convolutional autoencoder (SC-FCAE) and multi-task neural network regressor (MT-NNR), respectively. The S-FCN is first designed to accurately detect the road area. Then, the segmented road is executed inverse perspective mapping (IPM) and the result is fed to the developed SC-FCAE for extracting equivalent positioning features. Further, the MT-NNR is proposed to efficiently estimate lateral position and yaw angle with the help of a road map. Based on the estimation results, the MEMS INS/GPS integration is significantly augmented by extended Kalman filter (EKF). Experimental results validate the effectiveness of the proposed framework in enhancing positioning performance.", "paperid": 3032592799, "normalizedname_level1": "artificial intelligence"}
{"index": 265, "text": "This paper explores the social quality (goodness) of community structures formed across Twitter users, where social links within the structures are estimated based upon semantic properties of user-generated content (corpus). We examined the overlap of the community structures of the constructed graphs, and followership-based social communities, to find the social goodness of the links constructed. Unigram, bigram and LDA content models were empirically investigated for evaluation of effectiveness, as approximators of underlying social graphs, such that they maintain the community social property. Impact of content at varying granularities, for the purpose of predicting links while retaining the social community structures, was investigated. 100 discussion topics, spanning over 10 Twitter events, were used for experiments. The unigram language model performed the best, indicating strong similarity of word usage within deeply connected social communities. This observation agrees with the phenomenon of evolution of word usage behavior, that transform individuals belonging to the same community tending to choose the same words, made by [1], and raises a question on the literature that use, without validation, LDA for content-based social link prediction over other content models. Also, semantically finer-grained content was observed to be more effective compared to coarser-grained content.", "paperid": 2963652957, "normalizedname_level1": "artificial intelligence"}
{"index": 266, "text": "The Imitation Game that was presented by Turing back in the 1950s was an important experiment whose purpose was to provide a basic platform for the question of whether a computer can think. Over the years other views were raised that presented weaknesses of and claims against Turing's test, and some alternative tests were even proposed and recently there is a claim that a program already passes Turing Test. The ability to interface with a huge amount of data from a variety of public resources over the internet creates new functionalities and capabilities that may allow updating of the test rules, modifying them (based on examples, that at least part of them are already implemented) and also changing the scope of the question from whether a computer can think to how relevant the answer is to the requester.", "paperid": 2471292936, "normalizedname_level1": "artificial intelligence"}
{"index": 267, "text": "The problem of community detection in complex networks is of high interest in many application domains including sociology, biology, mathematics and economy. Given a set of nodes and links between them, the aim of the problem is to find a grouping of nodes such that a strong community has dense intra-connections and sparse outside community links. In this paper, a coarse-grained evolutionary algorithm (EA) is developed to address this challenging problem. Several populations of potential solutions are evolved in parallel in an island model and periodically exchange certain individuals. Each population can be evolved by a different fitness function and several approaches to evaluate the community structure are considered in the current paper. Experiments are performed for real-world complex networks and results are analysed based on the normalized mutual information between the detected and the known community structure. Comparisons with the standard version of the EA based on different fitness functions are performed and the results confirm a good performance of the parallel EA in terms of solution quality and computational time.", "paperid": 2769659904, "normalizedname_level1": "artificial intelligence"}
{"index": 268, "text": "In laminography imaging, the laminographic tilt angle is an important factor that affects the reconstruction result. However, the optimal tilt angle was mainly estimated from experience in the current research. In this article, an estimation approach for measuring the quantity information of projections has been proposed, which is based on the entropy of pixel grayscale distribution. The correlation of reconstructed image quality and tilt angle was analyzed quantitatively by the method. In this way, a solution has been proposed for seeking the optimal tilt angle, which aims to improve the image quality of reconstructed layers. Additionally, numerical simulation was designed to validate the method, in which the reconstructed layer images at different tilt angles were compared. The curves of grayscale MAE, PSNR and SSIM versus tilt angle verified the reliability of calculated optimal tilt angle, which has proved that the method is effective. Meanwhile, given a certain model of the scanned object, the optimal tilt angle is constant and computable.", "paperid": 3007655246, "normalizedname_level1": "artificial intelligence"}
{"index": 269, "text": "In mapping of an environment, an approach to locate points or features on the map is needed to be recognized by the robot. Corner detection is one of the methods used to find the feature of a corner. In the Indonesian fire fighting robot contest (KRPAI), the method was used to recognize the room where the robot started. The starting position was randomized, so it was difficult to determine which room the robot was placed. In this paper we want to solve the issue by using corner detection to look for corner in each mapped room and look for the characteristic in every room. Characteristics of the room obtained from the distance between the two corners and the distance between the door with the nearest corner. Based on experiments used this method can recognize the room with accuracy of 87.25%. The experiment result showed that 6 out of 48 trials require two scans by turning the robot at 90 degrees because of the limitations of the laser range finder which can only scan by 270 degrees. From all experiments the average error of the reference distance is 2.29 cm.", "paperid": 2909468565, "normalizedname_level1": "artificial intelligence"}
{"index": 270, "text": "In this article describes the definitions of network attacks through neural networks and how to group them into coordinates. An interactive model of user actions and a neural network attack detection system are described.", "paperid": 3010610057, "normalizedname_level1": "artificial intelligence"}
{"index": 271, "text": "To better understand task failures in cloud computing systems, we analyze failure frequency of tasks based on Google cluster dataset, and find what we call as killer tasks that suffer from long-term failures and repeated rescheduling. Killer task can be a big concern of cloud systems as it causes unnecessary resource wasting and significant increase of scheduling workloads. Hence there is a need to provide a service for cloud system operators to recognize killer tasks in time. In this paper, we propose an online killer task recognition service based on the resource usage time series which can recognize killer tasks at the very early stage of their occurrence so that they can be handled appropriately instead of being rescheduled. The experiment results show that the proposed service performs a 93.6% accuracy in recognizing killer tasks with an 87% timing advance and 86.6% resource saving for the cloud system averagely.", "paperid": 2406434850, "normalizedname_level1": "artificial intelligence"}
{"index": 272, "text": "Rapid urbanization has brought about great challenges to our daily lives, such as traffic congestion, environmental pollution, energy consumption, public safety, and so on. Research on smart cities aims to address these issues with various technologies developed for the Internet of Things. Very recently, the research focus has shifted toward processing of massive amount of data continuously generated within a city environment, e.g., physical and participatory sensing data on traffic flow, air quality, and health care. Techniques from computational intelligence have been applied to process and analyze such data, and to extract useful knowledge that helps citizens better understand their surroundings and informs city authorities to provide better and more efficient public services. Deep learning, as a relatively new paradigm in computational intelligence, has attracted substantial attention of the research community and demonstrated greater potential over traditional techniques. This paper provides a survey of the latest research on the convergence of deep learning and smart city from two perspectives: while the technique-oriented review pays attention to the popular and extended deep learning models, the application-oriented review emphasises the representative application domains in smart cities. Our study showed that there are still many challenges ahead for this emerging area owing to the complex nature of deep learning and wide coverage of smart city applications. We pointed out a number of future directions related to deep learning efficiency, emergent deep learning paradigms, knowledge fusion and privacy preservation, and hope these would move the relevant research one step further in creating truly distributed intelligence for smart cities.", "paperid": 2943201207, "normalizedname_level1": "artificial intelligence"}
{"index": 273, "text": "Manual examination of chest x-rays is a time consuming process that involves significant effort by expert radiologists. Recent work attempts to alleviate this problem by developing learning-based automated chest x-ray analysis systems that map images to multi-label diagnoses using deep neural networks. These methods are often treated as black boxes, or they output attention maps but don’t explain why the attended areas are important. Given data consisting of a frontal-view x-ray, a set of natural language findings, and one or more diagnostic impressions, we propose a deep neural network model that during training simultaneously 1) constructs a topic model which clusters key terms from the findings into meaningful groups, 2) predicts the presence of each topic for a given input image based on learned visual features, and 3) uses an image’s predicted topic encoding as features to predict one or more diagnoses. Since the net learns the topic model jointly with the classifier, it gives us a powerful tool for understanding which semantic concepts the net might be exploiting when making diagnoses, and since we constrain the net to predict topics based on expert-annotated reports, the net automatically encodes some higher-level expert knowledge about how to make diagnoses.", "paperid": 2959269630, "normalizedname_level1": "artificial intelligence"}
{"index": 274, "text": "This paper proposes an algorithm to describe the distribution of automobile dashboard object (ADO) . In this algorithm, we propose ADO encoding and similarity computation algorithm SDEA. We encode every automobile dashboard object into dashboard cell to assign them specified anti-noise ability even if the ADO is interfered by environment light, dust, shadow and so on. Usually the ADO of every vehicle is different so that every vehicle has its own different presentation code. The encoding method present the ADO with accurate cells to decrease noises, and the difference between source and candidates can then be computed effectively. In this paper, we proposed a novel Synthesized Distance of Mahalanobis and Euclidean distance for Encoded ADO (SDEA) algorithm to minimize the correlation between cells of the ADO and increase the robustness of recognition. The tiny difference of the ADO is then enlarged and the recognition of an interested candidate is easier with strong robustness. In special vehicle detection, the algorithm has more effective performance compared with only Euclidian or Mahalanobis distance. Over 500 vehicle images are utilized in our experiments and the result verifies that the ADO cells encoding SDEA algorithm has distinguished recognition ability even if the images are contaminated by strong noise and the ADO has shape transformation and position shift so that this algorithm presents the ADO mathematically and recognizes a specified vehicle accurately in huge amount of automobile images and is effective for interested vehicle recognition in big data with an excellent noise tolerant capability. This algorithm overcomes the shortcoming of other category methods when they recognize a special vehicle with the serious transformed object structure and strong noise.", "paperid": 3005544378, "normalizedname_level1": "artificial intelligence"}
{"index": 275, "text": "The major requirement for medical image watermarking is the reversibility of the medical image after extracting watermark. In this paper, we propose a secured reversible watermarking technique for medical images using Histogram shifting method. We provide extra security to the given watermark with chaos encryption. The given watermark is encrypted with chaos sequence prior to embedding in the given medical image. Also the block based technique is evaluated for increased watermarking capacity. The results of technique are compared on the basis on MSE and PSNR.", "paperid": 2576612210, "normalizedname_level1": "artificial intelligence"}
{"index": 276, "text": "Micro-Macro thinking is students' ability to understand concepts and models at the microscopic (typically unseen) level, and link them to their corresponding manipulable variables at the 'macroscopic' (mostly tangible and measurable) level. For example, in the domain of basic analog electronics, learners are expected to relate the microscopic structure of atoms and scientific models of electron motion to describe and predict the outcomes of current and voltage in a macroscopic circuit in the lab. Development of this skill is crucial as it helps students apply their theoretical knowledge to solve real world problems as well as do design and troubleshooting. Existing solutions have attempted developing micro-macro thinking skill in the context of inquiry learning and system thinking, however, these have primarily addressed school level topics and have been implemented in the presence of a facilitator and other elements such as peer learning and doubt-solving sessions. We have designed, developed and evaluated MIC-O-MAP (MICroscopic Observations MAcroscopic Predictions), a TEL environment to develop students' micro-macro thinking in the domain of basic analog electronics at the undergraduate level, in the context of self-regulated learning. Key features of MIC-O-MAP include dynamically linked multiple representations, conceptual scaffolding questions and customized feedback by a pedagogical agent, which help establish the micro-macro link. In this paper, we describe the development of MIC-O-MAP, the design of learning modules for various topics in basic analog electronics, and present the findings from studies to evaluate student learning of micro-macro thinking in the chosen topics.", "paperid": 2745135372, "normalizedname_level1": "artificial intelligence"}
{"index": 277, "text": "When full automation of mobile robots is not possible or desirable, teleoperation constitutes an alternative. The human operator can be supported with direction cues to facilitate localization or navigation. These cues are presented typically in the auditory, haptic and/or visual modality. An experiment was conducted to evaluate systematically and empirically the (uni-modal and multi-modal) effects of auditory and haptic feedback compared to visual feedback on target localization accuracy. Results show that haptic as well as auditory direction cues lead to significantly lower accuracy than visual cues. Moreover, combining feedback cues does not necessarily lead to better performance and can even reduce accuracy. Based on the results, possible implications for multi-modal human machine interface design are discussed.", "paperid": 2739452301, "normalizedname_level1": "artificial intelligence"}
{"index": 278, "text": "Lung segmentation in Computed Tomography (CT) images plays a vital role in the diagnosis, detection and three-dimensional visualization of lung nodules. In addition, the stability, accuracy and efficiency of lung segmentation in CT images have a significant impact on the performance of Computer-Aided Detection (CAD) systems. Lung segmentation is usually the first step in lung CT images analysis. In this paper, a fully automated algorithm for recognition and segmentation the lung in 3D X-ray images using the Active Shape Model (ASM) is presented. Proposed algorithms not only split the left and right lungs automatically, but also include the juxta-pleural nodules as a result of segmentation. This method is based on the ASM algorithm, which automatically detects nodules attached to the lung wall. This algorithm applied to 7 CT images of the lungs that include juxta-pleural nodules and calculate the division dice of segmentation.", "paperid": 3095472999, "normalizedname_level1": "artificial intelligence"}
{"index": 279, "text": "Typically, a single light field camera only captures a limited portion of the visual scene and the rendered views offer low spatial resolution since the full sensor resolution also needs to capture the light arriving to the sensor from multiple directions. However, many applications require a large field of view and higher spatial resolution, which cannot be offered by a single lenslet light field image. In this paper, a lenslet light field panorama creation solution is proposed based on the stitching of the sub-aperture images associated to several lenslet light fields. The proposed approach consists in capturing multiple light fields with a single lenslet camera, which is rotated to capture different scene angles; corresponding sub-aperture images associated with the multiple light field images are then stitched while avoiding misalignments. The created lenslet light field panorama should preserve the directional light information, thus allowing to change a posteriorithe perspective and the objects in focus on a panorama basis.", "paperid": 2903450883, "normalizedname_level1": "artificial intelligence"}
{"index": 280, "text": "Check-in prediction using location-based social network data is an important research problem for both academia and industry since an accurate check-in predictive model is useful to many applications, e.g. urban planning, venue recommendation, route suggestion, and context-aware advertising. Intuitively, when considering venues to visit, users may rely on their past observed visit histories as well as some latent attributes associated with the venues. In this paper, we therefore propose a check-in prediction model based on a neural framework called Preference and Context Embeddings with Latent Attributes (PACELA). PACELA learns the embeddings space for the user and venue data as well as the latent attributes of both users and venues. More specifically, we use a probabilistic matrix factorization-based technique to infer the latent attributes specific to users and locations in location-based social networks (LBSNs), considering the user visitation decisions that could be affected by area attraction, neighborhood competition, and social homophily. PACELA also includes a deep learning neural network to combine both embedding and latent features to predict if a user performs check-in on a location. Our experiments on three different real world datasets show that PACELA yields the best check-in prediction accuracy against several baseline methods.", "paperid": 2846263287, "normalizedname_level1": "artificial intelligence"}
{"index": 281, "text": "According to yangzhou 8 surface water monitoring station of 412 groups of measuring data, water quality assessment were analyzed by using grey correlation method of water quality evaluation factors sensitivity, and the sensitive parameters as the main parameter of water quality evaluation. The neural network model was established by using neural network theory and method. Water quality assessment was carried out for 8 surface water monitoring stations. The results are compared with the results of individual factors. The results show that the artificial neural network model can solve the complex nonlinear relationship between the evaluation factor and the water quality in the case of large quantities of data. The results are high reliability, high accuracy, good practicality and good objectivity. And the water quality in yangzhou is partly reflected.", "paperid": 2792231926, "normalizedname_level1": "artificial intelligence"}
{"index": 282, "text": "Irregular dial instruments, such as SF6, are widely used in industry environment. The results of these instruments are usually obtained by artificial. In order to make the result's acquisition and record automatically, this paper proposed an irregular dial instrument's result extraction method based on the image. This method gets the major features of dial instruments through ransac method and least square ellipse fitting. The pointer point, reference point and center point of instruments are extracted and used for the calculation of instruments' results. The errors can be kept at 5% with proposed method contrast with the result by artificial. The experimental results show that the result of irregular dial instrument can be effectively got by the proposed method. The proposed method has a reference for the other dial instruments.", "paperid": 2735112686, "normalizedname_level1": "artificial intelligence"}
{"index": 283, "text": "A major challenge facing camera networks today is how to effectively organizing and visualizing videos in the presence of complicated network connection and overwhelming and even increasing amount of data. Previous works focus on 2D stitching or dynamic projection to 3D models, such as panorama and Augmented Virtual Environment (AVE), and haven't given an ideal solution. We present a novel method of multiple video fusion in 3D environment, which produces a highly comprehensive imagery and yields a spatio-temporal consistent scene. User initially interact with a newly designed background model named video model to register and stitch videos' background frames offline. The method then fuses the offline results to render videos in a real time manner. We demonstrate our system on 3 real scenes, each of which contains dozens of wide-baseline videos. The experimental results show that, our 3D modeling interface developed with the our presented model and method can efficiently assist the users to seamlessly integrate videos by comparing to commercial-off-the-shelf software with less operating complexity and more accurate 3D environment. The stitching method proposed by us is much more robust against the position, orientation, attribute differences among videos than the start-of-the-art methods. More importantly, this study sheds light on how to use the 3D techniques to solve 2D problems in realistic and we validate its feasibility.", "paperid": 2902054777, "normalizedname_level1": "artificial intelligence"}
{"index": 284, "text": "Data transformation often requires users to write many trivial and task-dependent programs to transform thousands of records. Recently, programming-by-example (PBE) approaches enable users to transform data without coding. A key challenge of these PBE approaches is to deliver correctly transformed results on large datasets, since these transformation programs are likely to be generated by non-expert users. To address this challenge, existing approaches aim to identify a small set of potentially incorrect records and ask users to examine these records instead of the entire dataset. However, because the transformation scenarios are highly task-dependent, existing approaches cannot capture the incorrect records for various scenarios. We present a approach that learns from past transformation scenarios to generate a meta-classifier to identify the incorrect records. Our approach color-codes these transformed records and then presents them for users to examine. The method allows users to either enter an example for a record transformed incorrectly or confirm the correctness of a transformed record. And our approach can learn from the users' labels to refine the meta-classifier to accurately identify the incorrect records. Simulation results and a user study show that our method can identify the incorrectly transformed records and reduce the user efforts in examining the results.", "paperid": 2315227351, "normalizedname_level1": "artificial intelligence"}
{"index": 285, "text": "In bistatic forward-looking synthetic aperture radar (BFSAR), conventional autofocus algorithms cannot estimate the phase errors accurately when the range walk is compensated in the azimuthal time domain. This problem stems form the influence of the azimuth-variant Doppler coefficients after linear range cell migration correction (LRCMC) in azimuthal time domain. To cope with such a problem, an estimation equalization-estimation (EEE) autofocus scheme for BFSAR is proposed. Different from the conventional autofocus method, the azimuth-variant Doppler coefficients are additionally estimated and equalized. As the influence of azimuth-variant Doppler coefficients has been greatly reduced, conventional autofocus method is subsequently applied for accurate phase error retrieval. Simulation results demonstrate the validity of the proposed method on the improvement of autofocus in BFSAR.", "paperid": 2442352540, "normalizedname_level1": "artificial intelligence"}
{"index": 286, "text": "Disclosing the complex relationships effectively between paired brain regions played a significant role in measuring the brain functional connectivity and exploring brain topological structures. Even though Pearson correlation coefficient (PCC) has been widely used to construct functional brain networks in the previous studies, it was mainly sensitive to linear associations. Therefore, maximal information coefficient (MIC) was first utilized to make up this weakness of PCC to construct electroencephalography (EEG) connectivity in the current study. The simulation results showed that MIC could capture certain relationships which PCC failed to detect. Furthermore, brain network properties changed with various thresholds under the resting-state EEG, and the comparison analysis of network properties illustrated that MIC and PCC could capture different aspects of connections between paired brain regions. These findings indicated that MIC could be a complementary method of PCC for the construction of scalp resting-state EEG connectome and provided a novel tool to reveal the potential mechanisms of brain networks.", "paperid": 2911629262, "normalizedname_level1": "artificial intelligence"}
{"index": 287, "text": "Web medium service has emerged to be a dominant way for billions of individuals sharing and spreading instant news and information. Meanwhile, the challenging issues for delivering high-quality disaster related information are also brought up for the information overload, fast response and dynamic of disaster events. In this paper, we explore the problem of generating storyline from huge amount of web information and propose a knowledge graph-based disaster storyline generating framework. The deep learning technique and the semi-supervision method are first used to extract two kinds of triples from disaster news. Then the evolution of disasters is summarized in a way of graph-based which can clearly show the sketch of disaster development. Finally, the location entities are extracted by the name entity recognized model. Compared with commonly used text summarization storyline, the proposed framework can provide a better user situational awareness and deeper understanding on disaster events by the presentation of graph.", "paperid": 2972674313, "normalizedname_level1": "artificial intelligence"}
{"index": 288, "text": "Separating an optical remote sensing image into sea  and land areas is very challenging yet of great importance to the coastline extraction and subsequent object detection. In this paper, we propose a hierarchical region merging approach to automatically extract the sea area  and employ edge directed graph cut (GC) to accomplish the final segmentation. Firstly, an image is segmented into superpixels and a graph-based merging method is employed to extract the maximum area of sea region (MASR). Then the non-connected sea regions are identified by measuring the distance between their superpixels and the MASR. When modelling the pairwise term in GC, we incorporate edge information between neighboring superpixels to reduce under--segmentation.  Experimental results on a set of challenging images demonstrate the effectiveness of our method by comparing it with the state-of-the-art approaches.", "paperid": 2512848639, "normalizedname_level1": "artificial intelligence"}
{"index": 289, "text": "In this poster, we present our recent work, a wearable system for achieving real-time 3D arm skeleton. We have coped with the major challenge that the skeleton of each arm is determined from the locations of the elbow and wrist, whereas a wearable device only senses a single point from the wrist. Result shows that the potential solution space is huge. This underconstrained nature fundamentally challenges the achievement of accurate and real-time arm skeleton tracking. In this study, we propose Hidden Markov Model (HMM) state reorganization and hierarchical search two methods to improve the heavyweight computation of the state-of-art arm tracking model and achieve real-time tracking even on mobile phone.", "paperid": 2953104151, "normalizedname_level1": "artificial intelligence"}
{"index": 290, "text": "Radiomics, an emerging field of quantitative imaging, encompasses a broad class of analytical techniques. Recent literature have interrogated associations between quantitatively derived GLCM-based texture features and clinical/pathology information using machine learning algorithms in many cancer settings, but often fail to elucidate the predictive power of these features. Moreover, for many cancers characterized by complex histopathological profiles, such as adrenocortical carcinoma, reducing the multivariate functional structure of GLCM to a set of summary statistics is potentially reductive, masking the patterns that distinguish malignancy from benignity. We develop a Bayesian probabilistic framework for predictive classification of lesion types, based on the entire GLCM. Our method, which uses a spatial Gaussian random field to model dependencies among neighboring cells of the GLCMs, was applied in a cancer detection context to discriminant malignant from benign adrenal lesions using GLCMs arising from non-contrast CT scans. Our method is shown to yield improved predictive power both in simulations as well as the adrenal CT application when compared to state-of-the-art diagnostic algorithms that use GLCM derived features.", "paperid": 2679842080, "normalizedname_level1": "artificial intelligence"}
{"index": 291, "text": "Providing robots with the ability to recognize objects like humans has always been one of the primary goals of robot vision. The introduction of RGB-D cameras has paved the way for a significant leap forward in this direction thanks to the rich information provided by these sensors. However, the robot vision community still lacks an effective method to synergically use the RGB and depth data to improve object recognition. In order to take a step in this direction, we introduce a novel end-to-end architecture for RGB-D object recognition called recurrent convolutional fusion (RCFusion). Our method generates compact and highly discriminative multi-modal features by combining RGB and depth information representing different levels of abstraction. Extensive experiments on two popular datasets, RGB-D Object Dataset and JHUIT-50, show that RCFusion significantly outperforms state-of-the-art approaches in both the object categorization and instance recognition tasks. In addition, experiments on the more challenging Object Clutter Indoor Dataset confirm the validity of our method in the presence of clutter and occlusion. The code is publicly available at: “\n https://github.com/MRLoghmani/rcfusion \n.”", "paperid": 2963901718, "normalizedname_level1": "artificial intelligence"}
{"index": 292, "text": "To solve the problem that single characteristic of radio transmitters in low-end receivers is not ideal for the individual identification of radiation sources, the algorithm that box dimension of Product Function (PF) decomposed by Local Mean Decomposition(LMD) fuses Rectangular Integral Bispectrum(SIB) is proposed. Firstly, the acquired time domain signal is decomposed by LMD to obtain a set of PFs, and the box dimension of the PF is used as the radiation source feature. Then, the SIB is estimated by the signal high-order spectrum, and the SIB after dimensionality reduction is taken as the feature. By Canonical Correlation Analysis (CCA), the two features are fused as the fusion feature, which is identified by Support Vector Machine (SVM). Finally, this algorithm is validated in experiments where USRP-2920 is regarded as the signal receiver. In the classification experiment of 6 walkie-talkies as signal source devices, the recognition rate of the fusion feature is 13%~28% higher than the single feature. This paper applies the LMD algorithm to the field of RF radiation source identification for the first time.", "paperid": 3080467699, "normalizedname_level1": "artificial intelligence"}
{"index": 293, "text": "Partial discharge detection is important for identifying insulation defects of power cables, and the extraction of effective characteristic parameters is the emphasis of the study. In this paper, a feature extraction method based on 2 Dimensions Littlewood — Pale empirical wavelet transform (2D-LPEWT) is proposed to realize the accurate identification of different types of defects in cable discharge. By constructing a cable-insulated partial discharge detection platform, three-dimensional spectrum of four typical defect models was decomposed by 2D-LPEWT. And then Tamura features, moments and entropy characteristics are extracted from the obtained wavelet coefficients sub-graphs, and the effects of different feature extraction methods on performance of KNN, decision tree and SVM are discussed. Results show that the proposed feature extraction method can achieve high recognition accuracy under different classifiers, and has good practicability.", "paperid": 2810912904, "normalizedname_level1": "artificial intelligence"}
{"index": 294, "text": "Despite the increasing attention to big data, there are several domains where labeled data is scarce or too costly to obtain. For example, for data from information retrieval, gene analysis, and social network analysis, only training samples from the positive class are annotated while the remaining unlabeled training samples consist of both unlabeled positive and unlabeled negative samples. The specific positive and unlabeled (PU) data from those domains necessitates a mechanism to learn a two-class classifier from only one-class labeled data. Moreover, because data from those domains is highly sensitive and private, preserving training samples privacy is essential. This paper addresses the challenge of private PU learning by designing a differentially private algorithm for positive and unlabeled data. We first propose a learning framework for the PU setting when the class prior probability is known, with a theoretical guarantee of convergence to the optimal classifier. We then propose a privacy-preserving mechanism for the designed framework where the privacy and utility are both theoretically and empirically proved.", "paperid": 2889434690, "normalizedname_level1": "artificial intelligence"}
{"index": 295, "text": "This paper presents a cloud-based positioning method that leverages visualized signal images through visual analytics and deep learning. At a mobile client, such as a smart phone, this approach transforms multidimensional signals captured at a known location and at a given time into a signal image and transmits such visual signal images to the Cloud. By collecting and storing many such visual signal images as fingerprints, we can build a visual signal image cloud and produce a signal image map for the geographical region of interest and utilize such signal image map to serve the positioning requests of mobile clients on the move. When a user Alice wants to know her current position, her mobile client will generate a signal image from the multiple signals it receives with timestamp and send this query image to a Cloud server. The server searches the existing signal images stored in the cloud to find those that are similar to this query signal image and estimates the positioning of Alice based on the locations of those similar signal images collected by the server. We evaluate our visual signal images based positioning system on the entire two floors of a large department store and on the street and shops outside the department store, with the signal images collected over 30 minutes before serving positioning queries. The mean error of up to 4 meters is observed. To further verify the applicability of the proposed method, extensive experiments were conducted to distinguish whether a user is indoor or outdoor by applying a deep learning algorithm with 60% of signal images collected for training and 40% signal images for testing. This experiment shows that the proposed method is able to distinguish indoor and outdoor with accuracy of about 95%.", "paperid": 2754158589, "normalizedname_level1": "artificial intelligence"}
{"index": 296, "text": "This paper proposes two methods of separation of VLC signals, based on the stadistical variation 1) FastIca and 2) InfoMax, the first one based in the stadistical covariance of the negentrophy and the second one based in the artificial neural network for the analysis of covariance of the values from signals. This values are results of a simulation and experimental transference of information through Visible Light Communication, the simulation without noise, and the experimental process with noise.", "paperid": 2787653702, "normalizedname_level1": "artificial intelligence"}
{"index": 297, "text": "The aim of this paper attempts to produce panoramic holography image using HoloAD environment and adjust the rotation speed for 360° video. In this paper, we proposed scale invariant feature transform(SIFT) algorithm to adjust rotation speed of objects of video, and filmed cut the 0°, 90°, 180° and 270°of objects. The results of this paper shows efficient panoramic image processing and well quality of holographic image.", "paperid": 2741221845, "normalizedname_level1": "artificial intelligence"}
{"index": 298, "text": "Virtual simulation testing is becoming indispensable for the intelligence testing of intelligent vehicles. However, even the most advanced simulation software provides rather limited test conditions. In the long run, intelligent vehicles are expected to work at SAE (Society of Automotive Engineers) level 4 or level 5. Researchers should make full use of virtual simulation scenarios to test the visual intelligence algorithms of intelligent vehicles under various imaging conditions. In this paper, we create realistic artificial scenes to simulate the self-driving scenarios, and collect a dataset of synthetic images from the virtual driving scenes, named “ParallelEye-CS”. In the artificial scenes, we can flexibly change environmental conditions and automatically acquire accurate and diverse ground-truth labels. As a result, ParallelEye-CS has six ground-truth labels and includes twenty types of tests, which are divided into normal, environmental, and difficult tasks. Furthermore, we utilize ParallelEye-CS in combination with other publicly available datasets to conduct experiments for visual object detection. The experimental results indicate that: 1) object detection algorithms of intelligent vehicles can be tested under various scenario challenges; 2) mixed dataset can improve the accuracy of object detection algorithms, but domain shift is a serious issue worthy of attention.", "paperid": 2969446427, "normalizedname_level1": "artificial intelligence"}
{"index": 299, "text": "The growing diffusion of robotics in our daily life demands a deeper understanding of the mechanisms of trust in human-robot interaction. The performance of a robot is one of the most important factors influencing the trust of a human user. However, it is still unclear whether the circumstances in which a robot fails to affect the user's trust. We investigate how the perception of robot failures may influence the willingness of people to cooperate with the robot by following its instructions in a time-critical task. We conducted an experiment in which participants interacted with a robot that had previously failed in a related or an unrelated task. We hypothesized that users' observed and self-reported trust ratings would be higher in the condition where the robot has previously failed in an unrelated task. A proof-of-concept study with nine participants timidly confirms our hypothesis. At the same time, our results reveal some flaws in the design experimental, and encourage a future large scale study.", "paperid": 3016136523, "normalizedname_level1": "artificial intelligence"}
{"index": 300, "text": "With the rapid development of large-scale survey plans, the automatic classification of massive celestial spectrum data has urgently become an important research project. This paper presents the principle that based on density and improved density clustering algorithm — The Manhattan Distance density algorithm(MD-DBSCAN), applied to a variety of spectral data. According to the United States SDSS-DR8 astronomical spectral data, compared to three algorithms of DBSCAN, NED-DBSCAN, MD-DBSCAN performance, then give the corresponding conclusions, the average classified stable number of the MD-DBSCAN algorithm is smaller and computing time is shorter.", "paperid": 2791103944, "normalizedname_level1": "artificial intelligence"}
{"index": 301, "text": "This paper studies on the image segmentation method of Lingwu Long Jujubes based on a new extraction model of hue to improve the accuracy of extracting images of Lingwu Long Jujubes. According to the characteristics that color components of Lingwu Long Jujubes in RGB color space have different distribution in a shadow environment or others, a extraction model of hue aiming at images of Lingwu Long Jujubes based on stage treatment of R component is built to extract hue information. And the difference between the target object and the background object is increased by using color difference. Then, the image is segmented by optimal threshold obtained by combining the maximum entropy and the mathematical criteria to achieve the adaptive adjustment of the segmentation threshold. Finally, the segmented image will be obtained through dealing with mathematical morphology. By comparing the segmentation effect of 30 Lingwu Long Jujubes images with artificial methods and other methods, it proves that the color image segmentation method of Lingwu Long Jujubes based on a new extraction model of hue has good effect to extract the object region. The accuracy of the segmentation rate is up to 92.6883%. The time that the algorithm run is 1.3107 s.", "paperid": 2736757527, "normalizedname_level1": "artificial intelligence"}
{"index": 302, "text": "In this paper we propose the model of signal for objects that are subject to evaluation by crowdsourcing. Such signal, constructed as probability of distribution using Normal Random Utility Model (NRUM), can be used to measure object's performance, create rankings or predict next evaluations. Our model is designed for monadic scale evaluations where evaluators can have different expertise or bias for using scale. Moreover, our model is constructed for situations where we can have a lot of missing evaluations or varying numbers of evaluations for each object and from each evaluator, typical for crowdsourcing data. We have built a model for medical Web pages credibility from real crowdsourcing data and have evaluated the model's predictive ability, proving its superiority to alternative prediction methods.", "paperid": 2574387732, "normalizedname_level1": "artificial intelligence"}
{"index": 303, "text": "In this paper, we propose super-pixel based finger earth mover’s distance (SPFEMD) for hand gesture recognition. For finger representation, we design SPFEMD for similarity measurement between fingers and hand gestures, and use it as the distance metric for hand gesture recognition. First, we extract hands without any user interaction using both color and depth from Kinect camera. Then, we obtain the seed for hand segmentation on the depth map and segment hand on the color image using the seed. Since fingers contain distinct features for hand gesture recognition, we decompose the hand segment into palm and fingers based on morphological operation. Finally, we perform hand gesture recognition from fingers based on SPFEMD. Experiments on publicly available and our own data sets show the superiority of the proposed method over state-of-the-arts in terms of accuracy and confusion matrices.", "paperid": 2939300442, "normalizedname_level1": "artificial intelligence"}
{"index": 304, "text": "Stock prediction has been a popular research topic and researchers have done a lot of work in this field. Due to its stochastic nature, predicting the future stock market remains a very difficult problem. This paper studies the application of attention-based LSTM deep neural network in future stock market movement prediction. We also build stock aggregate dataset and individual dataset including stock history data, financial tweets sentiment and technical indicators in the US stock market. The experiment studies the time sensitivity of finance tweet sentiment and methods of collective sentiment calculation. This paper also experiments on conventional LSTM and attention-based LSTM for performance comparison. We find the finance tweets that are posted from market closure to market open in the next day has more predictive power on next day stock movement. The weighted sentiment on max follower on StockTwits also outperforms other methods. In our experiment, the result on our individual stock dataset shows a similar pattern like normal distribution.", "paperid": 3006726006, "normalizedname_level1": "artificial intelligence"}
{"index": 305, "text": "The muscle synergy concept provides the best framework to understand motor control and it has been recently utilised in many applications such as prosthesis control. The current muscle synergy model relies on decomposing multi-channel surface Electromyography (EMG) signals into a synergy matrix (spatial mode) and its weighting function (temporal mode). This is done using several matrix factorisation techniques, with Non-negative matrix factorisation (NMF) being the most prominent method. Here, we introduce a 4th-order tensor muscle synergy model that extends the current state of the art by taking spectral information and repetitions (movements) into account. This adds more depth to the model and provides more synergistic information. In particular, we illustrate a proof-of-concept study where the Tucker3 tensor decomposition model was applied to a subset of wrist movements from the Ninapro database. The results showed the potential of Tucker3 tensor factorisation in finding patterns of muscle synergies with information about the movements and highlights the differences between the current and proposed model.", "paperid": 3104591999, "normalizedname_level1": "artificial intelligence"}
{"index": 306, "text": "Recurrent neural networks are a type of neural network which was developed for handling sequential data more efficiently. Unlike feedforward neural networks, RNNs can use their internal state to process input sequences. A recurrent network can be implemented in many ways like Long Short Term Memory cell (LSTM), Gated Recurrent Unit (GRU), multidimensional LSTM, bidirectional LSTM, etc. In this paper, we have implemented variants of RNN. We have trained the models using conventional training technique as well as using a sliding window training technique. Later on in this paper, we have compared these techniques based on their performances and concluded which technique and model produce the best result for different datasets.", "paperid": 3023358479, "normalizedname_level1": "artificial intelligence"}
{"index": 307, "text": "Combinatorial testing (CT) is a widely-used technique to detect system interaction failures. To improve the test effectiveness of CT, prioritized combinatorial testing inputs priority weights of parameter-values, and generates combinatorial test suites based on the weights. This paper proposes a method to automatically determine the weights of parameter-values by Bayesian inference using previous testing results. Using two open source projects, we evaluate the fault detection effectiveness of the proposed weighting based prioritized combinatorial testing.", "paperid": 2605951069, "normalizedname_level1": "artificial intelligence"}
{"index": 308, "text": "In order to solve the problems of real-time beat tracking, such as the uncertainty of real beat value, the difficulty of getting close to people’s perception of music and the position of beat according to people’s feelings, the fact that most data sets are private and the amount of data is small, which affects the accuracy of experimental results, a real-time beat tracking method based on lstm neural network is proposed, which abandons the traditional idea of beat tracking to determine the position of beat, divides the beat into five levels according to the degree of strength, and then trains the beat information by using lstm network. Experiments show that the system functions well and the accuracy of the training results is guaranteed to reach 0.946.", "paperid": 2907672190, "normalizedname_level1": "artificial intelligence"}
{"index": 309, "text": "In the production process, the LCD screen will inevitably have various defects such as dead pixels, had lines, and block defects. Among them, the Mura defect is one of the defects with high misdetection rate because of its low contrast and blurred contour. This paper studies the detection of Mura defect and proposes the following innovations: (1) Compared with other low-pass filters, filtering periodic high frequency texture background by Gabor filters can enhance the local contrast of the Mura region effectively. (2) In order to remove the effect of uneven brightness while retaining the Mura defect, the image is subjected to brightness equalization based on Retinex theory, which enhances the global contrast of the Mura region. (3) Under the premise of retaining defect information, the image is downsampled by selecting appropriate coefficients through experiments, which improves the efficiency of the algorithm. This method was tested with the sample images collected at the industrial site. The detection accuracy reached 93.6% and the average detection time is 0.632 seconds, which meet the requirements of industrial detection. Key Words: Machine Vision, Mura Defect Detection, Gabor Filter, Retinex Theory", "paperid": 3049748746, "normalizedname_level1": "artificial intelligence"}
{"index": 310, "text": "We propose a methodology for designing dependable Artificial Neural Networks (ANNs) by extending the concepts of understandability, correctness, and validity that are crucial ingredients in existing certification standards. We apply the concept in a concrete case study for designing a highway ANN-based motion predictor to guarantee safety properties such as impossibility for the ego vehicle to suggest moving to the right lane if there exists another vehicle on its right.", "paperid": 2964089174, "normalizedname_level1": "artificial intelligence"}
{"index": 311, "text": "Interactive ray tracing applications running on commodity hardware can suffer from objectionable temporal artifacts due to a low sample count. We introduce stable ray tracing, a technique that improves temporal stability without the over-blurring and ghosting artifacts typical of temporal post-processing filters. Our technique is based on sample reprojection and explicit hole filling, rather than relying on hole-filling heuristics that can compromise image quality. We make reprojection practical in an interactive ray tracing context through the use of a super-resolution bitmask to estimate screen space sample density. We show significantly improved temporal stability as compared with supersampling and an existing reprojection techniques. We also investigate the performance and image quality differences between our technique and temporal antialiasing, which typically incurs a significant amount of blur. Finally, we demonstrate the benefits of stable ray tracing by combining it with progressive path tracing of indirect illumination.", "paperid": 2736741156, "normalizedname_level1": "artificial intelligence"}
{"index": 312, "text": "This paper presents a Robotics laboratory conceived for the Electrical Engineering students. The laboratory work comprises two stages - a preliminary one, in which they apply Robotics concepts by means of ready to use platforms, and a second one, when the students are engaged in a complex project, whose goal is to develop their own platform. There are detailed the work stages, emphasizing both the trainer and the students' activities.", "paperid": 2609027038, "normalizedname_level1": "artificial intelligence"}
{"index": 313, "text": "This paper introduces a framework based on the LMS algorithm for sequential deconvolution of hyperspectral images acquired by industrial pushbroom imaging systems. Considering a sequential model of image blurring phenomenon, we derive a sliding-block zero-attracting LMS algorithm with spectral regularization. The role of each hyper-parameter is discussed. The performance of the algorithm is evaluated using real hyperspectral data.", "paperid": 2725482130, "normalizedname_level1": "artificial intelligence"}
{"index": 314, "text": "The experts uses chest Computed Tomography (CT) images to manually analyze the presence of cancerous nodule during cancer screening process. Due to heterogeneous and low intensity nature of CT image, manual image analyzing becomes difficult which leads to different problems like false positive detection, consumption of huge analyzing time, observer error, etc. Developing an efficient automatic Computer Aided Detection (CAD) system is essential to reduce the frequency of missed lung cancer nodules, make diagnosis simpler and time saving. The CAD system improves the accuracy of lung tumor detection and survival rate of the patient. In this paper, a fully automated model is presented for NSCLC nodule(s) segmentation from CT scan image. The proposed method follows four steps: (1) Preprocessing, (2) Automatic Lung Parenchyma Extraction and Border Repair (ALPE&BR), (3) Automatic lung nodules segmentation using Connected Component Analysis (CCA) and Threshold BasedMathematical Nodule (TBMN) refinement algorithm and (4) Nodules filtering using Hounsfield Unit (HU) value and true cancerous nodule extraction. The ALPE&BR method consists of Automatic Single Seeded Region Growing (ASSRG) algorithm for automatic lung parenchyma extraction and novel hybrid border concavity closing algorithm to get clear lung boundary. The proposed method successfully segments the true cancerous nodules by filtering out false region such as vessels, bone, fat, soft tissues, etc. The proposed method can provide the SN of 99.41%, SP of 99.97%, FPR of 0.019%, DSC of 0.98, and accuracy of 99.97%. These results are used to demonstrate that the proposed method outperforms the existing lung nodule segmentation method.", "paperid": 3020155948, "normalizedname_level1": "artificial intelligence"}
{"index": 315, "text": "In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.", "paperid": 2910687636, "normalizedname_level1": "artificial intelligence"}
{"index": 316, "text": "With the rapid development of mobile Internet, online platforms such as social entertainment and e-commerce have brought a large number of unstructured texts containing sentiment polarity. Sentiment analysis of these texts can be used for public opinion analysis, product review and other tasks. Recent researches show great interest and success in using deep learning methods for sentiment analysis tasks. Among these contributions, Constituency Tree-LSTM has achieved good results because of its superior ability and tree structure to preserve sequence information over time. However, the model calculates the sentiment label of the node based mainly on its vector representation, while missing the sentiment information of its children. This paper proposes a parallel recursive Constituency Tree-LSTM (PRCT-LSTM), which combines recursive neural network with Constituency Tree-LSTM to achieve better performance. The node sentiment information propagates to the global evaluation through recursive neural networks. Therefore, the sentiment information of each node in the PRCT-LSTM structure consists of sentiment information generated by Constituency Tree-LSTM and the recursive model. In this way, we take more full usage of sentiment information. Experimental results manifest that the proposed model achieves a higher performance than the Constituency Tree-LSTM.", "paperid": 2994205078, "normalizedname_level1": "artificial intelligence"}
{"index": 317, "text": "Data-agnostic quasi-imperceptible perturbations on inputs are known to degrade recognition accuracy of deep convolutional networks severely. This phenomenon is considered to be a potential security issue. Moreover, some results on statistical generalization guarantees indicate that the phenomena can be a key to improve the networks' generalization. However, the characteristics of the shared directions of such harmful perturbations remain unknown. Our primal finding is that convolutional networks are sensitive to the directions of Fourier basis functions. We derived the property by specializing a hypothesis of the cause of the sensitivity, known as the linearity of neural networks, to convolutional networks and empirically validated it. As a byproduct of the analysis, we propose an algorithm to create shift-invariant universal adversarial perturbations available in black-box settings.", "paperid": 2890304135, "normalizedname_level1": "artificial intelligence"}
{"index": 318, "text": "We introduce a deep encoder-decoder architecture for image deformation prediction from multimodal images. Specifically, we design an image-patch-based deep network that jointly (i) learns an image similarity measure and (ii) the relationship between image patches and deformation parameters. While our method can be applied to general image registration formulations, we focus on the Large Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By predicting the initial momentum of the shooting formulation of LDDMM, we preserve its mathematical properties and drastically reduce the computation time, compared to optimization-based approaches. Furthermore, we create a Bayesian probabilistic version of the network that allows evaluation of registration uncertainty via sampling of the network at test time. We evaluate our method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our experiments show that our method generates accurate predictions and that learning the similarity measure leads to more consistent registrations than relying on generic multimodal image similarity measures, such as mutual information. Our approach is an order of magnitude faster than optimization-based LDDMM.", "paperid": 2963341239, "normalizedname_level1": "artificial intelligence"}
{"index": 319, "text": "Single image super-resolution (SISR) reconstruction for magnetic resonance imaging (MRI) has generated significant interest because of its potential to not only speed up imaging but to improve quantitative processing and analysis of available image data. Generative Adversarial Networks (GAN) have proven to perform well in image recovery tasks. In this work, we followed the GAN framework and developed a generator coupled with discriminator to tackle the task of 3D SISR on T1 brain MRI images. We developed a novel 3D memory-efficient residual-dense block generator (MRDG) that achieves state-of-the-art performance in terms of SSIM (Structural Similarity), PSNR (Peak Signal to Noise Ratio) and NRMSE (Normalized Root Mean Squared Error) metrics. We also designed a pyramid pooling discriminator (PPD) to recover details on different size scales simultaneously. Finally, we introduced model blending, a simple and computational efficient method to balance between image and texture quality in the final output, to the task of SISR on 3D images.", "paperid": 3020887200, "normalizedname_level1": "artificial intelligence"}
{"index": 320, "text": "The main challenge for single image dehazing is the lack of effective prior information for restoration. To address this issue, in this paper, we propose to generate artificial multiple shots for simulating the images captured under different haze degrees, and two context reasoning modules are developed to describe the relationship across different spatial regions and artificial shots. It brings two benefits in the inhomogeneous haze distribution. First, within one shot, the regions occluded in one location could be recovered with the help of other clear regions, which share the similar structures. Second, for the same spatial location, the regions distorted in one shot could be restored by means of other shots with clear content. We evaluate our method on different benchmark datasets. The results demonstrate that our method achieves superior performance over many state-of-the-art dehazing algorithms.", "paperid": 3091357435, "normalizedname_level1": "artificial intelligence"}
{"index": 321, "text": "Biomedical image analysis is one of the most challenging and inevitable part of the computer aided diagnostic systems. Automated analysis of the image can detect various diseases automatically without human intervention. Computer vision and artificial intelligence can sometimes defeat human diagnostic power and can reveal some hidden information from the biomedical images. In the field of health care, accurate results are highly required within stipulated amount of time. But to increase accuracy, proper preprocessing with sophisticated algorithms is required. Low quality image can affect processing algorithm which can leads to the poor result. Therefore, sophisticated preprocessing methods are required to get reliable results. Contrast is one of the most important parameter for any image. Poor contrast may cause several problems for computer vision algorithms. Conventional algorithms for contrast adjustment may not be suitable for many purposes. Sometimes, these methods can generate some images that may lose some critical information. In this work, a contrast optimization method based on well-known metaheuristic technique called genetic algorithm with elitism is used that can enhance the biomedical images for better analysis. A new kernel has been proposed to detect the edges. Obtained results illustrate the efficiency of the proposed algorithm.", "paperid": 2943787899, "normalizedname_level1": "artificial intelligence"}
{"index": 322, "text": "According to the principle of coordinate transformation, a calculation model of angle and distance truth is obtained by using photoelectric calibration device. The influence of the posture change of the ship and the measurement error of the equipment on the accuracy of the calibration system is analyzed, and the error calculation formula of the device distance and the angle truth is deduced based on the error transfer theory. The simulation results of Matlab are used to verify the accuracy of the proposed method.", "paperid": 2759653626, "normalizedname_level1": "artificial intelligence"}
{"index": 323, "text": "Advanced remote gaze estimation systems use automatic calibration procedure without requiring active user involving into the estimation of subject-specific eye parameters. Though automatic calibration process can simplify the difficulty of calibration task, it still needs time to collect information for completing the eye parameters of users before the gaze tracking system is used. This paper proposes a novel method, free of calibration procedure to extract subject-specific eye parameters. To estimate the real-time angles between the optical and visual axes of each eye before calculating the direction of the visual axes of the both the left and right eyes, differential evolution and Shuffled Frog-leaping Algorithm (DE-SLFA) is used to minimize the distance between the intersections of the visual axes of the left and right eyes with the surface of a display while subjects look naturally at the display. As a consequence, the inconvenient calibration procedure which may produce possible calibration errors can be eliminated. Computer simulation have been performed to confirm the proposed method.", "paperid": 2735242942, "normalizedname_level1": "artificial intelligence"}
{"index": 324, "text": "High definition (HD) camera is widely used in surveillance systems. An HD camera with optical zoom is useful for monitoring a large area. However, it is inconvenient for a user to manually control the optical zoom for a long time. To exploit the functionality and extend the application domains of a HD camera, the zooming should be controlled automatically. An automatic zooming mechanism is proposed in this paper. When an object moves through the field of view (FOV) of the camera, the zoom is controlled for capturing the object as clear as possible. In order to achieve the above goal, a Gaussian Mixture Model (GMM), temporal image differencing, a CamShift tracking method, and a Kalman filter are utilized for object detection and tracking. Then, an adaptive neuro-fuzzy inference system (ANFIS) is used to learn and determine a suitable value for adjusting the zoom. According to the experimental study of the prototype, the results show that the proposed mechanism is useful to capture the clear images of moving objects in a practical environment.", "paperid": 2296472520, "normalizedname_level1": "artificial intelligence"}
{"index": 325, "text": "In recent years, multi-agent systems have taken an increasingly important place in computer science, whether in the field of artificial intelligence, distributed systems, robotics, or even in this new field of “artificial life”, introducing the problematic of collective intelligence and the emergence of structures by interactions. Multi-agent systems provide a radically new solution to the concept of modeling and simulation in the environmental sciences, offering the opportunity to directly represent individuals, their behaviors and their interactions. The objective of this paper is the application of the techniques of the multi-agent approach in the simulation of the propagation of electromagnetic waves by FDTD method using Netlogo.", "paperid": 2909395097, "normalizedname_level1": "artificial intelligence"}
{"index": 326, "text": "Deep learning has recently developed as quickly rising field for the analysis of different medical images. Ultrasound (US) has developed as one of the most frequently clinically used imaging modalities. Although, it is a quickly developing technology but it also has challenges like low imaging quality and high variability. So, it is desirable to progressively develop techniques for automatic analysis of US images for diagnosis. Now a days, Deep learning is also widely used technique for analysis of many US images. In this review, we surveyed different deep learning techniques used for classification, detection, and segmentation along with the challenges of deep learning in US image analysis.", "paperid": 3004311026, "normalizedname_level1": "artificial intelligence"}
{"index": 327, "text": "In this paper, we propose Discriminative Collaborative Representation (DCR) as an extension to Collaborative Representation (CR), by adding an extra discriminative term to the original formulation of CR. In the literature, both CR and Sparse Representation (SR) have been shown to be good in signal classification. Compared to SR, CR is more computationally efficient, but does not give obvious performance improvement. Therefore, we propose DCR, which aims at improving the performance of CR in signal classification. Besides, we extend DCR to Kernel DCR (KDCR), which generalizes DCR by introducing kernel functions. Comparisons among SR, CR and DCR are made in doing two audio signal classification tasks. Experimental results show that DCR can outperform CR and SR in both classification tasks, which demonstrates the effectiveness of our proposed DCR and the usefulness of the extra discriminative term.", "paperid": 2902978475, "normalizedname_level1": "artificial intelligence"}
{"index": 328, "text": "This paper presents a new method for movement detection, based on the projection of the first eigenvalue obtained by using the Incremental Principal Component Analysis (IPCA). This is obtained assuming that the incremental computation of the eigenvalues using two images, simultaneously, produces an eigenvector that projects the maximum variability among both images and then, the movement can be estimated.", "paperid": 2766552659, "normalizedname_level1": "artificial intelligence"}
{"index": 329, "text": "In this paper, we describe a novel method to address the challenge of reconstructing the 3D shape of smooth transparent objects. Transparent objects will reflect the incident light; therefore the reflected light would carry cues of the surface received by the camera. We combine two mature methods to complete the 3D geometry acquisition: light-path triangulation and polarization analyses. We determine the normal vector by solving the degree of polarization; obtain the incidence vector and the reflection vector correspondingly with the help of the calibration for matching about pixels and the calibrated camera. The depth information of the surface could be acquired with figuring out the intersection of incidence and reflection. Our method shows excellent adaptability for measuring the complex shape and the structure of a transparent object. With the original mutual complementation for two methods, we could take advantage of the radiometric and geometric information to do the reconstruction. Compared with traditional techniques, we could obtain more clues than mere rebuilding with the single information. Obviously, multiform information will improve the result of the reconstruction and simplify the procedure of the measurement. We also dissect the measurement precision to appraise this method.", "paperid": 2627130583, "normalizedname_level1": "artificial intelligence"}
{"index": 330, "text": "Diversity is a key characteristic of a classifier ensemble. A classifier ensemble must be composed of base classifiers with different performance in different areas of the problem space. Several works studied different diversity measures by performing extensive numerical experiments. However, up to our knowledge, no method has been proposed to visualize the diversity of a classifier ensemble. In this contribution, we propose a novel approach to visualize and analyze classifier ensembles diversity. Our novel proposal (called DivGrams), allows the visualization of the diversity between base classifiers in the classifier ensemble by using a network representation. The nodes represent base classifiers and its edges represent diversity relations between the base classifiers. We apply DivGrams to fuzzy rule-based classifier ensembles, as in our previous work these machine learning models proved to deal well with complex classification problems. A preliminary experimental study is performed using two UCI datasets in order to show the usefulness of DivGrams. Furthermore, we show a practical application of DivGrams to develop manual classifier selection on eight UCI datasets. The results obtained show the interesting characteristics of our proposal and support this novel approach in the fuzzy classifier ensemble field.", "paperid": 2550601806, "normalizedname_level1": "artificial intelligence"}
{"index": 331, "text": "Tracking objects in infrared video sequences became a very important challenge for many current tracking algorithms due to several complex situations such as illumination variation, night vision, and occlusion. This study proposes a new tracker that uses a set of invariant parameters calculated via the co-occurrence moments to better describe the target object. The usage of the co-occurrence moments gives the ability to exploit the information about the texture of the target to enhance the robustness of the tracking task. This latter is performed without any learning or clustering phase. The qualitative and quantitative studies on challenging sequences demonstrate that the results obtained by the proposed algorithm are very competitive in comparison to several state-of-the-art methods.", "paperid": 2791543841, "normalizedname_level1": "artificial intelligence"}
{"index": 332, "text": "Loop closure detection is one of the important components of Visual SLAM. It can reduce the accumulating drift of visual odometer if the loops are detected correctly. Traditional loop closure detection mainly relies on the traditional algorithms to extract feature points. However, these algorithms are difficult to adapt to the complex and dynamic environment, e.g. illumination changes. In this paper, a new approach of loop closure detection is proposed. It learns inner structures from raw data using neural networks named SuperPoint. SuperPoint is designed to detect interest points and corresponding descriptors at the same time. The method clusters the feature descriptors as words using K-means and converts descriptors of each tested image into a vector by comparing the similarity between the descriptors and words. It measures the similarity of the images by calculating the cosine similarity of the corresponding vectors. A series of experiments on New College and City Center are demonstrated to evaluate the performance of the proposed method. The average precision of loop closure detection based on SuperPoint increases by 28% and 122% respectively compared with that based on SIFT and ORB under the same conditions. It is proved that the method based on SuperPoint is possible to detecti loops at a satisfactory precision compared with the traditional method based on ORB or SIFT.", "paperid": 3006330312, "normalizedname_level1": "artificial intelligence"}
{"index": 333, "text": "Facial expression is an important feedback of human feelings, and has always been the focus of human-computer interaction research. In recent years, with the rapid rise of artificial intelligence technology and the dramatic improvement of computing technology, the method of facial expression recognition has changed greatly, from the traditional machine learning method of image preprocessing, feature extraction and classification into classifier to the deep learning method based on large data cloud computing, and the recognition rate of facial expression has been remarkable. Raise. This paper introduces the common facial expression database, facial expression recognition based on classical machine learning method and popular deep learning method. Finally, the research of facial expression recognition is summarized and prospected.", "paperid": 2973081711, "normalizedname_level1": "artificial intelligence"}
{"index": 334, "text": "Online banking activities are constantly growing and are likely to become even more common as digital banking platforms evolve. One side effect of this trend is the rise in attempted fraud. However, there is very little work in the literature on online banking fraud detection. We propose an attention based architecture for classifying online banking transactions as either fraudulent or genuine. The proposed method allows transparency to its decision by identifying the most important transactions in the sequence and the most informative features in each transaction. Experiments conducted on a large dataset of real online banking data demonstrate the effectiveness of the method in terms of both classification accuracy and interpretability of the results.", "paperid": 2991368766, "normalizedname_level1": "artificial intelligence"}
{"index": 335, "text": "Certain situations require human intervention to identify the emotional condition of the subject. In order to automate this process, the paper explores the idea of applying the Fisher face method to build an accurate, reliable and automatic system accompanied by supervised classification methods such as K-nearest neighbor and artificial neural network for human emotion recognition as depicted in still images. The experimental analysis is performed on the popular Japanese female facial expression (JAFFE) database. We have explored the efficacy of the Fisher face model in classifying human emotion based on content obtained from facial images. We have used basic prototypic emotions as defined by Paul Ekman - happiness (H), sadness (S), surprise (SU), and neutral (N), as our four classes. The technique used for feature extraction of facial expression detection is local fisher discriminant analysis (LFDA) which performs dimensionality reduction. The supervised classification task is carried out by K-nearest neighbor (KNN) and artificial neural network (ANN) separately. It is observed that ANN performance is better in case of emotions like happiness and surprise while neutral and sad emotions are recognized better by KNN technique.", "paperid": 3007984744, "normalizedname_level1": "artificial intelligence"}
{"index": 336, "text": "Automatic identification of abnormal cervical cells, including feature representation, feature combination and classification strategy, is highly demanded in women's annual cervical cancer screenings. However, previous methods only deal with one or two of these three phases, and currently there is few complete framework for this problem. A novel three-phrase boosting framework is proposed for the detection of abnormal cells from cervical smear images. First, the authors extract 160 dimensional features with respect to each cervical cell from three aspects, including cytology morphology, chromatin pathology and region intensity. In particular, 106 dimensional chromatin pathology features are newly adopted to describe the nucleus textural transformation. Second, an adaptive feature combination method is introduced to select the optimal feature patterns, which can combine all features using a reinforced margin-based approach with the heuristic knowledge. Finally, a two-stage classification strategy is presented to reduce erroneous classification abnormal cells using two different classifiers. Experimental results achieve state-of-the-art performance and the proposed framework outperforms the other 16 compared detection methods.", "paperid": 2575111548, "normalizedname_level1": "artificial intelligence"}
{"index": 337, "text": "Although many stroke survivors are not fully capable of driving, they drive again without any formal assessment due to an absence of valid screening tools. This leads to an elevated risk of accidents. Although an on-road test is considered a standard assessment method for items relevant to actual driving, it may be dangerous to evaluate all stroke drivers with the on-road test. For safe pre-screening of unsuitable stroke drivers, we propose an automatic Driving Performance Assessment System for Stroke drivers (Driving-PASS). Driving-PASS aims to provide not only information about problematic driving assessment items but also a decision about fitness to drive. The problematic driving items are classified by abnormal classifiers while the decision item is determined by a decision classifier in Driving-PASS. For designing the system, we firstly propose a subjective assessment method consisting of ten assessment items and one decision item. And then, we propose an automated method of the subjective assessment method with a machine learning approach (i.e., ANN and SVM) by using assessment criteria from five expert's judgments. Evaluation results demonstrate that Driving-PASS automatically assess not only the ten assessment items (total average Accuracy of 90% and F1-score of 88%) but also the decision item (Accuracy of 93% and F1-score of 92%). We expect Driving-PASS provides analytical assessment results that can be used in driving rehabilitation programs and contributes to reducing the risk of vehicle accidents by pre-screening unsuitable stroke drivers with high accuracy and reliability.", "paperid": 2907815763, "normalizedname_level1": "artificial intelligence"}
{"index": 338, "text": "We describe a method to detect human movement using a single camera and construct a non-contact human interface in this paper. In this system, a virtual switch is set in the air, and when the user touches the virtual switch, built-in five videos can be sequentially switched. In order to examine the operation accuracy of the system, a total of 460 evaluation experiments were conducted. The evaluation experiments were conducted on two cases, i.e., the case where the operation was performed without passing through the glass and the case where the operation was performed through the glass. As a result, the success rate in the case of not passing the glass was 95.8%, the success rate in the case of passing the glass was 96.0%, both were a very high recognition success rate. From these result, we can say that this system is sufficiently practical as a human computer interface. Furthermore, it was confirmed that this system can be operated through the glass. This means that this system can be operated from the outside even if it is installed in the show window. When we install the proposed system to a computer with built-in camera, we can easily construct an inexpensive interactive digital signage without any external device.", "paperid": 2742390963, "normalizedname_level1": "artificial intelligence"}
{"index": 339, "text": "In this paper, we describe the relationship between the presence or absence of interest and the fixation time of face orientation. There is a conventional method of measuring the fixation time of line-of-sight orientation to prevent accidents due to carelessness. In addition, studies are being performed on the estimation of the relationship between face orientation and line-of-sight orientation. However, even if face and line-of-sight remain, it has not been confirmed whether people are interested. Therefore, we conducted experiments to investigate the relationship between the presence or absence of interest and the fixation time of face orientation. We simultaneously measured the change in interest and face orientation with time as subjects watched two movies. As a result, it was suggested that face orientation remained longer for an object of interest.", "paperid": 2792768360, "normalizedname_level1": "artificial intelligence"}
{"index": 340, "text": "Non-cosmic, non-Gaussian disturbances known as “glitches”, show up in gravitational-wave data of the Advanced Laser Interferometer Gravitational-wave Observatory, or aLIGO. In this paper, we propose a deep multi-view convolutional neural network to classify glitches automatically. The primary purpose of classifying glitches is to understand their characteristics and origin, which facilitates their removal from the data or from the detector entirely. We visualize glitches as spectrograms and leverage the state-of-the-art image classification techniques in our model. The suggested classifier is a multi-view deep neural network that exploits four different views for classification. The experimental results demonstrate that the proposed model improves the overall accuracy of the classification compared to traditional single view algorithms.", "paperid": 2611363611, "normalizedname_level1": "artificial intelligence"}
{"index": 341, "text": "The microbiome has been shown to have an impact on the development of various diseases in the host. Being able to make an accurate prediction of the phenotype of a genomic sample based on its microbial taxonomic abundance profile is an important problem for personalized medicine. In this paper, we examine the potential of using a deep learning framework, a convolutional neural network (CNN), for such a prediction. To facilitate the CNN learning, we explore the structure of abundance profiles by creating the phylogenetic tree and by designing a scheme to embed the tree to a matrix that retains the spatial relationship of nodes in the tree and their quantitative characteristics. The proposed CNN framework is highly accurate, achieving a 99.47% of accuracy based on the evaluation on a dataset 1967 samples of three phenotypes. Our result demonstrated the feasibility and promising aspect of CNN in the classification of sample phenotype.", "paperid": 2753944919, "normalizedname_level1": "artificial intelligence"}
{"index": 342, "text": "Since the start of industrialization, machine capabilities have increased in such a way that the control of processes by humans is becoming increasingly complex. This is especially the case in Intelligent Manufacturing Systems for which processes tend to be so autonomous that humans are more and more unaware of processes running, particularly when humans may need to intervene to update the manufacturing plan or to modify the process configuration if machines or intelligent entities need assistance. The present paper proposes solutions based on the use of Human(s)-Machine(s) Cooperation (HMC) principles to support humans in the process control. The aim of these principles is to adopt a human-centered approach for the design and evaluation of assistance systems and processes, as well as their interaction with humans. Two main complementary features of HMC, the know-how and the know-how-to-cooperate, are detailed. They provide a very useful approach to design task allocation, support for mutual understanding and communication between one human operator and one Artificial Self Organizing system. An assistance system resulting from this approach was evaluated and first results highlighted the improvement of global performance and acceptability.", "paperid": 2571355713, "normalizedname_level1": "artificial intelligence"}
{"index": 343, "text": "Genetic improvement uses automated search to find improved versions of existing software. Software can either be evolved with general-purpose intentions or with a focus on a specific application (e.g., to improve it's efficiency for a particular class of problems). Unfortunately, software specialisation to each problem application is generally performed independently, fragmenting and slowing down an already very time-consuming search process. We propose to incorporate specialisation as an online mechanism of the general search process, in an attempt to automatically devise application classes, by benefiting from past execution history.", "paperid": 2962297541, "normalizedname_level1": "artificial intelligence"}
{"index": 344, "text": "Object localization can be defined as the task of finding the bounding boxes of objects in a scene. Most of the state-of-the-art approaches utilize meticulously handcrafted training datasets. In this work, we are aiming to create a generative adversarial reinforcement learning framework, which can work without having any explicit bounding box information. Instead of relying on bounding boxes, our framework uses tightly cropped object images as training data. Our image localization framework consists of two parts: a reinforcement learning agent (RL agent) and a discriminator. The RL agent takes input scenes and crops them with the objective of creating a tightly cropped object image. The discriminator tries to distinguish whether the image is generated by the RL agent or it comes from a tightly cropped object database. Experiments indicate that it is possible to achieve a promising localization performance without having explicit bounding box data. It can be concluded that generative adversarial reinforcement learning is an important tool in dealing with other learning problems where explicit input/output paired data is not available.", "paperid": 2891934616, "normalizedname_level1": "artificial intelligence"}
{"index": 345, "text": "This research presents a complete study of a new alternating vector filter for the removal of impulsive noise in colour images. The method is based on an impulsive noise detector for greyscale images that has been adapted in a localised manner using geometric information for processing colour images. Based on this statistic, a filtering scheme alternating between the identity and a non-linear vector filter is proposed. A geometric and experimental study was performed to obtain the optimal filter design. Experimental studies show that the proposed technique is simple, easy to implement, robust to noise, and outperforms the classic vector filters, as well as more recent filters.", "paperid": 2249016826, "normalizedname_level1": "artificial intelligence"}
{"index": 346, "text": "Tongue manifestation is one of the most significant basic criteria for the diagnosis of Traditional Chinese Medicine (TCM). And tongue color recognition with high accuracy will contribute to the efficiency of TCM diagnosis. The drawbacks of traditional tongue diagnosis methods are that the features need to be designed artificially. While the feature acquisition from the deep learning is a process of simulating the brain activities and learning behaviors of human beings, and it has achieved fruitful results in many aspects, including image classification, face recognition, objects detection and so on. Therefore, the method combining deep learning with tongue color classification is proposed. First, the preprocessed and enhanced images are created as a tongue image database. Then, the parameters of the traditional network are modified for tongue color classification. Finally, it is more targeted to use our own model to fine-tune our neural networks. The experimental results show that this method is more practical and accurate than the traditional one.", "paperid": 2766922223, "normalizedname_level1": "artificial intelligence"}
{"index": 347, "text": "To jointly match multiply images for one specific object has more and more applications in practice. In this paper, given a small annotated subset as templates, we propose to jointly match a series target images by a novel idea: selecting the initial matching results by the bidirectional voting between template set and candidate set. In our method, firstly, the forward pairwise matching from template set to target set is performed. These matching results are denoted as candidates. When multiply results appear for one target, that means the matching results are inconsistent. Then, a novel screening method is proposed by the backward matching and voting, until all results reach consistent. Experiments conducted on various moving objects in the wild demonstrate the proposed method can overcome the matching difficulty by a single template and improve the matching accuracy under complex conditions.", "paperid": 2914811453, "normalizedname_level1": "artificial intelligence"}
{"index": 348, "text": "As an external manifestation of human emotions, expression recognition plays an important role in human-computer interaction. Although existing expression recognition methods performs perfectly on constrained frontal faces, there are still many challenges in expression recognition in natural scenes due to different unrestricted conditions. Expression classification belongs to a pattern recognition problem where intra-class distance is greater than the inter-class distance, which leads to severe over-fitting when using neural networks for expression recognition. This paper proposes a novel net-work structure called Dimension Reduction Network which can effectively reduce generalization error. By adding a data dimension reduction module before the general classification network, a lot of redundant information is filtered, and only useful information is left. This can reduce the interference by irrelevant information when performing classification tasks and reduce generalization error. The proposed method does not require any modification to the classification network, only a small dimension reduction module needs to be added in front of the classification network. However, it can effectively reduce generalization error. We designed big and tiny versions of Dimension Reduction Network, both exceeds our baseline on AffectNet data set. The big version of our proposed method surpassed the state-of-the-art methods by more than 1.2% on AffectNet data set. Our code will open source3 when the paper is accepted.", "paperid": 3091732393, "normalizedname_level1": "artificial intelligence"}
{"index": 349, "text": "Bone scintigraphy is difficult to understand the anatomical structure and quantitatively evaluate functions due to two-dimensional image, especially in the region such as sternum and pelvis, while bone SPECT providing three-dimensional image is useful for them. However, the imaging time of SPECT using many projection data is long. Shortening of the SPECT imaging time is desired. The aim of this study is to apply the image reconstruction method using total variation (TV) regularization to bone SPECT, and to examine the feasibility of bone SPECT from a small number of projections. In the image reconstruction, we used the expectation maximization-TV (EM-TV) algorithm consisting of the L1 norm regularization called TV, one of the methods of compressed sensing, and the maximum likelihood-expectation maximization (ML-EM) method, which is a statistical iterative image reconstruction method. First, it was validated by numerical phantom simulation that EM-TV algorithm could reconstruct a small number of projection data successfully. Next, bone SPECT imaging with 99mTc-MDP was performed using clinical SPECT-CT scanner, and image reconstruction was performed with equally spaced 12 out of 72 directions as projection data of a small number, and comparison with the conventional method, ML-EM, was performed. From results of bone SPECT study, the artifact which appears on the image reconstructed by ML-EM was dramatically improved by EM-TV reconstruction. In addition, EM-TV reconstruction significantly improved the quantitative accuracy in the region such as the pelvis. In conclusion, this study suggested the feasibility of bone SPECT with a small number of projections by EM-TV image reconstruction method.", "paperid": 3016194253, "normalizedname_level1": "artificial intelligence"}
{"index": 350, "text": "The rating prediction from a user to a product is one of the main reference of the recommendation systems widely used in E-commerce. The collaborative filtering algorithm is one of the most wildly used and successful approaches to predict the rating data. However, the rating data from many real-world scenarios is often sparse due to the difficulties of collection. How to improve the rating prediction algorithm with a sparse rating data becomes a real challenging problem. In this paper, we proposes an algorithm called UAD (User Attention Degree) based on the relationships between the number of rating times and the user attention. The algorithm predicts the user’s rating on an item taking account the impact from that user’s attention degree. The experimental results indicate that our algorithm can effectively improve the prediction accuracy.", "paperid": 2938548485, "normalizedname_level1": "artificial intelligence"}
{"index": 351, "text": "Understanding and predicting user behavior on online platforms has proved to be of significant value, with applications spanning from targeted advertising, political campaigning, anomaly detection to user self-monitoring. With the growing functionality and flexibility of online platforms, users can now accomplish a variety of tasks online. This advancement has rendered many previous works that focus on modeling a single type of activity obsolete. In this work, we target this new problem by modeling the interplay between the time series of different types of activities and apply our model to predict future user behavior. Our model, FM-Hawkes, stands for Fourier-based kernel multi-dimensional Hawkes process. Specifically, we model the multiple activity time series as a multi-dimensional Hawkes process. The correlations between different types of activities are then captured by the influence factor. As for the temporal triggering kernel, we observe that the intensity function consists of numerous kernel functions with time shift. Thus, we employ a Fourier transformation based non-parametric estimation. Our model is not bound to any particular platform and explicitly interprets the causal relationship between actions. By applying our model to real-life datasets, we confirm that the mutual excitation effect between different activities prevails among users. Prediction results show our superiority over models that do not consider action types and flexible kernels", "paperid": 2767214294, "normalizedname_level1": "artificial intelligence"}
{"index": 352, "text": "We consider the problem of sorting a densely cluttered pile of unknown objects using a robot. This yet unsolved problem is relevant in the robotic waste sorting business.", "paperid": 2963158400, "normalizedname_level1": "artificial intelligence"}
{"index": 353, "text": "In this paper, we propose a channel-wise interaction based binary convolutional neural network learning method (CI-BCNN) for efficient inference. Conventional methods apply xnor and bitcount operations in binary convolution with notable quantization error, which usually obtains inconsistent signs in binary feature maps compared with their full-precision counterpart and leads to significant information loss. In contrast, our CI-BCNN mines the channel-wise interactions, through which prior knowledge is provided to alleviate inconsistency of signs in binary feature maps and preserves the information of input samples during inference. Specifically, we mine the channel-wise interactions by a reinforcement learning model, and impose channel-wise priors on the intermediate feature maps through the interacted bitcount function. Extensive experiments on the CIFAR-10 and ImageNet datasets show that our method outperforms the state-of-the-art binary convolutional neural networks with less computational and storage cost.", "paperid": 2954048742, "normalizedname_level1": "artificial intelligence"}
{"index": 354, "text": "Dimensionality reduction is an important processing step for pattern recognition. Designing a new optimization goal is a popular method to improve the effect of the dimensionality decrease method. In this paper, we noted that the distribution density of data was not considered in the most classifiers, which may have a negative impact on the classifier. To overcome the above problem, a new optimization goal is designed under the distribution density of the data. In this optimization goal, the sample with smaller density owns larger impact for the optimization result, and then the density of sample could be adjusted to nearly the same in the low dimensional space. The experiments performed verified the proposed method in terms of classification performance.", "paperid": 2907294324, "normalizedname_level1": "artificial intelligence"}
{"index": 355, "text": "We introduce a deep learning based collision avoidance based on learning events accompanied by an online, semi-supervised learning algorithm that allows the learning agent to gain experiences and learn by itself without any preacquired training dataset through online trial-and-error approach. Using distance sequences as inputs, two procedures are performed in the proposed algorithm; data gathering procedure and learning procedure. Simulation results show that our system can achieve minimum of 99.86% up to 99.99% accuracy in classifying collision event from all possible events, allowing autonomous agent to navigate within simulated environments without collision.", "paperid": 2887175977, "normalizedname_level1": "artificial intelligence"}
{"index": 356, "text": "Distributed control has emerged as a major focus in the systems and controls area, with multiagent robotics playing a prominent role both as a canonical instantiation of a system, where control decisions must be made by individual nodes across an information-exchange network, and as a rich source of applications [1]-[5]. These applications include environmental monitoring [6], collective materials handling [7], construction [8], disaster response [9], and precision agriculture [10].", "paperid": 3003535010, "normalizedname_level1": "artificial intelligence"}
{"index": 357, "text": "In this article, we propose a novel method that can measure the similarity of FoV-tagged videos in two dimensions. Recently many researchers have focused on measuring the similarity of FoV-tagged videos. The similarity measurement of FoV-tagged videos plays an important role in various societal applications, including urban road networks, traffic, and geographic information systems. Our preliminary work introduced the Largest Common View Subsequences (LCVS) algorithm for computing the similarity of FoV-tagged videos. However, LCVS requires a high computational cost for calculating common viewable regions between two FoV-tagged videos. To handle this limitation, we propose the largest View Vector Subsequence (VVS) algorithm for reducing the computational cost of FoV-tagged videos. VVS uses the movement distances and the viewable direction distances to support the simplified vector-based similarity measurement. We demonstrate the superiority of our approach by comparing it with the Longest Common Subsequences (LCSS) and our prior work (LCVS). Our experimental results show that VVS outperforms the prior work in terms of the computational cost and enhances the versatility and stability of the similarity measurement.", "paperid": 3097012534, "normalizedname_level1": "artificial intelligence"}
{"index": 358, "text": "Alzheimer's disease (AD) has become a severe medical challenge. Advances in technologies produced high-dimensional data of different modalities including functional magnetic resonance imaging (fMRI) and single nucleotide polymorphism (SNP). Understanding the complex association patterns among these heterogeneous and complementary data is of benefit to the diagnosis and prevention of AD. In this paper, we apply the appropriate correlation analysis method to detect the relationships between brain regions and genes, and propose “brain region-gene pairs” as the multimodal features of the sample. In addition, we put forward a novel data analysis method from technology aspect, cluster evolutionary random forest (CERF), which is suitable for “brain region-gene pairs”. The idea of clustering evolution is introduced to improve the generalization performance of random forest which is constructed by randomly selecting samples and sample features. Through hierarchical clustering of decision trees in random forest, the decision trees with higher similarity are clustered into one class, and the decision trees with the best performance are retained to enhance the diversity between decision trees. Furthermore, based on CERF, we integrate feature construction, feature selection and sample classification to find the optimal combination of different methods, and design a comprehensive diagnostic framework for AD. The framework is validated by the samples with both fMRI and SNP data from ADNI. The results show that we can effectively identify AD patients and discover some brain regions and genes associated with AD significantly based on this framework. These findings are conducive to the clinical treatment and prevention of AD.", "paperid": 3006321375, "normalizedname_level1": "artificial intelligence"}
{"index": 359, "text": "This paper aims to better understand a new property of Phase Congruency (PC) based image processing technique. It is illustrated that by optimizing the PC orientation, the direction that contains maximum information can be detected in images with straight line segments. We formulate the Direction of Maximum Information (tDMI) and develop the PC orientation optimization paradigm to compute it in such images. We also develop the Holmholtz Principle and Hough Transform based Line Segment Detection (HP-LSD and HT-LSD) methods to compute tDMI. We apply these methods to identify tDMI in 32 test images corrupted with gaussian and speckle noises with different variances. All methods show fairly good robustness to the noise variance. However, the results show that the PC orientation optimization method detects tDMI with estimation errors significantly lower than those of HP-LSD and HT-LSD methods. Furthermore, PC estimates tDMI directly, whereas, HT-LSD and HP-LSD require to measure lines' widths and lengths. The worst estimation error is obtained by using HT-LSD method, with an average error 102.81% for images with straight line segments of the same thickness. The average error of HP-LSD method over all 32 test images and noise conditions is 47.58%. The average estimation error of PC method over all scenarios is 15.80%, which shows more than 30% and 70% improvement compared to HP-LSD and HT-LSD methods, respectively. The results also show that it is better to consider both maximum and minimum momentums into the PC orientation optimization.", "paperid": 2965777452, "normalizedname_level1": "artificial intelligence"}
{"index": 360, "text": "This article is part of a research work that aims to characterize the effect of the temperature at the myoelectric level in the human body, specifically in upper extremities in order to be applied to improve the prosthesis in the future. Surface electromyographic signals (sEMG) are currently being used for many medical applications, hence the importance of characterizing them in the best possible way. These signals are acquired and processed by electronic interfaces connected to the computer by means of a data acquisition card and processed in MatLab-Simulink. The study consists in comparing the times in which the significant changes in the surface electromyographic signal (sEMG) occur, considering that the only parameter that is being manipulated is the temperature and with the assumption that the rest of the parameters involved are kept constant. By using a statistical method like the AGLR (approximate generalized likelihood ratio) algorithm, it is being corroborated that there are changes at a myoelectric level when this variable affects the upper limb, to develop a mathematical model that will serve as a guide for temperature changes recognition patterns. The results obtained are favorable and open the possibility for this tool to perform real-time detection for future applications in this research.", "paperid": 2971912535, "normalizedname_level1": "artificial intelligence"}
{"index": 361, "text": "The progression of cells through the cell cycle is a tightly regulated process and is known to be key in maintaining normal tissue architecture and function. Disruption of these orchestrated phases will result in alterations that can lead to many diseases including cancer. Regrettably, reliable automatic tools to evaluate the cell cycle stage of individual cells are still lacking, in particular at interphase. Therefore, the development of new tools for a proper classification are urgently needed and will be of critical importance for cancer prognosis and predictive therapeutic purposes. Thus, in this work, we aimed to investigate three deep learning approaches for interphase cell cycle staging in microscopy images: 1) joint detection and cell cycle classification of nuclei patches; 2) detection of cell nuclei patches followed by classification of the cycle stage; 3) detection and segmentation of cell nuclei followed by classification of cell cycle staging. Our methods were applied to a dataset of microscopy images of nuclei stained with DAPI. The best results (0.908 F1-Score) were obtained with approach 3 in which the segmentation step allows for an intensity normalization that takes into account the intensities of all nuclei in a given image. These results show that for a correct cell cycle staging it is important to consider the relative intensities of the nuclei. Herein, we have developed a new deep learning method for interphase cell cycle staging at single cell level with potential implications in cancer prognosis and therapeutic strategies.", "paperid": 3082411567, "normalizedname_level1": "artificial intelligence"}
{"index": 362, "text": "The paper discusses the passive optical detection of small-sized targets moving through the air at overhead levels. An experimental module for a standalone locator to operate in real time is presented together with methods usable within the actual implementation of the underlying designer project. Within the supporting tests, an algorithm was developed to detect small particles in a video sequence, and every image of the sequence was properly processed. The applied processing tools or methods included shape detection, filtering, statistic image analysis, and algorithms for the detection of moving objects; the images with recorded movement were stored on an SD card. The resolution of the moving object to be detected can correspond to a value as low as one pixel. Respecting the scope of the analyzed problems, the authors describe in detail not only the entire detection algorithm but also the results obtained from the test algorithm and the actual device.", "paperid": 2555662015, "normalizedname_level1": "artificial intelligence"}
{"index": 363, "text": "Micro aerial vehicles (MAVs) are strongly limited in their payload and power capacity. In order to implement autonomous navigation, algorithms are therefore desirable that use sensory equipment that is as small, low-weight, and low- power consuming as possible. In this paper, we propose a method for autonomous MAV navigation and exploration using a low-cost consumer-grade quadrocopter equipped with a monocular camera. Our vision-based navigation system builds on LSD-SLAM which estimates the MAV trajectory and a semidense reconstruction of the environment in real-time. Since LSD-SLAM only determines depth at high gradient pixels, texture-less areas are not directly observed so that previous exploration methods that assume dense map information cannot directly be applied. We propose an obstacle mapping and exploration approach that takes the properties of our semidense monocular SLAM system into account. In experiments, we demonstrate our vision-based autonomous navigation and exploration system with a Parrot Bebop MAV.", "paperid": 3101233843, "normalizedname_level1": "artificial intelligence"}
{"index": 364, "text": "The paper addresses specific results of the study dealing with data analytic system development for scientific and technical solutions and technologies efficiency assessment and provides the comparison of the application results for different algorithms, including Random Forest, Extreme Gradient Boosting (XGBoost) as well as hybrid neural networks. In order to illustrate practical results of the proposed system, the analysis of the effectiveness and feasibility of scientific and technical solutions and technologies was carried out for the Power & Energy Sector of Russia, namely for the innovation projects, dealing with energy efficiency and energy saving and presented at business incubator competitions and/or submitted to state scientific foundations for the period from 2010 ti112017. The paper provides the result of the classification accuracy analysis for the algorithms under consideration. The obtained results characterize the gradient boosting over decision trees as fairly reliable with an accuracy of 89,4%. In addition to the generally accepted metrics, precision and recall parameters were considered to improve the quality of the resulting error analysis.", "paperid": 3035777892, "normalizedname_level1": "artificial intelligence"}
{"index": 365, "text": "The use of robotics in controlled environments has flourished over the last several decades and training robots to perform tasks using control strategies developed from dynamical models of their hardware have proven very effective. However, in many real-world settings, the uncertainties of the environment, the safety requirements and generalized capabilities that are expected of robots make rigid industrial robots unsuitable. This created great research interest in developing control strategies for flexible robot hardware for which building dynamical models are challenging. In this paper, inspired by the success of deep reinforcement learning (DRL), we systematically study the efficacy of policy search methods using DRL in training flexible robots. Our results indicate that DRL is successfully able to learn efficient and robust policies for complex tasks at various degrees of flexibility. We also note that DRL using Deep Deterministic Policy Gradients can be sensitive to the choice of sensors and adding more informative sensors does not necessarily make the task easier to learn.", "paperid": 3003289094, "normalizedname_level1": "artificial intelligence"}
{"index": 366, "text": "Depth sensors used in autonomous driving and gaming systems often report back 3D point clouds. The lack of structure from these sensors does not allow these systems to take advantage of recent advances in convolutional neural networks which are dependent upon traditional filtering and pooling operations. Analogous to image based convolutional architectures, recently introduced graph based architectures afford similar filtering and pooling operations on arbitrary graphs. We adopt these graph based methods to 3D point clouds to introduce a generic vector representation of 3D graphs, we call graph 3D (G3D). We believe we are the first to use large scale transfer learning on 3D point cloud data and demonstrate the discriminant power of our salient latent representation of 3D point clouds on unforeseen test sets. By using our G3D network (G3DNet) as a feature extractor, and then pairing G3D feature vectors with a standard classifier, we achieve the best accuracy on ModelNet10 (93.1%) and ModelNet 40 (91.7%) for a graph network, and comparable performance on the Sydney Urban Objects dataset to other methods. This general-purpose feature extractor can be used as an off-the-shelf component in other 3D scene understanding or object tracking works.", "paperid": 2801933800, "normalizedname_level1": "artificial intelligence"}
{"index": 367, "text": "Recurrent neural networks (RNNs) have shown outstanding performance for natural language processing tasks, influenced by the repeated multiplication of the recurrent weight matrices, the problem of gradient vanishing and explosion problem will be encountered when training RNN. Independently recurrent neural network (IndRNN) makes neurons independent and constrains recursive weights to effectively solve gradient problems. We combine IndRNN with long short-term memory (LSTM) and attention model, and test it for text classification, the results show that our models can effectively adapt to text classification task.", "paperid": 3042780833, "normalizedname_level1": "artificial intelligence"}
{"index": 368, "text": "Deep learning has recently gained more and more popularity, because of its high accuracy and wide range of coverage. In particular, deep learning is widely used in the medical field. Because in the field of image classification and biological applications, the accuracy of deep learning is very high. Unfortunately, even under the collaborative deep learning, there is still serious risk of information leakage. Moreover, the risk of information leakage in the medical field is greater and the harm is even greater. For example, medical treatment data may be leaked to third-party organizations. When these important medical data is illegally used by for-profit organizations or obtained by criminals, it will not only lead to the disclosure of personal privacy information, but also cause serious economic losses to the victims. However, the victim cannot delete the leaked information by itself or limit the scope and use of the information that has been leaked. Therefore, the adverse effects are unimaginable. This paper mainly studies the information protection methods under GAN model attack, in order to find a better way to prevent attacks and effectively protect information.", "paperid": 2972751055, "normalizedname_level1": "artificial intelligence"}
{"index": 369, "text": "Localizing event-related cortical sources is a key factor while developing a computationally efficient Brain Computer Interface (BCI). This paper proposes a unified application of wavelet-based Maximum Entropy on the Mean (wMEM), as a channel selection method, for classifying two motor imagery (MI) tasks using optimal electroencephalography (EEG) sources. The EEG data, which are collected from publicly available BCI Competition III, are captured from five healthy individuals. This source optimization tool has been validated with a generic BCI framework, which utilizes common spatial pattern with and without regularization as preprocessing tools. However, the best classification accuracy attained is 98% using only 11 selected channels that is close to 100% attained using available 118 channels. This result summarizes how optimal EEG channels can be used to develop a BCI system without compromising the performance significantly.", "paperid": 2581259192, "normalizedname_level1": "artificial intelligence"}
{"index": 370, "text": "In this study, the authors propose a variational approach based on total generalised variation (TGV) and local gradient information to fuse multi-focus images as well as medical images of computed tomography and magnetic resonance. They use the second-order TGV as the regularisation term and local gradient information as the fusion weight to extract image features. To compute the new model effectively, the primal-dual algorithm is carried out. Various experiments are made to verify the effectiveness of the proposed methods.", "paperid": 2791177855, "normalizedname_level1": "artificial intelligence"}
{"index": 371, "text": "Recent progress in the field of person re-identification have shown promising improvement by designing neural networks to learn most discriminative features representations. Some efforts utilize similar parts from different locations to learn better representation with the help of soft attention, while others search for part based learning methods to enhance consecutive regions relationships in the learned features. However, only few attempts have been made to learn non-local similar parts directly for the person re-identification problem. In this paper, we propose a novel self attention based multi branch(classifier) network to directly model long-range dependencies in the learned features. Multi classifiers assist the model to learn discriminative features while self attention module encourages the learning to be independent of the feature map locations. Spectral normalization is applied in the whole network to improve the training dynamics and for the better convergence of the model. Experimental results on two benchmark datasets have shown the robustness of the proposed work.", "paperid": 3094968811, "normalizedname_level1": "artificial intelligence"}
{"index": 372, "text": "Fully supervised methods for semantic segmentation require pixel-level class masks to train, the creation of which is expensive in terms of manual labour and time. In this work, we focus on weak supervision, developing a method for training a high-quality pixel-level classifier for semantic segmentation, using only image-level class labels as the provided ground-truth. Our method is formulated as a two-stage approach in which we first aim to create accurate pixel-level masks for the training images via a bootstrapping process, and then use these now-accurately segmented images as a proxy ground-truth in a more standard supervised setting. The key driver for our work is that in the target dataset we typically have reliable ground-truth image-level labels, while data crawled from the web may have unreliable labels, but can be filtered to comprise only easy images to segment, therefore having reliable boundaries. These two forms of information are complementary and we use this observation to build a novel bi-directional transfer learning framework. This framework transfers knowledge between two domains, target domain and web domain, bootstrapping the performance of weakly supervised semantic segmentation. Conducting experiments on the popular benchmark dataset PASCAL VOC 2012 based on both a VGG16 network and on ResNet50, we reach state-of-the-art performance with scores of 60.2% IoU and 63.9% IoU respectively1.", "paperid": 2798683932, "normalizedname_level1": "artificial intelligence"}
{"index": 373, "text": "Using the iCub humanoid robot with an artificial pressure-sensitive skin, we investigate how representations of the whole skin surface resembling those found in primate primary somatosensory cortex can be formed from local tactile stimulations traversing the body of the physical robot. We employ the well-known self-organizing map algorithm and introduce its modification that makes it possible to restrict the maximum receptive field (MRF) size of neuron groups at the output layer. This is motivated by findings from biology where basic somatotopy of the cortical sheet seems to be prescribed genetically and connections are localized to particular regions. We explore different settings of the MRF and the effect of activity-independent (input-output connections constraints implemented by MRF) and activity-dependent (learning from skin stimulations) mechanisms on the formation of the tactile map. The framework conveniently allows one to specify prior knowledge regarding the skin topology and thus to effectively seed a particular representation that training shapes further. Furthermore, we show that the MRF modification facilitates learning in situations when concurrent stimulation at nonadjacent places occurs (“multitouch”). The procedure was sufficiently robust and not intensive on the data collection and can be applied to any robots where representation of their “skin” is desirable.", "paperid": 2570286934, "normalizedname_level1": "artificial intelligence"}
{"index": 374, "text": "In the field of SAR, the projector-camera system has been well studied; its radiometric model can be easily described by a color mixing matrix. Many SAR applications have proposed and created by using this model. However, this model can be used for reflectance component, but not for fluorescence component. In this paper, we propose RKS Projector-Camera response model for separating of the color mixing matrix's reflectance components and fluorescence components and describe how to decompose them.", "paperid": 2605304431, "normalizedname_level1": "artificial intelligence"}
{"index": 375, "text": "Long-term tracking of people in unconstrained scenarios is still an open problem due to the absence of constant elements in the problem setting. The camera, when active, may move and the appearance of both the background and the target may change abruptly, leading to the inadequacy of most standard tracking techniques. We propose to exploit a learning approach that considers the tracking task as a semisupervised learning problem. Given few target samples, the aim is to search for the target occurrences in the video stream, reinterpreting the problem as label propagation on a similarity graph. We propose a solution based on graph transduction that iteratively works frame by frame. In addition, to avoid drifting, we introduce an update strategy based on an evolutionary clustering technique that chooses the visual templates that better describe target appearance, evolving the model during the processing of the video. Since we model people’s appearance by means of covariance matrices on color and gradient information, our framework is directly related to structure learning on Riemannian manifolds. Tests on publicly available data sets and comparisons with state-of-the-art techniques allow us to conclude that our solution exhibits interesting performances in terms of tracking precision and recall in most of the considered scenarios.", "paperid": 2315889990, "normalizedname_level1": "artificial intelligence"}
{"index": 376, "text": "Presence detection is used in occupancy-based control to dynamically adjust energy-related appliances in smart buildings. Yet, practical applications typically suffer from high sensor unreliability. In our previous work, we suggested a Hidden Markov Model (HMM) for fusing information from multiple sources to better estimate the user state (presence/absence). We now extend this model and exploit information on the time-dependency of the probability of occupancy according to the time of the day. People generally have a typical working schedule, that is, occupants in an office arrive and leave every day at almost the same time. In this approach, we use our prior knowledge on office occupancy profiles to develop a time-dependent (in-homogeneous) HMM. Judging from our experiments, the algorithm shows improved performance, also, in a real-world test set-up where user presence and sensors error may not exactly follow our idealized model assumptions.", "paperid": 2795315366, "normalizedname_level1": "artificial intelligence"}
{"index": 377, "text": "Aspect-based sentiment classification aims to detect the sentiment polarity of a target in a given context. Most previous approaches use long short-term memory (LSTM) and attention mechanisms to predict the sentiment polarity of targets, which are usually complex and need more training time. Some previous approaches are based on convolutional neural networks (CNN) and gating mechanisms, which are much simpler, efficient and takes lesser convergence time than LSTM due to parallelized computations during training. However, such CNN-based networks ignore the separate modeling of targets via context-specific representations. In this paper, we propose a novel interactive gated convolutional network (IGCN) that uses a bidirectional gating mechanism to learn mutual relation between the target and corresponding review context. IGCN also uses positional information of context words with respect to the given target, POS tags, and domain-specific word embeddings for predicting the sentiment of a target. The experimental results on SemEval 2014 datasets show the effectiveness of our proposed IGCN model.", "paperid": 3003580126, "normalizedname_level1": "artificial intelligence"}
{"index": 378, "text": "Visual Simultaneous Localization and Mapping (vSLAM) is one of the key technologies in the field of robotics. The assumption of scene static is typical in SLAM algorithms. Such a strong assumption limits the use of most vSLAM systems in populated real-world environments. Recently, the semantic vSLAM systems towards dynamic scenes have gradually attracted more and more attentions. Existing semantic vSLAM system usually solely simply combines semantic information and motion check to obtain dynamic target contours, and delete all feature points on the contour. This article propose a new framework to exclude feature points using a mask produced by probabilistic mesh. It proposes to use superpoint segmentation to divide the picture into probabilistic meshs, and use the feature point matching relationship of historical frames to propagating probability, Only use the feature points in the low probability mesh to stably estimate camera motion. Experiments conducted on TUM’s RGBD dataset [15] show that the average accuracy of the camera trajectory estimated by this method is 90% higher than that of the original ORB-SLAM2 [1], and it is also compared with other SLAM systems that can cope with dynamic environments.", "paperid": 3102705261, "normalizedname_level1": "artificial intelligence"}
{"index": 379, "text": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.   In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.", "paperid": 2282821441, "normalizedname_level1": "artificial intelligence"}
{"index": 380, "text": "Content structure is an important aspect in the understanding of video. In this paper, we demonstrate that knowledge about the structure can improve the performance of content analysis operations such as feature extraction, shot transition, shot duration and activity. We have proposed two concepts with the aim to improve the performance of existing Video Shot detection methods. First, we have used a number of Transformations to convert the frames in a video sequence from intensity domain to various other domains. Second, we have used simple algorithms like Pixel Difference and Histogram Difference to the input video sequence of each Transform domain and demonstrate the Shot Detection on a database of Sports clips. The process of Domain Transformation is time intensive and requires high computational resources. Hence it is necessary to find memory handling and process distribution techniques to facilitate Video Shot Detection. In order to handle the seamless video sequence efficiently, we have proposed two different ways of handling the memory. Multithreading and Process Concurrency is the underlying principle employed in both these models. Finally the performance of the Video shot detection method with the best Transform Domain and best Memory model suitable for a real life application is determined.", "paperid": 2780549285, "normalizedname_level1": "artificial intelligence"}
{"index": 381, "text": "While recurring queries over evolving data are the bedrock of the analytical applications, resources demanded to process a large amount of data for each recurring execution can be a fatal bottleneck in cost-sensitive cloud computing environments. It is thus imperative to design a system responsive to users' preferences regarding how resources should be utilized. In this work, we propose PRO, a preference-aware recurring query processing system that optimizes recurring query executions complying with user preferences. First, we show that finding an optimal is an NP-complete problem due to the cost interdependencies between consecutive executions. We propose an execution relation graph (ERG) model that effectively incorporates these dependencies between executions. This model enables us to transform our problem into a well-known graph problem. We then design a graph-based approach (called PRO-OPT) leveraging dynamic programming and pruning techniques with pseudo-polynomial complexity. Our experiments confirm that PRO consistently outperforms state-of-the-art solutions by 9 fold in processing time under a rich variety of circumstances on the Wikipedia datasets.", "paperid": 2538135201, "normalizedname_level1": "artificial intelligence"}
{"index": 382, "text": "Path planning is an active area of research essential for many applications in robotics. Popular techniques include graph-based searches and sampling-based planners. These approaches are powerful but have limitations.This paper continues work to combine their strengths and mitigate their limitations using a unified planning paradigm. It does this by viewing the path planning problem as the two subproblems of search and approximation and using advanced graph-search techniques on a sampling-based approximation.This perspective leads to Advanced BIT*. ABIT* combines truncated anytime graph-based searches, such as ATD*, with anytime almost-surely asymptotically optimal sampling-based planners, such as RRT*. This allows it to quickly find initial solutions and then converge towards the optimum in an anytime manner. ABIT* outperforms existing single-query, sampling- based planners on the tested problems in ℝ4 and ℝ8, and was demonstrated on real-world problems with NASA/JPL-Caltech.", "paperid": 3091295346, "normalizedname_level1": "artificial intelligence"}
{"index": 383, "text": "This paper presents machine learning algorithms based on back-propagation neural network (BPNN) that employs sequential feature selection (SFS) for predicting the compressive strength of Ultra-High Performance Concrete (UHPC). A database, containing 110 points and eight material constituents, was collected from the literature for the development of robust models using machine learning techniques. The BPNN and SFS were used interchangeably to identify the relevant features that contributed with the response variable. As a result, the BPNN with the selected features was able to interpret more accurate results (r2 = 0.802) than the model with all the features (r2 = 0.489). It is concluded that the incorporation of ANN with SFS provided an improvement to the prediction model's accuracy, making it a viable tool for machine learning approaches in civil engineering case studies.", "paperid": 2981949820, "normalizedname_level1": "artificial intelligence"}
{"index": 384, "text": "Cross-modal hashing aims to map heterogeneous cross-modal data into a common Hamming space, which can realize fast and flexible retrieval across different modalities. Unsupervised cross-modal hashing is more flexible and applicable than supervised methods, since no intensive labeling work is involved. However, existing unsupervised methods learn the hashing functions by preserving inter- and intra-correlations while ignoring the underlying manifold structure across different modalities, which is extremely helpful in capturing the meaningful nearest neighbors of different modalities for cross-modal retrieval. Furthermore, existing works mainly focus on pairwise relation modeling while ignoring the correlations within multiple modalities. To address the above-mentioned problems, in this paper, we propose a multi-pathwaygenerativeadversarialhashing approach for unsupervised cross-modal retrieval, which makes full use of a generative adversarial network's ability for unsupervised representation learning to exploit the underlying manifold structure of cross-modal data. The main contributions can be summarized as follows: First, we propose a multi-pathwaygenerativeadversarialnetwork to model cross-modal hashing in an unsupervised fashion. In the proposed network, given the data of one modality, the generative model tries to fit the distribution over the manifold structure and selects informative data of other modalities to challenge the discriminative model. The discriminative model learns to distinguish the generated data and the true positive data sampled from the correlation graph to achieve better retrieval accuracy. These two models are trained in an adversarial way to improve each other and promote hashing function learning. Second, we propose a correlation graph-based approach to capture the underlying manifold structure across different modalities so that data of different modalities but within the same manifold can have a smaller Hamming distance to promote retrieval accuracy. Extensive experiments compared with state-of-the-art methods on three widely used datasets verify the effectiveness of our proposed approach.", "paperid": 2953037339, "normalizedname_level1": "artificial intelligence"}
{"index": 385, "text": "We propose a new traffic-sign detection method based on a weakly-supervised multi-purpose single convolutional neural architecture. The base classification network used is the very light convolutional architecture, MobileNetv2, which is used as a region proposal network, in addition to being a classification network. The method is divided into two stages; in the first stage MobileNetv2 is trained to suggest certain regions within the image to classify, while in the second stage it is trained to be a traffic-sign classifier. The method attained few milliseconds of processing time for single image or frame testing and averaged about 55 milliseconds on 800x1300 resolution, while maintaining an acceptable accuracy. This method takes advantage of weak supervision which completely eliminates the time required for dataset annotation. We trained and tested our proposed technique on two datasets that have been broadly used for traffic-sign recognition and detection: the German Traffic Signs Recognition Benchmark (GTSRB) and the German Traffic Signs Detection Benchmark (GTSDB).", "paperid": 3013040110, "normalizedname_level1": "artificial intelligence"}
{"index": 386, "text": "Detection and tracking humans in videos have been long-standing problems in computer vision. Most successful approaches (e.g., deformable parts models) heavily rely on discriminative models to build appearance detectors for body joints and generative models to constrain possible body configurations (e.g., trees). While these    $2$      D models have been successfully applied to images (and with less success to videos), a major challenge is to generalize these models to cope with camera views. In order to achieve view-invariance, these   $2$      D models typically require a large amount of training data across views that is difficult to gather and time-consuming to label. Unlike existing   $2$      D models, this paper formulates the problem of human detection in videos as spatio-temporal matching (STM) between a    $3$      D motion capture model and trajectories in videos. Our algorithm estimates the camera view and selects a subset of tracked trajectories that matches the motion of the    $3$      D model. The STM is efficiently solved with linear programming, and it is robust to tracking mismatches, occlusions and outliers. To the best of our knowledge this is the first paper that solves the correspondence between video and   $3$      D motion capture data for human pose detection. Experiments on the CMU motion capture, Human3.6M, Berkeley MHAD and CMU MAD databases illustrate the benefits of our method over state-of-the-art approaches.", "paperid": 2342651600, "normalizedname_level1": "artificial intelligence"}
{"index": 387, "text": "In this paper, we introduce PhoenixMap, a visual analytics system to help analysts understand spatiotemporal distribution patterns and anomalies of many objects. It focuses on solving two VA challenges. First, visualizing the spatial distribution of many points under different categories especially when these points partially overlap with each other; Second, employing visual means to classify bird calls using deep learning CNN method. This PhoenixMap system can successfully help us understand the change and patterns of birds regions over many years.", "paperid": 2969930472, "normalizedname_level1": "artificial intelligence"}
{"index": 388, "text": "In this study, an automated microscope was developed that mechanically focuses and captures images of the urine sediment for image recognition of four urine constituents in the urinalysis examination: (1) Red Blood Cells (RBC), (2) White Blood Cells (WBC), (3) Bacteria, and (4) Calcium Oxalates (CaC204) using PIC microcontroller. Automatic image-focusing and stage movement were successfully achieved using stepper motors interfaced with PIC18F25J50 microcontroller. The microcontroller circuit board was mounted and attached to the fine-adjustment and stage-control knob of the microscope. The Edge Detection Method using Prewitt operators and a proprietary algorithm for moving lens was efficiently used for image auto-focusing. Image acquisition and mechanical actuators of the microscope were integrated into a software, enabling automation of microscope operations. A Capture tab in the GUI was designed to gather 70 images of the urine sediment before the system starts to analyze the images. Digital image processing and Artificial Neural Network created in Matlab were used to recognize and count the constituents which were incorporated in the GUI. The result of urinalysis was generated in PDF. Implementation of the system was done using 100 urine samples by examining same specimen with the automated and manual microscopy at the same time. Overall, automated capturing and recognizing of the four most common urine constituents in the microscopic examination generate results with an average speed of 3.66 minutes and an accuracy of 89.5%.", "paperid": 2919998643, "normalizedname_level1": "artificial intelligence"}
{"index": 389, "text": "When we look towards the world of humans and robots harmonically working together in a social environment, the robots should behave in cultural norms. A culturally aware robot navigation is highly expected to enable mobile service robots to politely and respectfully navigate among humans in human-robot shared workspaces. In this paper, we present a foundation of culturally aware robot navigation for mobile service robots in a social environment. The culturally aware robot navigation system is developed by integrating extended personal spaces representing individual states and social interaction spaces representing human-robot interactions and human groups. The culturally aware robot navigation plays the role of human-aware decision making upon the conventional robot navigation system to ensure that a mobile service robot is capable of detecting and identifying social contexts and situations to culturally navigate in human appearances. Simulation results illustrate our methodological approach.", "paperid": 2566747533, "normalizedname_level1": "artificial intelligence"}
{"index": 390, "text": "Deep Learning has already proven to be the primary technique to address a number of problems. It holds further promise in solving more challenging problems if we can overcome obstacles, such as the lack of quality training data and poor interpretability. The exploitation of domain knowledge and application semantics can enhance existing deep learning methods by infusing relevant conceptual information into a statistical, data-driven computational approach. This will require resolving the impedance mismatch due to different representational forms and abstractions between symbolic and statistical AI techniques. In this article, we describe a continuum that comprises of three stages for infusion of knowledge into the machine/deep learning architectures. As this continuum progresses across these three stages, it starts with shallow infusion in the form of embeddings, and attention and knowledge-based constraints improve with a semideep infusion. Toward the end reflecting deeper incorporation of knowledge, we articulate the value of incorporating knowledge at different levels of abstractions in the latent layers of neural networks. While shallow infusion is well studied and semideep infusion is in progress, we consider Deep Infusion of Knowledge as a new paradigm that will significantly advance the capabilities and promises of deep learning.", "paperid": 3003973800, "normalizedname_level1": "artificial intelligence"}
{"index": 391, "text": "A novel multimodal method for the estimation of password strength was presented in Part I of this series of two papers. In this paper, the experimental framework used for the evaluation of the novel approach is described. The method is evaluated following a reproducible protocol, which includes a three-dimensional approach: 1) deterministic assessment; 2) statistical assessment; and 3) third parties assessment (thanks to the availability upon request of an executable application that integrates the multimodal meter). The key experiment of the protocol compares, from a probabilistic point of view, the strength distributions assigned to passwords broken with increasingly complex attacking approaches, following a common strategy in a typical password cracking session. The experimental evaluation is carried out not only for the new meter, but also for other strength estimators from the state of the art, comparing their overall performance. In addition to its consistent results, the proposed method is highly flexible and can be adjusted to specific environments or to a certain password policy. Furthermore, it can also evolve over time in order to naturally adjust to new password selection trends followed by users.", "paperid": 2736745396, "normalizedname_level1": "artificial intelligence"}
{"index": 392, "text": "Causality analysis of simultaneous measurements of the brain's electrical activity and its hemodynamic activity provides the opportunity to study the neural underpinning of hemodynamic fluctuations. This multimodal analysis can also be used to extract valuable information regarding the location of the generators of various electrical events such as Alpha rhythms or epileptiform activity. To best of our knowledge, we are the first propose a method to assess causality from EEG to the hemodynamic activity measured using functional near-infrared spectroscopy (fNIRs). The main challenge in studying causality within this setting arises from the low sampling rate of the fNIRs and the mixed frequency nature of the data. Our method of analysis consists of two parts. Through a simple modification of Geweke's formulation of contamination, we first show that the low sampling frequency of the fNIRs does not cause contamination in estimating causality from EEG to fNIRs. We then apply a novel causality test to avoid the down-sampling of the EEG when measuring for causality. The method of analysis proposed here can be generalized to study causality in other biomedical signal analysis applications and mixed frequency settings.", "paperid": 2577083640, "normalizedname_level1": "artificial intelligence"}
{"index": 393, "text": "This paper presents a vision system and a depth processing algorithm for DRC-HUBO+, the winner of the DRC finals 2015. Our system is designed to reliably capture 3D information of a scene and objects and to be robust to challenging environment conditions. We also propose a depth-map upsampling method that produces an outliers-free depth map by explicitly handling depth outliers. Our system is suitable for robotic applications in which a robot interacts with the real-world, requiring accurate object detection and pose estimation. We evaluate our depth processing algorithm in comparison with state-of-the-art algorithms on several synthetic and real-world datasets.", "paperid": 2964090275, "normalizedname_level1": "artificial intelligence"}
{"index": 394, "text": "Dongba hieroglyphs are the only living hieroglyphs in the world today and are still used by people. The various ritual activities in Dongba culture are passed down through the Dongba hieroglyphs in the form of books. In view of the current classification and preservation of Dongba ancient books, it is a matter of labour-intensive time for translation, cataloguing, integration, and classification, so combining the methods of convolutional neural networks (CNN), an intelligent classification model is established to directly identify and classify ancient images. As the structure of the CNN has a great influence on the final recognition accuracy, a network structure that is most suitable for image recognition of Dongba ancient books is proposed. Experiments are performed on the Dongba image base established by myself and the result proves that the feasibility and effectiveness of this method.", "paperid": 2982219634, "normalizedname_level1": "artificial intelligence"}
{"index": 395, "text": "The recent increase in popularity of binary feature descriptors has opened the door to new lightweight computer vision applications. Most research efforts thus far have been dedicated to the introduction of new large-scale binary features, which are primarily used for keypoint description and matching. In this paper, we show that the side products of small-scale binary feature computations can efficiently filter images and estimate image gradients. The improved efficiency of low-level operations can be especially useful in time-constrained applications. Through our experiments, we show that efficient binary feature convolutions can be used to mimic various image processing operations, and even outperform Sobel gradient estimation in the edge detection problem, both in terms of speed and F-Measure.", "paperid": 2467323177, "normalizedname_level1": "artificial intelligence"}
{"index": 396, "text": "\"the Ghost in the Dandelion\" is an interactive installation features a physiological measuring device with facial recognition technology. The biosensor is able to analyze the facial expressions and heartbeat signals and convert them to the form of dandelion.", "paperid": 2768878675, "normalizedname_level1": "artificial intelligence"}
{"index": 397, "text": "Item recommendation is a personalized ranking task. To this end, many recommender systems optimize models with pairwise ranking objectives, such as the Bayesian Personalized Ranking (BPR). Using matrix Factorization (MF) - the most widely used model in recommendation - as a demonstration, we show that optimizing it with BPR leads to a recommender model that is not robust. In particular, we find that the resultant model is highly vulnerable to adversarial perturbations on its model parameters, which implies the possibly large error in generalization. To enhance the robustness of a recommender model and thus improve its generalization performance, we propose a new optimization framework, namely Adversarial Personalized Ranking (APR). In short, our APR enhances the pairwise ranking method BPR by performing adversarial training. It can be interpreted as playing a minimax game, where the minimization of the BPR objective function meanwhile defends an adversary, which adds adversarial perturbations on model parameters to maximize the BPR objective function. To illustrate how it works, we implement APR on MF by adding adversarial perturbations on the embedding vectors of users and items. Extensive experiments on three public real-world datasets demonstrate the effectiveness of APR - by optimizing MF with APR, it outperforms BPR with a relative improvement of 11.2% on average and achieves state-of-the-art performance for item recommendation. Our implementation is available at: \\urlhttps://github.com/hexiangnan/adversarial_personalized_ranking.", "paperid": 2798868970, "normalizedname_level1": "artificial intelligence"}
{"index": 398, "text": "We aim to determine the speed of ego-vehicle motion from a video stream. Previous work by Konda et al. [1] has shown that motion can be detected and quantified with the help of a synchrony autoencoder, which has multiplicative gating interactions introduced between its hidden units, and hence, across video frames. In this work we modify their synchrony autoencoder method to achieve a ”real time” performance in a wide variety of driving environments. Our modifications led to a model which is 1.5 times faster and uses only half of the total memory by comparison with the original. We also benchmark the speed estimation performance against a model based on CaffeNet. CaffeNet is known for visual classification and localization but we employ its architecture with a little tweak for speed determination using sequential video frames and blur patterns. We evaluate our models on self-collected data, KITTI, and other standard sets.", "paperid": 2741366276, "normalizedname_level1": "artificial intelligence"}
{"index": 399, "text": "Deep convolutional neural networks have achieved tremendous success in a variety of applications across many disciplines. However, their superior performance relies on correctly annotated large-scale datasets. It is very expensive and time-consuming to get the annotated large-scale datasets, especially in the medical field. While collecting a large amount of data is relatively easy, given the amount of data available on the web, but these data are highly unreliable, and they often include a massive amount of noisy labels. The past research works have shown that these noisy labels could significantly affect the performance of the deep convolutional neural networks on image classification. However, training a robust deep convolutional neural network with extremely noisy labels is a very challenging task. Inspired by the co-teaching concept, this paper proposes a novel method for training a robust convolutional neural network with extremely noisy labels, which is called group-teaching. Specifically, we train a group of convolutional neural networks simultaneously, and let them teach each other by selecting possibly clean samples for each network in each mini-batch. Each network back propagates the samples selected by other networks except itself and then it updates itself. The empirical results on noisy versions of CIFAR-10 and CIFAR-100 datasets demonstrate that our method is superior to the state-of-the-art methods in the robustness for noisy labels. Particularly, to verify the efficacy of our group-teaching in real-world noisy labels distribution, we have also validated the effectiveness of our method on the real-world noisy WebVision1000-100 dataset. The results show that our method has achieved higher performance than the state-of-the-art methods.", "paperid": 3008862545, "normalizedname_level1": "artificial intelligence"}
{"index": 400, "text": "How to leverage knowledge from labelled domain (source) to help classify unlabeled domain (target) is a key problem in the machine learning field. Unsupervised domain adaptation (UDA) provides a solution to this problem and has been well developed for two homogeneous domains. However, when the target domain is unlabeled and heterogeneous with the source domain, current UDA models cannot accurately transfer knowledge from a source domain to a target domain. Benefiting from development of neural networks, this paper presents a new neural network, shared fuzzy equivalence relations neural network (SFER-NN), to address the heterogeneous UDA (HeUDA) problem. SFER-NN transfers knowledge across two domains according to shared fuzzy equivalence relations that can simultaneously cluster features of two domains into several categories. Based on the clustered categories, SFER-NN is constructed to minimize the discrepancy between two domains. Compared to previous works, SFER-NN is more capable of minimizing discrepancy between two domains. As a result of this advantage, SFER-NN delivers a better performance than previous studies using two public datasets.", "paperid": 2980172942, "normalizedname_level1": "artificial intelligence"}
{"index": 401, "text": "Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.", "paperid": 3098953334, "normalizedname_level1": "artificial intelligence"}
{"index": 402, "text": "Origin-Destination (OD) flow data is an important instrument for traffic study and management. So far traditional ways like surveys or detectors are costly and only give limited availability of OD flows. Various statistical and stochastic models for OD flow estimation and prediction based on limited link volume data or automatic vehicle identification (AVI) data have been developed. However, smartphone-generated trajectory data has not been as much leveraged in this field, though the usage of smartphones in traveling is emerging in recent years. In this paper, we propose a semi-supervised deep learning based model that appropriately combines both AVI and smartphone trajectory data during training and is able to generate predictions of OD flows in an urban network solely based on the smartphone trajectory data at inference time. Our model can provide OD estimation and prediction services on larger spatial areas beyond the limited spatial coverage of AVI data. Tests of our model using real data have shown promising results, compared with an AVI input-dependent Kalman filter model. Potentially, our model can easily be embedded to a trajectory collecting platform and generate continuous real-time OD flow predictions online.", "paperid": 3007547063, "normalizedname_level1": "artificial intelligence"}
{"index": 403, "text": "Landmark detection and recognition algorithm is a very important technology for vision-based Unmanned Aerial Vehicles (UAVs) autonomous pitching. The deformation and rotation of landmarks and the background distraction will be the challenges for detection and recognition. Based on Support Vector Machine (SVM) and the appearance features of landmarks, a landmark detection and recognition algorithm is proposed in this paper. The algorithm presents a landmark detection scheme based on ellipse detection which forms ellipses by optimized arcs and estimates parameters in a decomposed space using Hough transform. To get better edge features, a segmentation is designed to reduce the background noise. Due to the lack of direction information of landmarks in detection procedure, a SVM classifier with a multi-direction voting mechanism is presented for recognition. We expand the training sample set through the affine transformation and make a vote on classification results from multiple directions to achieve accurate landmark recognition. Experimental results show that our landmark detection and recognition algorithm is effective on the UAV platform and the adaptability to the environment is strong.", "paperid": 3005655602, "normalizedname_level1": "artificial intelligence"}
{"index": 404, "text": "Medical image processing is a very active and fast-growing field that has evolved into an established discipline. Accurate segmentation of medical images is a fundamental step in clinical studies for diagnosis, monitoring, and treatment planning. Manual segmentation of medical images is a time consuming and a tedious task. Therefore the automated segmentation algorithms with high accuracy are of interest. There are several critical factors that determine the performance of a segmentation algorithm. Examples are: the area of application of segmentation technique, reproducibility of the method, accuracy of the results, etc. The purpose of this review is to provide an overview of current image segmentation methods. Their relative efficiency, advantages, and the problems they encounter are discussed. In order to evaluate the segmentation results, some popular benchmark measurements are presented.", "paperid": 2602594360, "normalizedname_level1": "artificial intelligence"}
{"index": 405, "text": "On the basis of the theory of S-space self-organization, the following have been presented: operator's personality model; classification of psychological (personality) types; means of testing; processing and presentation of results. On the basis of Markov's network decision-making models were proposed taking into consideration the circumstances of various flight situations. On the basis of the reflexive theory of bipolar choice the expected risks of decision-making by the Air Navigation System's operator influence of external environment, previous experience and intention were identified. The methods for analysis of decision-making by the human-operator in Air Navigation System using stochastic networks have been developed.", "paperid": 2562204572, "normalizedname_level1": "artificial intelligence"}
{"index": 406, "text": "In dynamic planar imaging, extraction of signals specific to structures is complicated by structures superposition. Due to overlapping, signals extraction with classic regions of interest (ROIs) methods suffers from inaccuracy, as extracted signals are a mixture of targeted signals. Partial volume effect raises the same issue in dynamic tomography. Source separation methods, such as factor analysis of dynamic sequences, have been developed to unmix such data. However, the underlying problem is underdetermined and the model used is not relevant in the whole image. This non-uniqueness issue was overcome by introducing prior knowledge, such as sparsity or smoothness, in the separation model. In practice, these methods are barely used because of the lack of reliability of their results. Previously developed methods aimed to be fully automatic, but efficiency can be improved with additional prior knowledge. Some methods using ROIs knowledge in a straightforward way have been proposed. In this paper, we propose an unmixing method, based on an objective function minimization and integrating these ROIs in a different and robust manner. The objective function promotes consistent solutions regarding ROIs while relaxing the model outside ROIs. In order to reduce user-dependent effects, ROIs are used as soft constraints in a robust way through the use of a distance matrix. Consistency, effectiveness, and robustness to the ROIs selection are demonstrated on a toy example, a highly realistic simulated renography data set and a clinical data set. Performance is compared with the competitive methods.", "paperid": 2763009002, "normalizedname_level1": "artificial intelligence"}
{"index": 407, "text": "Artificial Neural Network (ANN) is one of the promising domains in Artificial Intelligence (AI). With the development of engineering and research in AI, there are so many real time applications that use ANN for various classification and regression problems. It is important to analyze the performance of a neural network to know which kind of neural network provides best result to a particular kind of application. The performance can be analyzed using various transfer functions, training algorithms and performance functions. This paper analyses the performance of various linear and non linear transfer functions used in the hidden and output layer of the neural network by applying these transfer functions to various levels of classification problems involving datasets of three levels of complexity. Performance of artificial neural network for classification can be assessed using training, validation and testing accuracy. Various training algorithms and performance functions are also applied to the ANN along with different transfer functions.", "paperid": 2901486290, "normalizedname_level1": "artificial intelligence"}
{"index": 408, "text": "We investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images. This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based image retrieval application. We introduce a new database of 1,432 sketchphoto pairs from two categories with 32,000 fine-grained triplet ranking annotations. We then develop a deep tripletranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data. Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for finegrained cross-domain ranking tasks.", "paperid": 2467281799, "normalizedname_level1": "artificial intelligence"}
{"index": 409, "text": "Depending on the product category the authenticity of a consumer good concerns economic, social and/or environmental issues. Counterfeited drugs are a threat to patient safety and cause significant economic losses. Different from physical-marking based approaches this work investigates authentication of drugs based on intrinsic texture features of the packaging material. Therefore, it is assumed that the packaging material of a certain drug shows constant but discriminative textural features which enable authentication, i.e. to prove if the packaging material is genuine or not. This objective requires considering a binary classification problem with an open set of negative classes, i.e. unknown and unseen counterfeits. In order to investigate the feasibility a novel drug packaging texture databases was acquired. The experimental evaluation of two basic requirements in texture classification serves as an evidence on the basic feasibility.", "paperid": 2785703666, "normalizedname_level1": "artificial intelligence"}
{"index": 410, "text": "There is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. Additionally, several researches focus on sentence-based approaches, which can effectively deal with an attribute-sentiment word pair within one sentence. However, those approaches are unable to process more than one attribute within one sentence. In this paper, we first present an improved sentiment word quantitative method to generate sentiment score for every word in sentiment lexicon. Additionally, we propose a novel identification approach of attribute-modifier-sentiment word triple using shallow semantic information. Experimental results show the feasibility and effectiveness of our approach.", "paperid": 2803988148, "normalizedname_level1": "artificial intelligence"}
{"index": 411, "text": "RFID is a promising technology that uses source-free tags for object tracking. Multiple tags can be attached to a single object to improve the object detection probability. However, the total identification time may also multiplied due to the increased tag population. This letter presents a brother tags filtering-based identification scheme (BFI), which is the first scheme designed for multi-tagged object identification. The brother tags denote the tags attached to the same object. By iteratively identifying tags and filtering the remaining brother tags attached to the identified object, BFI avoids unnecessary brother tag transmission. Performance analysis and simulation results show that the proposed scheme performs much better than the existing anti-collisions schemes in time-efficiency.", "paperid": 2922407079, "normalizedname_level1": "artificial intelligence"}
{"index": 412, "text": "Face recognition is a method in Machine Learning to recognize objects in the picture or video. Humans have a memory to recognize other people and recognize some objects like animals, plants, living objects, and non-living objects. However, how the computer does that although it has memory? Machine Learning is the technique or method in Computer Vision that can be used, so computers can understand one person's face to another person contained in the image or video. In this paper, the author proposes about testing some popular Convolutional Neural Network (CNN) Model Architecture to see which one is better to recognize the person face dataset in disguised. The author uses the “Recognizing Disguised Faces” dataset to distinguish 75 classes of faces, and then try to train and test how accurate it can be recognized by the machine, where it will be useful to anyone who needs to explore and develop an Architecture of Deep Learning. This paper is expected to contribute to the field Machine Learning related algorithm that is used to solve the problem in image classification. The experimental results show significant improvement using transfer learning in VGG Models. We then conclude that ImageNet weight best used for face-recognizing using VGG Models.", "paperid": 3049455083, "normalizedname_level1": "artificial intelligence"}
{"index": 413, "text": "Image fusion is quite common in applications such as digital photography, medical imaging, surveillance and remote sensing. Designing a common fusion algorithm for all image fusion applications is a challenging task. The cross bilateral filter based image fusion (CBFF) is one such general-purpose method which can be applied to both mono and multimodal image fusion applications. However, CBFF has some drawbacks. 1) It introduces artifacts or extra information into the fused image. 2) The runtime of the CBFF is high. To solve these problems and improve the performance further, we propose a new image fusion algorithm based on the cross bilateral filter by designing a simple and an efficient image fusion rule. Experiments are conducted on both images and videos. Results are analyzed using recent fusion metrics in addition to the qualitative and run time analysis. Results demonstrated that the proposed algorithm can be used as an alternative method to the CBFF.", "paperid": 2890909311, "normalizedname_level1": "artificial intelligence"}
{"index": 414, "text": "Currently, CNN-based scene classification algorithms have become mainstream. By using the features of convolutional neural networks, we propose an image classification method with Fisher feature analysis. Rich high-dimensional image descriptors can be learned through convolutional neural networks, and it is inefficient to calculate the similarity of these high feature descriptors. In order to reduce the time of feature matching and improve the accuracy of similarity descriptor matching, the algorithm adds a hidden layer between the fully-connected layer and the output layer which fine-tuning network to learn the features of low images. For solve the similarity of image feature descriptors, we use Fisher discriminant to classify images which enhance the independence between sample features. Experiments based on the Scene-15 and cifar-10 datasets show that the proposed method improves the efficiency of network feature matching and classification accuracy.", "paperid": 3009114322, "normalizedname_level1": "artificial intelligence"}
{"index": 415, "text": "Brain-computer interface (BCI) is a new technology that enables communication using brain activities for patients in totally locked-in state. In this research, we examined optimal mental task for near-infrared spectroscopy-based BCI from among six tasks. SVM was used for learning, and the classification accuracy for each tasks through k-fold cross validation was calculated. As a result, it was suggested that the mental figure rotation is a task with high discrimination accuracy and less sense of burden.", "paperid": 2982349895, "normalizedname_level1": "artificial intelligence"}
{"index": 416, "text": "This paper presents a vehicle navigation system that is capable of achieving sub-meter GPS-denied navigation accuracy in large-scale urban environments, using pre-mapped visual landmarks. Our navigation system tightly couples IMU data with local feature track measurements, and fuses each observation of a pre-mapped visual landmark as a single global measurement. This approach propagates precise 3D global pose estimates for longer periods. Our mapping pipeline leverages a dual-layer architecture to construct high-quality pre-mapped visual landmarks in real time. Experimental results demonstrate that our approach provides sub-meter GPS-denied navigation solutions in large-scale urban scenarios.", "paperid": 2566241853, "normalizedname_level1": "artificial intelligence"}
{"index": 417, "text": "Within a Music Information Retrieval perspective, the goal of the study presented here is to investigate the impact on sound features of the musician's affective intention, namely when trying to intentionally convey emotional contents via expressiveness. A preliminary experiment has been performed involving 10 tuba players. The recordings have been analysed by extracting a variety of features, which have been subsequently evaluated by combining both classic and machine learning statistical techniques. Results are reported and discussed.", "paperid": 2474201625, "normalizedname_level1": "artificial intelligence"}
{"index": 418, "text": "Shape correspondence is a fundamental problem in computer graphics and vision, with applications in various problems including animation, texture mapping, robotic vision, medical imaging, archaeology and many more. In settings where the shapes are allowed to undergo non-rigid deformations and only partial views are available, the problem becomes very challenging. To this end, we present a non-rigid multi-part shape matching algorithm. We assume to be given a reference shape and its multiple parts undergoing a non-rigid deformation. Each of these query parts can be additionally contaminated by clutter, may overlap with other parts, and there might be missing parts or redundant ones. Our method simultaneously solves for the segmentation of the reference model, and for a dense correspondence to (subsets of) the parts. Experimental results on synthetic as well as real scans demonstrate the effectiveness of our method in dealing with this challenging matching scenario.", "paperid": 2509989438, "normalizedname_level1": "artificial intelligence"}
{"index": 419, "text": "Image recognition is challenging in the field of wildlife ecology as samples of a specific species can be rare, making manual detection cumbersome. With over 2,060,000 images taken from motion-sensor trail cameras and unmanned aerial vehicle flights, a touch enabled web interface has been developed to allow citizen scientists and ecologists to categorize positive samples. To minimize categorization errors, the same images are shown to multiple separate users. The observations of each user are then compared using two novel validation strategies: percentage of overlapping area and maximum corner distance. Two novel methods for the extraction of final images from validated results are presented and compared as well: average corner points and area intersection. These methods were evaluated using a set of 142 images with a total of 811 observations of objects generated by citizen scientists that were manually inspected for ground truth. Results show that for this research a maximum corner distance of 10 pixels and the use of area intersection provided the best extracted imagery for future use as training and testing data by computer vision methods.", "paperid": 2592997557, "normalizedname_level1": "artificial intelligence"}
{"index": 420, "text": "The purpose of the superpixel algorithm is to find an over-segmented set of images. In this paper, we transform the superpixel segmentation problem into the problem of minimizing the cost function on the graph. We propose a new minimum spanning tree cost function based on graph theory. In order to achieve this cost function, we propose a greedy algorithm based on multiple seed growth. Compared to other superpixel segmentation algorithms, our proposed algorithm not only ensures superpixel segmentation quality but also has linear execution time and is easy to implement. Experiments on the BSD benchmark dataset show that superpixel segmentation algorithm in this paper is superior to the current most of the superpixel segmentation algorithm in Boundary recall and Under-segmentation error, and the algorithm is more efficient than the current most of the superpixel segmentation algorithm.", "paperid": 2782785686, "normalizedname_level1": "artificial intelligence"}
{"index": 421, "text": "Quadtree brings extremely high computational complexity in high efficiency video coding (HEVC). Innovative works for improving quadtree structures to further reduce encoding time are stated in this paper. A novel quadtree probability mechanism is proposed for HEVC fast coding unit (CU) encoding. Firstly, this paper makes an in-depth study of the relationship among CU distribution, quantization parameter (QP) and video content change. Secondly, a CU quadtree probability model is proposed for modeling and predicting CU partition based on the group of picture (GOP). Eventually, a CU quadtree probability update is proposed, aiming to address probabilistic model distortion problems caused by video content change. Experimental results have shown that the proposed CU quadtree probability mechanism significantly outperforms HEVC by considerably reducing encoding time by 27% for lossy coding and 42% for (visually) lossless coding, without compromising rate-distortion (RD) performance.", "paperid": 2562667460, "normalizedname_level1": "artificial intelligence"}
{"index": 422, "text": "Due to the easily available software for tampering images, image manipulation has become quite common. Since the tampered images are non-distinguishable by the naked eye, they are being circulated on various platforms giving rise to rumors and misleading many. This has led researchers to work on various techniques for the detection of manipulated images with improved accuracy. Traditional works on image forgery detection are mostly based on extracting simple features that are specific for detecting some particular type of forgery. Recently, works on forgery detection based on neural networks have proved to be very efficient in detecting image forgery. Neural networks are capable of extracting complex hidden features of an image, thus giving better accuracy. Contrary to the traditional methods of forgery detection, a deep learning model automatically builds the required features, hence it has become the new area of research in image forgery. The paper initially discusses various types of image forgery techniques and later on compares different approaches involving neural networks to identify forged images.", "paperid": 3036963649, "normalizedname_level1": "artificial intelligence"}
{"index": 423, "text": "Unsupervised domain adaptation is effective in leveraging rich information from a labeled source domain to an unlabeled target domain. Though deep learning and adversarial strategy made a significant breakthrough in the adaptability of features, there are two issues to be further studied. First, hard-assigned pseudo labels on the target domain are arbitrary and error-prone, and direct application of them may destroy the intrinsic data structure. Second, batch-wise training of deep learning limits the characterization of the global structure. In this paper, a Riemannian manifold learning framework is proposed to achieve transferability and discriminability simultaneously. For the first issue, this framework establishes a probabilistic discriminant criterion on the target domain via soft labels. Based on pre-built prototypes, this criterion is extended to a global approximation scheme for the second issue. Manifold metric alignment is adopted to be compatible with the embedding space. The theoretical error bounds of different alignment metrics are derived for constructive guidance. The proposed method can be used to tackle a series of variants of domain adaptation problems, including both vanilla and partial settings. Extensive experiments have been conducted to investigate the method and a comparative study shows the superiority of the discriminative manifold learning framework.", "paperid": 3047518573, "normalizedname_level1": "artificial intelligence"}
{"index": 424, "text": "Psychophysical and neurophysiological investigations on the human visual system show that most neurons in the primary visual cortex (V1) possess a non-classical receptive field (nCRF) region in addition to the CRF region. The nCRF has a modulatory, normally inhibitory, effect on the responses to visual stimuli generated within the CRF. In computational terms, this mechanism suppresses the response to edges in the presence of similar edges in the surroundings. Many computational techniques have been proposed to address the surround suppression mechanism. These methods introduce an inhibition term that is required to suppress the textures and protect the contours. Several studies have found that the spatial summation properties over the receptive fields of retinal X cells are approximately linear, while they are non-linear for Y cells. Inspired by the visual information processing in the X–Y channel and spatial summation properties of X and Y cells, the authors propose a contour detector using linear and non-linear modulations based on nCRF suppression. Extensive experimental evaluations demonstrate that their contour detector significantly outperforms other algorithms. The methods proposed in this study are expected to facilitate the development of efficient computational models in the field of machine vision.", "paperid": 2790416135, "normalizedname_level1": "artificial intelligence"}
{"index": 425, "text": "Face recognition systems in a video sequence constitute an essential technical tool in several domains. To classify the faces in minimal time, the classic methods of classification being inadequate, fuzzy logic is considered as an effective technique for solving a classification problem. This article proposes a fuzzy approach for detection and face recognition in video sequences using a multi-agent modeling. This method contains several steps to classify the faces detected in the video. The multi-agent approach that is adopted allows minimizing the complexity of the processing and getting to the result with minimal time. The tasks of detection and classification of face are realized in two steps. In the first step, faces are detected using texture color and geometrical face. In the second step, the multi-agent system and fuzzy approach are used in the recognition process to find the degrees of membership. The results obtained using this method demonstrates performance in terms of robustness, in the variations illumination and speed.", "paperid": 2351211718, "normalizedname_level1": "artificial intelligence"}
{"index": 426, "text": "In recent years autoencoder based collaborative filtering for recommender systems have shown promise. In the past, several variants of the basic autoencoder based approach has been proposed - marginalized denoising autoencoder and stacked denoising autoencoder. However, these are not new developments; just applications of existing machine learning techniques on collaborative filtering. In this work we propose a fundamentally new architecture of hierarchical autoencoder. In a normal stacked denoising autoencoder, reconstruction only happens at the final layer, the intermediate layers are not directly responsible. In our proposed hierarchical model every layer reconstructs; each layer provides complimentary information. The output from all the layers are fused to yield the final result. Experiments of benchmark collaborative filtering datasets show the superiority of our technique over the state-of-art.", "paperid": 2897230420, "normalizedname_level1": "artificial intelligence"}
{"index": 427, "text": "The neuronal spike timing was usually supposed to be not robust enough to code neuron information because the background noise would influence neuronal precise spiking timing. In this paper, we verify the robustness of rank order coding, which is a type of temporal coding, under balanced background noise. We utilize the rank-order coding-based Spiking Neural Network (SNN) to analysis the effect of background noise, SNN is trained to recognize images by Spike-prop algorithm and tested under noise of different strength, the robustness is represented by recognition accuracy of images. The result shows that even if the noise would reduce the precision of neuronal spike timing, the SNN is not sensitive to the noise, it could conduct information correctly in the existence of strong background noise, meanwhile, adding background noise in training enable SNN to be more robust. We also reveal that weak synaptic coupling among neurons enables the SNN to be more robust through decreasing the fluctuation of neuronal spike timing.", "paperid": 2981216867, "normalizedname_level1": "artificial intelligence"}
{"index": 428, "text": "Unsupervised domain adaptation (UDA) for nuclei instance segmentation is important for digital pathology, as it alleviates the burden of labor-intensive annotation and domain shift across datasets. In this work, we propose a Cycle Consistency Panoptic Domain Adaptive Mask R-CNN (CyC-PDAM) architecture for unsupervised nuclei segmentation in histopathology images, by learning from fluorescence microscopy images. More specifically, we first propose a nuclei inpainting mechanism to remove the auxiliary generated objects in the synthesized images. Secondly, a semantic branch with a domain discriminator is designed to achieve panoptic-level domain adaptation. Thirdly, in order to avoid the influence of the source-biased features, we propose a task re-weighting mechanism to dynamically add trade-off weights for the task-specific loss functions. Experimental results on three datasets indicate that our proposed method outperforms state-of-the-art UDA methods significantly, and demonstrates a similar performance as fully supervised methods.", "paperid": 3034457289, "normalizedname_level1": "artificial intelligence"}
{"index": 429, "text": "Image fusion is a process of obtaining one image from multiple. The resulting image carries more information about the photographed scene, than each of the originals. Such an image can be more useful when we deal with human or image processing system. Algorithms that performed this task are used in a wide applying in practical: computer vision, robotics, medicine, forensics, etc. Most popular quality assessment measure for multi-focused image fusion are discribed. Expert image quality assessment experiment was performed. Different kinds of image quality assessment were proposed for scenes with various characteristics.", "paperid": 2766213991, "normalizedname_level1": "artificial intelligence"}
{"index": 430, "text": "With the explosive growth of digital transactions, the security of personal identity presents a serious challenge in our world today. It has become necessary to provide reliable and robust recognition systems. To overcome this problem, we propose a novel approach for finger knuckle print using Compound Local Binary Pattern (CLBP). Unlike the LBP operator, the CLBP add an extra bit for each P bits encoded by LBP corresponding to a neighbor of the local neighborhood, in order to construct a robustious feature descriptor that exploits both the sign and the inclination information of the differences between the center and the neighbor gray values. The effectiveness of proposed method has been verified on PolyU FKP database. The experimental results show that the recognition rates are significantly improved compared with others methods existing in literature. The recognition rate of the proposed method is the highest among the other algorithms. The optimal recognition rates obtained is 98,18%, 99,29%, 98,48% and 98,89% for Left Index, Left Middle, Right Index and Right Middle, respectively.", "paperid": 2784025751, "normalizedname_level1": "artificial intelligence"}
{"index": 431, "text": "Fiber Specklegram Sensors (FSSs) are highly sensitive to external perturbations, however, trying to locate perturbation's position remains as a barely addressed study. In this work, a system able to classify perturbations according to the place they have been caused along a multimode optical fiber has been designed. As proof of concept, a multimode optical fiber has been perturbated in different points, recording the videos of the perturbations in the speckle pattern, processing these videos, training with them a machine learning algorithm, and classifying further perturbations based on the spatial locations they were generated. The results show classifications up to 99% when the system has to categorize among three different locations lowering to 71% when the locations rise to ten.", "paperid": 2811047374, "normalizedname_level1": "artificial intelligence"}
{"index": 432, "text": "Concerning the domain of Image Processing, image segmentation step is considered to be a wider term as a necessary requirement for the progression of the essentiel data out of the given image. Therefore the image segmentation is a very important step in most computer vision systems. Our aim is to improve the quality of the segmented image by the Quadtree division method, for this we proposed three approaches: the first is to segment the palette of gray levels in 32 intervals to reduce the blocks number obtained in order to avoid over-segmentation, the second is to cooperate two methods one for the regions-based segmentation using the Quadtree method and the other for the edges-based segmentation using Sobel operator or Canny operator, in order to obtain reliable result by exploiting the advantages of both types of segmentation. The third and last is a hybridization between the Quadtree and one of the segmentation by clustering method that is K-means, using the peaks number detected by the equalized histogram. For a good automation of the system, we have assigned this peaks number to K the class number in Kmeans.", "paperid": 2888613526, "normalizedname_level1": "artificial intelligence"}
{"index": 433, "text": "Learnable data augmentation is a technique where a neural netowrk learns to create modified data samples that improve the training outcome from a second, parallel neural network. This is a relatively new approach to dataset augmentation that has inspired many variations in the last few years. In this article the most signficiant of these advanced data augmentation strategies are summarised and discussed.", "paperid": 3014672015, "normalizedname_level1": "artificial intelligence"}
{"index": 434, "text": "Wi-Fi fingerprinting has been extensively studied for indoor localization due to its deployability under pervasive indoor WLAN. As the signals from access points (APs) may change due to, for example, AP movement or power adjustment, the traditional approach is to conduct site survey regularly in order to maintain localization accuracy, which is costly and time-consuming. Here, we study how to accurately locate a target and automatically update fingerprints in the presence of altered AP signals (or simply, “altered APs”). We propose  L ocalization with  A ltered  A Ps and  F ingerprint  U pdating (LAAFU) system, employing implicit crowdsourced signals for fingerprint update and survey reduction. Using novel subset sampling, LAAFU identifies any altered APs and filter them out before a location decision is made, hence maintaining localization accuracy under altered AP signals. With client locations anywhere in the region, fingerprint signals can be adaptively and transparently updated using non-parametric Gaussian process regression. We have conducted extensive experiments in our campus hall, an international airport, and a premium shopping mall. Compared with traditional weighted nearest neighbors and probabilistic algorithms, results show that LAAFU is robust against altered APs, achieving 20 percent localization error reduction with the fingerprints adaptive to environmental signal changes.", "paperid": 2519504401, "normalizedname_level1": "artificial intelligence"}
{"index": 435, "text": "One of the main tools in knowledge representation is ontology, which is a collection of logic-based formal language sentences. These sentences are used by automated reasoning programs to extract new knowledge and answer to the given questions. Although ontology languages are standardized by W3C, there are still many problems remaining. One of the most important problems is related to, so called, fuzzy ontologies. These are ontologies, where information is vague and imprecise. Fuzzy ontologies are obtained by integrating fuzzy logic with ontologies. Such kind of ontologies have applications in many different fields, such as medicine, biology, e-commerce and the like. In this paper, we develop an unranked fuzzy logic and study some of its properties. The novelty of our approach is that we will extend many-valued logics with sequence variables and flexiblearity function and predicate symbols. To the best of our knowledge, such formalisms are not yet studied in the literature. The unranked fuzzy language will broaden the knowledge engineering capabilities in different fields.", "paperid": 3095841571, "normalizedname_level1": "artificial intelligence"}
{"index": 436, "text": "In machine learning, feature engineering has been a pivotal stage in building a high-quality predictor. Particularly, this work explores the multiple Kernel Discriminant Component Analysis (mKDCA) feature-map and its variants. However, seeking the right subset of kernels for mKDCA feature-map can be challenging. Therefore, we consider the problem of kernel selection, and propose an algorithm based on Differential Mutual Information (DMI) and incremental forward search. DMI serves as an effective metric for selecting kernels, as is theoretically supported by mutual information and Fisher's discriminant analysis. On the other hand, incremental forward search plays a role in removing redundancy among kernels. Finally, we illustrate the potential of the method via an application in privacy-aware classification, and show on three mobile-sensing datasets that selecting an effective set of kernels for mKDCA feature-maps can enhance the utility classification performance, while successfully preserve the data privacy. Specifically, the results show that the proposed DMI forward search method can perform better than the state-of-the-art, and, with much smaller computational cost, can perform as well as the optimal, yet computationally expensive, exhaustive search.", "paperid": 2771885995, "normalizedname_level1": "artificial intelligence"}
{"index": 437, "text": "For mobile devices, motion estimation has been the most time-consuming part of video compression. Many fast motion vector block matching algorithms are proposed to decrease time complexity. In our paper, a new algorithm called Predictive Root Pattern Search (PRPS) is proposed. Experimental results show that the image quality of the proposed method is better than that of other block matching methods, especially on large and fast motion video chips.", "paperid": 2564798663, "normalizedname_level1": "artificial intelligence"}
{"index": 438, "text": "Because it is relatively difficult in practice to classify the Raman spectrum under baseline noise and additive white Gaussian noise environments, this paper proposes a new framework based on a wavelet transform and deep neural network for identification of noisy Raman spectra. The framework consists of two main engines. Wavelet transform is proposed as the framework front end for transforming the 1-D noise Raman spectrum to two-dimensional data. The two-dimensional data are fed to the framework back end, which is a classifier. The optimum classifier is chosen by implementing several traditional machine learning (ML) and deep learning (DL) algorithms, and we investigate their classification accuracy and robustness performances. The four chosen MLs are naive Bayes (NB), a support vector machine (SVM), a random forest (RF) and a k-nearest neighbor (KNN), and a deep convolution neural network (DCNN) was chosen as a DL classifier. Noise-free, Gaussian noise, baseline noise, and mixed-noise Raman spectra were applied to train and validate the ML and DCNN models. The optimum back-end classifier was obtained by testing the ML and DCNN models with several noisy Raman spectra (10-30 dB noise power). Based on the simulation, the accuracy of the DCNN classifier is 9% higher than that of the NB classifier, 3.5% higher than the RF classifier, 1% higher than the KNN classifier, and 0.5% higher than the SVM classifier. In terms of robustness to mixed noise scenarios, the framework with the DCNN back end showed superior performance compared with the other ML back ends. The DCNN back end achieved 90% accuracy at 3 dB SNR, while the NB, SVM, RF, and K-NN back ends required 27 dB, 22 dB, 27 dB, and 23 dB SNR, respectively. In addition, in the low-noise test dataset, the F-measure score of the DCNN back end exceeded 99.1%, and the F-measure scores of the other ML engines were below 98.7%.", "paperid": 3097720301, "normalizedname_level1": "artificial intelligence"}
{"index": 439, "text": "We study the problem of optimally coordinating multiple fixed-wing UAVs to perform target tracking, which entails that the UAVs are tasked with gathering the best joint radar-based measurements of ground targets. In order to obtain the maximum amount of information, we first studied the information expression in multi-sensor network system. Based on the Minkowski determinant theorem, the change of information volume caused by data fusion is analyzed with the relevant content of information geometry, and take it as the foundation of communication and action decision-making. Simulation results show that the data fusion can increase the amount of information, and make the result more accurate. Further, for specific scene, the simulation results illustrate that multi-UAV cooperative observation can improve the accuracy of target tracking. This sets the foundation for the further study of the information exchange between multi-UAV.", "paperid": 2754868093, "normalizedname_level1": "artificial intelligence"}
{"index": 440, "text": "Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation at this http URL. In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15~months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.", "paperid": 2981566147, "normalizedname_level1": "artificial intelligence"}
{"index": 441, "text": "An automatic IC character recognition system for IC test handler is proposed in this paper based on support vector machine (SVM). It can achieve character recognition on the chip surface. Firstly, the chips' images are captured and binarized using Otsu algorithm. And median filter is used to remove the images' noise. Secondly, character segmentation is done to get the image of each character through projection feature. Character images are normalized in order to convert to same size. Thirdly, feature extraction is performed based on grid feature. Fourthly, the classifier based on SVM is used for sample training and character recognition. Finally, the character recognition system based on SVM is built. And experiment on character recognition for IC chips is performed. The experiment results demonstrate the effectiveness and feasibility of the proposed system.", "paperid": 2566612050, "normalizedname_level1": "artificial intelligence"}
{"index": 442, "text": "Despite the recent great achievements in speech emotion recognition (SER) with the development of deep learning, the performance of SER systems depends strongly on the amount of labeled data available for training. Obtaining sufficient annotated data, however, is often extremely time consuming and costly and sometimes even prohibitive because of privacy and ethical concerns. To address this issue, this article proposes the semisupervised generative adversarial network (SSGAN) for SER to capture underlying knowledge from both labeled and unlabeled data. The SSGAN is derived from a GAN, but the discriminator of the SSGAN can not only classify its input samples as real or fake but also distinguish their emotional class if they are real. Thus, the distribution of realistic inputs can be learned to encourage label information sharing between labeled and unlabeled data. This article proposes two advanced methods, i.e., the smoothed SSGAN (SSSGAN) and the virtual smoothed SSGAN (VSSSGAN), which, respectively, smooth the data distribution of the SSGAN via adversarial training (AT) and virtual adversarial training (VAT). The SSSGAN smooths the conditional label distribution given inputs using labeled examples, while the VSSSGAN smooths the conditional label distribution without label information (“virtual” labels). To evaluate the effectiveness of the proposed methods, four publicly available and frequently used corpora are selected to conduct experiments in intradomain and interdomain situations. The results illustrate that the proposed methods are superior to the state-of-the-art methods. Specifically, in experimental settings with mismatched and semimismatched unlabeled training sets, the SSSGAN and VSSSGAN are more robust than the SSGAN because of the distributional smoothness.", "paperid": 3035043463, "normalizedname_level1": "artificial intelligence"}
{"index": 443, "text": "This report tries to investigate the effective use of the machine learning in the area of image analysis and processing. The field of healthcare taking a large datasets of image like X-ray, Ultrasound, MRI, CT scan, Echo-cardiograpgy with the known classification, Take images as input and then process the images, in case of process the images following steps are involved formatting of images if not suitable as per the required format and then Segmentation, Feature extraction and Classification and then train the model with given data of images with known classification (that is called data sets) after that model can predict the classification of the given new images that is called test data. And then compare the result with the already given model result with different-different machine learning algorithm. And try to improve the result with existing result and target is to achieve 100 % accuracy. To improve the result is depend on many things like in image processing it depend on how well had done segmentation and then feature extraction is again main factor to improve the result, how many feature taken during developing model and then classification, it also depend on machine learning algorithm used as per the given data sets.", "paperid": 2955440672, "normalizedname_level1": "artificial intelligence"}
{"index": 444, "text": "The automatic parking system using an integral intensity projection is important in order to reduce the time spend for finding an available parking space. We applied the intensity projection and peak detection approaches to find the number and location of the parking space from a parking lot image. The parking lot image is firstly applied the integral projection in order to sum and smooth intensity projection of this image in a horizontal direction. After that the image is segmented into the region of interest (ROI) image by using the location object's edges derived from a derivative method. Then the integral intensity projection is again utilized the maximum points in vertical direction of the image intensity summation. Finally, the number of parking spots were counted by using peak detection approach. In the experimental results, the accuracy for counting the number of cars in the parking lot image is 53.03%.", "paperid": 2603399545, "normalizedname_level1": "artificial intelligence"}
{"index": 445, "text": "This paper presents the conscientious system in order to make it fully Automated, ceaseless, cost and power effective system. The advanced technologies like wireless smart Intelligent network and Artificial Intelligence being implemented here with the help of Smart algorithms written in microcontroller. Here we have designed and implemented wind speed and direction sensor to provide the real time data gathering from the various nodes and keep track of all child nodes ceaselessly. In this way, the weather parameters like Temperature, Humidity, Wind speed and Wind Directions gets monitored ceaselessly and the faulty nodes can be detected very easily and such sensed data would be directly monitored by the maintenance team for further repairing of the faulty nodes by monitoring the data on the web page.", "paperid": 2940477871, "normalizedname_level1": "artificial intelligence"}
{"index": 446, "text": "This study focuses on effects of uniform and full height map correction methods for dewarping book spread images in an automated book reader design for individuals with visual impairment and blindness. The design concept could also be applied to address the challenging process of book digitization. The method is dependent on the geometry of the book reader setup for acquiring the 3-D maps that yield a high reading accuracy. The experiments were performed on a testing dataset consisting of 142 pages with their corresponding depth maps that were extracted. The accuracy of the book spread images was quantified and measured by introducing the corrected images to an Optical Character Recognition engine. Initially, the book spreads were tested by placing them with a standard alignment which yielded an average accuracy of 95.55% and 96.11% with the uniform maps and the full height maps, respectively. Rotations of the book spreads are introduced in a separate test to see if the two proposed methods are tolerant to unsuspected misaligned placements of the book. These tests yield an average accuracy of 90.63% for the corrections with a uniform map and 94.75% with the full height maps.", "paperid": 2600061120, "normalizedname_level1": "artificial intelligence"}
{"index": 447, "text": "Crowd analysis is an essential topic of research in artificial intelligence. There are several applications on crowd analysis, such as, environmental management, urban planning and public safety. This paper presents review of different methodologies those have been implemented for estimating crowd. This paper covers several methods of crowd density estimation, such as, image processing techniques, machine learning and deep learning based technique, and smartphone based technique.", "paperid": 3007801911, "normalizedname_level1": "artificial intelligence"}
{"index": 448, "text": "Image fusion technique integrates suitable information from various modalities of input images into a fused distinct image where the resultant image provides better information in comparison with the input images which are used for fusion and is more appropriate for visual perception. This work presents an image fusion method which performs wavelet decomposition for both PET and MRI images with different activity levels. This method generates promising fusion results by varying the structural information in the gray matter area and the spectral information in the white matter area to have better color preservation. Moreover, to produce good spectral resolution, smoothing filters is applied to the low frequency region and adaptive histogram equalization is performed to obtain a high contrast fused output image.", "paperid": 2557530442, "normalizedname_level1": "artificial intelligence"}
{"index": 449, "text": "The safety accident hidden danger of on-site inspection by railway workers are stored in text format, and this kind of data contains a lot of valuable information related to railway safety, so it is urgent to classify and manage the data by classification model. In this paper, we analyze the characteristics of such data. Firstly, we use TF-IDF method to extract text features and convert them into vectors. Then, decision tree classifier is used to classify the data. In order to improve classification accuracy, the Bagging Ensemble Classifier conduct a random sample training to text vector converted by TF-IDF which decision as the base classifier, produce Bagging classification results, considering the Bagging Algorithm is a the number of base classifiers results voting combination classification model which has a better classification performance, we use Genetic Algorithm to calculate Bagging classifier combination optimization, better classification results are produced by the Ensemble Classifier based on Genetic Algorithm(Evolutionary Ensemble Classifier). Through the experimental analysis of text data on safety accident hidden danger of power supply catenary in a Railway Bureau, it is proved that the safety classification accuracy, recall rate and f-score value of the Evolutionary Ensemble Classifier model are significantly improved.", "paperid": 2973285597, "normalizedname_level1": "artificial intelligence"}
{"index": 450, "text": "There are two sub-tasks implied in the weakly-supervised SED: audio tagging and event boundary detection. Current methods which combine multi-task learning with SED requires annotations both for these two sub-tasks. Since there are only annotations for audio tagging available in weakly-supervised SED, we design multiple branches with different learning purposes instead of pursuing multiple tasks. Similar to multiple tasks, multiple different learning purposes can also prevent the common feature which the multiple branches share from overfitting to any one of the learning purposes. We design these multiple different learning purposes based on combinations of different MIL strategies and different pooling methods. Experiments on the DCASE 2018 Task 4 dataset and the URBAN-SED dataset both show that our method achieves competitive performance.", "paperid": 3015387077, "normalizedname_level1": "artificial intelligence"}
{"index": 451, "text": "In this paper, we propose like Double-Ring Marker based method which can estimate the 3D pose parameters of a Rod-shaped object such as MIS (Minimally Invasive Surgery) instrument using just a single 2D image. The core of the proposed method is a set of equations derived from the geometric relationship between the Double-Ring Markers on the rod and their projections onto the image plan through the camera's perspective transformation. Compared to existing MIS pose estimation methods, which normally require time consuming processes including depth estimation, instrument identification and position parameters estimation as the pre-processing, the proposed Double-Rings marker based algorithm is very accurate and efficient.", "paperid": 2763166043, "normalizedname_level1": "artificial intelligence"}
{"index": 452, "text": "Combining multiple information streams has shown obvious improvements in video action recognition. Most existing works handle each stream independently or perform a simple combination on temporally simultaneous samples in multi-streams, which fails to make full use of the streamwise complementary property due to the negligence of the temporal pattern gaps among streams. In this paper, we propose a cross-stream selective network (CSN) to properly integrate and evaluate information in multi-streams. The proposed CSN first introduces a local selective-sampling module (LSM), which can find asynchronous correspondences among streams and construct high-correlated sample groups across multiple information streams. This LSM can effectively deal with the temporal dis-alignment among different streams, leading to a better integration of cross-stream information. We further introduce a global adaptive-weighting module (GAM). It adaptively evaluates the importance weights for each cross-stream sample group and selects temporally more important ones in action recognition. With the integration of cross-stream information, our GAM can obtain more reasonable importance than the existing single-stream weighting schemes. Extensive experiments on benchmark datasets of UCF101 and HMDB51 demonstrate the effectiveness of our approach over previous state-of-the-art methods.", "paperid": 2969776042, "normalizedname_level1": "artificial intelligence"}
{"index": 453, "text": "Recently, Linear Temporal Logic (LTL) has been used as a formalism for defining high-level robot tasks, and LTL synthesis has been used to automatically create correct-by-construction robot control. The underlying premise of this approach is that the robot has a set of actions, or skills, that can be composed to achieve the high- level task. In this paper we consider LTL specifications that cannot be synthesized into robot control due to lack of appropriate skills; we present algorithms for automatically suggesting new or modified skills for the robot that will guarantee the task will be achieved. We demonstrate our approach with a physical Baxter robot and a simulated KUKA IIWA arm.", "paperid": 3089675627, "normalizedname_level1": "artificial intelligence"}
{"index": 454, "text": "Adversarial attacks have always been a serious threat for any data-driven model. In this paper, we explore subspaces of adversarial examples in unitary vector domain, and we propose a novel detector for defending our models trained for environmental sound classification. We measure chordal distance between legitimate and malicious representation of sounds in unitary space of generalized Schur decomposition and show that their manifolds lie far from each other. Our front-end detector is a regularized logistic regression which discriminates eigenvalues of legitimate and adversarial spectrograms. The experimental results on three benchmarking datasets of environmental sounds represented by spectrograms reveal high detection rate of the proposed detector for eight types of adversarial attacks and it also outperforms other detection approaches.", "paperid": 3016206375, "normalizedname_level1": "artificial intelligence"}
{"index": 455, "text": "Sleep apnea is a complete or partial cessation of breathing during sleep. Obstructive sleep apnea (OSA) is one of the most common breathing-related sleep disorders. The well-known reliable and standard diagnosis test used by specialized physicians is the polysomnographic sleep study. However, this test is complex and time consuming and expensive. Therefore, a non-invasive technique applying signal-processing algorithms is of more benefits for identification of OSA patients from normal subjects. Any identification algorithm has two parts: feature extraction part and feature matching part. In this paper, the feature extraction part depends on the wavelet-packet decomposition technique of the Heart Rate Variability (HRV) signal. The feature matching part uses the support vector machine (SVM). The highest performance on MIT standard data is achieved by the linear support vector machine with 5 stages wavelet decomposition using db1 filters with specificity, sensitivity, and accuracy of 100%, 90% and 93.34%, respectively.", "paperid": 2810901824, "normalizedname_level1": "artificial intelligence"}
{"index": 456, "text": "The aim of this study is to detect transportation modes by using smart phone sensor data. The data are obtained from the GPS, accelerometer and gyroscope sensors of the smartphone. The collected data is divided into 10 second windows and each pattern contains 200 patterns. After the attributes have been determined, the manifold learning algorithm is applied to data set. The obtain features are classified by the Support Vector Machine (SVM) method. In experimental study stage, the performances of three kernel functions of the SVM were compared.", "paperid": 2770649916, "normalizedname_level1": "artificial intelligence"}
{"index": 457, "text": "Extracting inherent patterns from large data using decompositions of data matrix by a sampled subset of exemplars has found many applications in machine learning. We propose a computationally efficient algorithm for adaptive exemplar sampling, called fast exemplar selection (FES). The proposed algorithm can be seen as an efficient variant of the oASIS algorithm [1]. FES iteratively selects incoherent exemplars based on the exemplars that are already sampled. This is done by ensuring that the selected exemplars forms a positive definite Gram matrix which is checked by exploiting its Cholesky factorization in an incremental manner. FES is a deterministic rank revealing algorithm delivering a tighter matrix approximation bound. Further, FES can also be used to exactly represent low rank matrices and signals sampled from a unions of independent subspaces. Experimental results show that FES performs comparable to existing methods for tasks such as matrix approximation, feature selection, outlier detection, and clustering.", "paperid": 2616505510, "normalizedname_level1": "artificial intelligence"}
{"index": 458, "text": "With the developing remote sensing technology, hundreds of different wavelengths of hyperspectral images are obtained in the electromagnetic spectrum. LiDAR data, which gives altitude information, provides additional information for the area being imaged. In this study, there are two stages of solving the problem of semantic segmentation using these datasets, namely the information fusion and classification. In this study, firstly, morphological profile maps were produced from the hyperspectral LiDAR images in the Houston dataset, then these spectral data and morphological profiles were integrated through concatenation. Then, this data was filtered by the filters in the first convolution layer of AlexNet, which has a highly efficient deep convolutional architecture in image classification. Finally, this data was classified with a proposed deep convolutional neural network. Classification results are compared with the five methods proposed in the recent years, and it has been shown that our proposed method gives the best results among the competing methods.", "paperid": 2814508103, "normalizedname_level1": "artificial intelligence"}
{"index": 459, "text": "Camera 360° has been a very huge help in technology now a days. Indoor navigation using cameras has been widely studied by different researches. The proponents find a way to the existing problem of using 2d camera. Using camera 360°, the whole scene can be captured and using Scale Invariant Feature Transform Algorithm, the landmarks will be recognized and then the system will do computations to give the shortest path using Dijkstra”s Algorithm. The system will give instructions to the user, as audio, based on the destination. The system has been concluded that it solves the problem encounter using 2d camera and navigate more efficiently compared to past studies.", "paperid": 3043595029, "normalizedname_level1": "artificial intelligence"}
{"index": 460, "text": "Today, face detection is of paramount importance due to its wide range of benefits and applications. Results of studies in this field have led to obtaining methods for face detection. In each of these methods, two factors of accuracy and runtime are important. The necessity of using accurate and quick methods has led to more studies in this regard. In face images, the individual’s face is not always directed toward the camera. Therefore, one of the important challenges in face detection is the correct detection when the angle of the image to the camera is not in the same direction and there are differences in the degree measure of the image angle, compared to the main image. The main issue in face detection, which has always been considered an important concept, is achieving the desired result based on the needs of security departments and scientific organizations. The present study aimed to evaluate the face detection methods in angular positions. In addition, one of the objectives of the research was assessing the advantages and disadvantages of each technique. In the end, the evaluated methods were compared on databases of ORL, ORL, and ORL in terms of accuracy of face detection. According to the results, the PCA+LDA+GABOR was the most efficient method due to special attention to viewing angles in different images that can result in high detection accuracy, compared to other methods.", "paperid": 2953296124, "normalizedname_level1": "artificial intelligence"}
{"index": 461, "text": "There has been a significant interest in the estimation of time and effort in fixing defects among both software practitioners and researchers over the past two decades. However, most of the focus has been on prediction of time and effort in resolving bugs, without much regard to predicting time needed to complete high-level requirements, a critical step in release planning. In this paper, we describe a mixed-method empirical study on three large IBM projects in which we developed and evaluated a process of training a predictive model constituting a set of 29 features in nine categories in order to predict if a requirement will be completed within its planned iteration. We conducted feature engineering through iterative interviews with IBM practitioners as well as analysis of large development repositories of these three projects. Using machine learning techniques, we were able to make predictions on completion time of requirements at four different stages of their lifetime. Using our industrial partner's interest in high precision over recall, we then adopted a cost sensitive learning method and maximized precision of predictions (ranging from 0.8 to 0.97) while maintaining an acceptable recall. We also ranked the features based on their relative importance to the optimized predictive model. We show that although satisfying predictions can be made at early stages, performance of predictions improves over time by taking advantage of requirements' progress data. Furthermore, feature importance ranking results show that although importance of features are highly dependent on project and prediction stage, there are certain features (e.g. requirement creator, time remained to the end of iteration, time since last requirement summary change and number of times requirement has been replanned for a new iteration) that emerge as important across most projects and stages, implying future worthwhile research directions for both researchers and practitioners.", "paperid": 2728622899, "normalizedname_level1": "artificial intelligence"}
{"index": 462, "text": "This paper describes an algorithm for the automated design of whole machine learning workflows, including preprocessing of the data and automatic creation of several types of ensembles. The algorithm is based on strongly typed genetic programming which ensures the validity of the workflows. The evolution of the individuals in the population is asynchronous in order to improve the utilization of computational resources. The approach is validated on four data sets from the UCI machine learning repository.", "paperid": 2579591092, "normalizedname_level1": "artificial intelligence"}
{"index": 463, "text": "Feature selection is the important method in data mining. In the traditional batch learning method, it is difficult to retrieve the selected features or data from the large set of dataset. The offline feature selection is difficult because it follows a priori. To overcome the offline selection features we are going to online feature selection by separating as a subset using classification and clustering techniques through that it will create a table and creates the attributes automatically. We cannot predict the range of the table accurately. So we are giving an average range, which can increase or decrease. It has the most relevant and correlated data it forms a subset and compares with the entropy and then it forms a tree construction by the subsets. Through the full input and partial input it produces the efficient and relevant result with any correlation. This will analyze the problem theoretically as well as practically using different data sets.", "paperid": 2548973255, "normalizedname_level1": "artificial intelligence"}
{"index": 464, "text": "The world is experiencing a paradigm shift towards intelligent agents in form of machine learning for modeling any given task or process. Human vehicle drivers are agents that operate under stochastic environments, full of other agents. Such environments are complex to perceive and model. This study explores how a utility-based agent could be used to model human vehicle drivers. The motivation behind the study was established on the assumption that a driver agent founded on GPS data, Mixture Models and probabilistic reasoning methodologies could effectively model human vehicle drivers. The data collected by GPS receivers was appropriately analysed to establish a driver behaviour dataset. The dataset was then divided into three sets: training, test and validation sets that were used to formulate the driver agent. The agent's successive actions were evaluated against sets of performance metrics to determine accuracy, precision and recall levels. The evaluation yielded over 50% successful performance rates at all levels. The significance of the study is four-fold: First, the function of the system could be extended to providing advisory services to drivers in real-time. Second, data gathered from the system could be used by road safety stakeholders to vet drivers and to diagnose causes of road accidents. Thirdly, the resulting knowledge-base could establish standards of rationality in driving and/or formulate rules for use in driverless vehicle control systems. Finally, the model could be used to build a dataset on driver behaviour for any given vehicle driver and type and nature of operational environment.", "paperid": 3041065571, "normalizedname_level1": "artificial intelligence"}
{"index": 465, "text": "In this paper, we study oracle character recognition and general sketch recognition. First, a data set of oracle characters, which are the oldest hieroglyphs in China yet remain a part of modern Chinese characters, is collected for analysis. Second, typical visual representations in shape- and sketch-related works are evaluated. We analyze the problems suffered when addressing these representations and determine several representation design criteria. Based on the analysis, we propose a novel hierarchical representation that combines a Gabor-related low-level representation and a sparse-encoder-related mid-level representation. Extensive experiments show the effectiveness of the proposed representation in both oracle character recognition and general sketch recognition. The proposed representation is also complementary to convolutional neural network (CNN)-based models. We introduce a solution to combine the proposed representation with CNN-based models, and achieve better performances over both approaches. This solution has beaten humans at recognizing general sketches.", "paperid": 2185824196, "normalizedname_level1": "artificial intelligence"}
{"index": 466, "text": "Recently the computer vision and machine learning research communities pay a great attention to the leaf image recognition problem. Our literature survey focusing on the user interaction aspect reveals that two schemes of image acquisition have been used, one with strong constraint and the other with no constraint. The strong constraint interaction asks users to capture images by placing a leaf on a uniform background such as white paper while the unconstrained interaction allows any form of image capturing. The former one gets a high performance sacrificing the user convenience while the latter one provides a great convenience sacrificing the recognition performance. Our scheme is weakly constrained in the middle of two extremes. The proposed interaction scheme only asks users to center the leaf on smartphone camera screen. The leaf may be on the tree or off the tree. When the leaf is picked off the tree, it is recommended to place it against rather uniform background such as sky, soil, or tree bark. By fine-tuning the pre-trained CNNs (Convolutional Neural Network), we obtained a practical performance, 96.08% top-1 and 99.81% top-5 accuracies. The dataset is publicly open and the recognition system is released as an Android App.", "paperid": 2796239752, "normalizedname_level1": "artificial intelligence"}
{"index": 467, "text": "A procedure for reflection and discourse on the behavior of bots in the context of law, deception, and societal norms.", "paperid": 2747954815, "normalizedname_level1": "artificial intelligence"}
{"index": 468, "text": "In this work we combine different methodologies in order to develop algorithms for Computer-Aided Diagnosis (CAD) for brain tumors from the axial plane (T2 MRI). All methods utilize texture analysis by extracting features from raw data, without post-processing, based on different techniques, such as Gray Level Co-Occurrence Matrix (GLCM), or Discrete Wavelet Transform (DWT) and different classification methods, based on ANN or ANFIS. All of our proposed methodologies are developed, validated and verified on various sub data including 65% non-healthy MRIS. The total used database consists of 202 MRIs from non-healthy patients and 18 from healthy, segmented visually by an experienced neurosurgeon. Combining different subsets of features, our best results are by using 4 GLCM features for a 4 input and two hidden layers ANN, giving sensitivity 100%, specificity 77.8% accuracy 94.3%. It is proved that the input data to train such a CAD are considered to be unbiased if the ratio between healthy/un-healthy tissue MRIs is about 35%/65%, respectively.", "paperid": 2903956681, "normalizedname_level1": "artificial intelligence"}
{"index": 469, "text": "Recent years have seen a growing recognition of the role that affect plays in learning. Because game-based learning environments elicit a wide range of student affective states, affect-enhanced student modeling for game-based learning holds considerable promise. This paper introduces an affect-enhanced student modeling framework that leverages facial expression tracking for game-based learning. The affect-enhanced student modeling framework was used to generate predictive models of student learning and student engagement for students who interacted with CRYSTAL ISLAND, a game-based learning environment for microbiology education. Findings from the study reveal that the affect-enhanced student models significantly outperform baseline predictive student models that utilize the same gameplay traces but do not use facial expression tracking. The study also found that models based on individual facial action coding units are more effective than composite emotion models. The findings suggest that introducing facial expression tracking can improve the accuracy of student models, both for predicting student learning gains and also for predicting student engagement.", "paperid": 2732301027, "normalizedname_level1": "artificial intelligence"}
{"index": 470, "text": "This paper describes an automatic method for the optic disc localization in retinal images, which is effective and reliable with multiple datasets. Particularly, the described method reveals very effective dealing with retinal images with large pathological signs. The algorithm begins with a new vessel enhancement method based on a modified corner detector. Subsequently, a weighted version of the vessel enhancement is combined with morphological operators, to detect the four main vessels orientations   $\\lbrace 0^\\circ, 45^\\circ, 90^\\circ, 135^\\circ \\rbrace$  . These four image functions have all the necessary information to determine an initial optic disc localization, resulting in two images that are respectively divided along the vertical or horizontal orientations with different division sizes. Each division is averaged creating a 2-D step function, and a cumulative sum of the different sizes step functions is calculated in the vertical and horizontal orientations, resulting in an initial optic disc position. The final optic disc localization is determined by a vessel convergence algorithm using its two most relevant features; high vasculature convergence and high intensity values. The proposed method was evaluated in eight publicly available datasets, including the STARE and DRIVE datasets. The optic disc was localized correctly in   $1752$   out of the   $1767$   retinal images   $(99.15\\%)$   with an average computation time of   $18.34$   s.", "paperid": 2043960248, "normalizedname_level1": "artificial intelligence"}
{"index": 471, "text": "Learning to predict human body motion has emerged as a meaningful research in computer vision and artificial intelligence. This paper presents the study on predicting human body motion from video sequences. We propose a human body motion prediction network integrating the recent advanced 2D feature extraction and video sequences prediction. Based on the temporal characteristics extracted from video sequences, our network realizes the prediction of the human motion. We train the network using the video based human pose datasets and demonstrate good performance of our network on 2D human body motion prediction through quantitative and qualitative results. Experimental results prove the feasibility of our method.", "paperid": 2909800030, "normalizedname_level1": "artificial intelligence"}
{"index": 472, "text": "Mid-Infrared (MIR) spectroscopy has emerged as the most economically viable technology to determine milk values as well as to identify a set of animal phenotypes related to health, feeding, well-being and environment. However, Fourier transform-MIR spectra incurs a significant amount of redundant data. This creates critical issues such as increased learning complexity while performing Fog and Cloud based data analytics in smart farming. These issues can be resolved through data compression using unsupervisory techniques like PCA, and perform analytics in the compressed-domain i.e. without decompressing. Compression algorithms should preserve non-linearity of MIRS data (if exists), since emerging advanced learning algorithms can improve their prediction accuracy. This study has investigated the non-linearity between the feature variables in the measurement-domain as well as in two compressed domains using standard Linear PCA and Kernel PCA. Also, the non-linearity between the feature variables and the commonly used target milk quality parameters (Protein, Lactose, Fat) has been analyzed. The study evaluates the prediction accuracy using PLS and LS-SVM respectively as linear and nonlinear predictive models.", "paperid": 2771818529, "normalizedname_level1": "artificial intelligence"}
{"index": 473, "text": "In this paper, we study the problem of learning Graph Convolutional Networks (GCNs) for regression. Current architectures of GCNs are limited to the small receptive field of convolution filters and shared transformation matrix for each node. To address these limitations, we propose Semantic Graph Convolutional Networks (SemGCN), a novel neural network architecture that operates on regression tasks with graph-structured data. SemGCN learns to capture semantic information such as local and global node relationships, which is not explicitly represented in the graph. These semantic relationships can be learned through end-to-end training from the ground truth without additional supervision or hand-crafted rules. We further investigate applying SemGCN to 3D human pose regression. Our formulation is intuitive and sufficient since both 2D and 3D human poses can be represented as a structured graph encoding the relationships between joints in the skeleton of a human body. We carry out comprehensive studies to validate our method. The results prove that SemGCN outperforms state of the art while using 90% fewer parameters.", "paperid": 3098612954, "normalizedname_level1": "artificial intelligence"}
{"index": 474, "text": "The act of fraudulent credit card transaction has been increased over the past recent years, as the era of digitization hits our day-to-day life, with people are getting more involved in online banking and online transaction system. Machine learning algorithms have played a significant role in detection of credit card frauds. However, the unbalanced nature of the real-life datasets causes the traditional classification algorithms to perform low in detection of credit card fraud. In this work, a cost-sensitive weighted random forest algorithm has been proposed for effective credit card fraud detection. A cost-function has been defined in the training phase of each tree, in bagging which emphasizes to assign more weight to the minority instances during training. The trees are ranked according to their predictive ability of the minority class instances. The proposed work has been compared with two existing random-forest based techniques for two binary credit card datasets. The efficiency of the model has been evaluated in terms G-mean, F-measure and AUC values. The experimental results have established the proficiency of the proposed model, than the existing ones.", "paperid": 2998046181, "normalizedname_level1": "artificial intelligence"}
{"index": 475, "text": "Polyadenylation (Poly(A)) plays crucial roles in gene regulation, especially in messenger RNA metabolism, protein diversification, and protein localization. Accurate prediction of polyadenylation sites and identification of motifs that controlling polyadenylation are fundamental for interpreting the patterns of gene expression, improving the accuracy of genome annotation and comprehending the mechanisms that governing gene regulation. Despite considerable advances in using machine learning techniques for this problem, its efficiency is still limited by the lack of experiences and domain knowledge to carefully design and generate useful features, especially for plants. With the increasing availability of extensive genomic data sets and leading computational techniques, deep learning methods, especially convolutional neural networks, have been applied to automatically identify and understand gene regulation directly from gene sequences and predict unknown sequence profiles. Here, we present DeepPolyA, a new deep convolutional neural network-based approach, to predict polyadenylation sites from the plant Arabidopsis thaliana gene sequences. We investigate various deep neural network architectures and evaluate their performance against classical machine learning algorithms and several popular deep learning models. Experimental results demonstrate that DeepPolyA is substantially better than competing methods regarding various performance metrics. We further visualize the learned motifs of DeepPolyA to provide insights of our model and learned polyadenylation signals.", "paperid": 2799996237, "normalizedname_level1": "artificial intelligence"}
{"index": 476, "text": "We propose a hybrid Markov random field (MRF) model and a two stage cutset-MRF approach for reconstructing bilevel images from cutsets. We show that the proposed approach leads to substantial improvements over previous cutset-MRF approaches in terms of both reconstruction error and visual quality (continuity of reconstructed segments and preservation of image structure). The proposed approach approaches the performance of pattern-based approaches without the additional memory requirements and training overhead. We also show that it outperforms inpainting approaches adapted to bilevel cutset reconstruction.", "paperid": 2510893454, "normalizedname_level1": "artificial intelligence"}
{"index": 477, "text": "This paper addresses the problem of video object segmentation, where the initial object mask is given in the first frame of an input video. We propose a novel spatiotemporal Markov Random Field (MRF) model defined over pixels to handle this problem. Unlike conventional MRF models, the spatial dependencies among pixels in our model are encoded by a Convolutional Neural Network (CNN). Specifically, for a given object, the probability of a labeling to a set of spatially neighboring pixels can be predicted by a CNN trained for this specific object. As a result, higher-order, richer dependencies among pixels in the set can be implicitly modeled by the CNN. With temporal dependencies established by optical flow, the resulting MRF model combines both spatial and temporal cues for tackling video object segmentation. However, performing inference in the MRF model is very difficult due to the very high-order dependencies. To this end, we propose a novel CNN-embedded algorithm to perform approximate inference in the MRF. This algorithm proceeds by alternating between a temporal fusion step and a feed-forward CNN step. When initialized with an appearance-based one-shot segmentation CNN, our model outperforms the winning entries of the DAVIS 2017 Challenge, without resorting to model ensembling or any dedicated detectors.", "paperid": 2794847483, "normalizedname_level1": "artificial intelligence"}
{"index": 478, "text": "We present a novel framework for precisely estimating dense depth maps by combining 3D lidar scans with a set of uncalibrated camera RGB color images for the same scene. Rough estimates for 3D structure obtained using structure from motion (SfM) on the uncalibrated images are first co-registered with the lidar scan and then a precise alignment between the datasets is estimated by identifying correspondences between the captured images and reprojected images for individual cameras from the 3D lidar point clouds. The precise alignment is used to update both the camera geometry parameters for the images and the individual camera radial distortion estimates, thereby providing a 3D-to-2D transformation that accurately maps the 3D lidar scan onto the 2D image planes. The 3D to 2D map is then utilized to estimate a dense depth map for each image. Experimental results on two datasets that include independently acquired high-resolution color images and 3D point cloud datasets indicate the utility of the framework. The proposed approach offers significant improvements on results obtained with SfM alone.", "paperid": 2691889327, "normalizedname_level1": "artificial intelligence"}
{"index": 479, "text": "Kinship verification has a number of applications such as organizing large collections of images and recognizing resemblances among humans. In this research, first, a human study is conducted to understand the capabilities of human mind and to identify the discriminatory areas of a face that facilitate kinship-cues. Utilizing the information obtained from the human study, a hierarchical Kinship Verification via Representation Learning (KVRL) framework is utilized to learn the representation of different face regions in an unsupervised manner. We propose a novel approach for feature representation termed as filtered contractive deep belief networks (fcDBN). The proposed feature representation encodes relational information present in images using filters and contractive regularization penalty. A compact representation of facial images of kin is extracted as an output from the learned model and a multi-layer neural network is utilized to verify the kin accurately. A new WVU Kinship Database is created which consists of multiple images per subject to facilitate kinship verification. The results show that the proposed deep learning framework (KVRL-fcDBN) yields stateof-the-art kinship verification accuracy on the WVU Kinship database and on four existing benchmark datasets. Further, kinship information is used as a soft biometric modality to boost the performance of face verification via product of likelihood ratio and support vector machine based approaches. Using the proposed KVRL-fcDBN framework, an improvement of over 20% is observed in the performance of face verification.", "paperid": 2520903215, "normalizedname_level1": "artificial intelligence"}
{"index": 480, "text": "The ability to produce convincing textural details is essential for the fidelity of synthesized person images. However, existing methods typically follow a ``warping-based'' strategy that propagates appearance features through the same pathway used for pose transfer. However, most fine-grained features would be lost due to down-sampling, leading to over-smoothed clothes and missing details in the output images. In this paper we presents RATE-Net, a novel framework for synthesizing person images with sharp texture details. The proposed framework leverages an additional texture enhancing module to extract appearance information from the source image and estimate a fine-grained residual texture map, which helps to refine the coarse estimation from the pose transfer module. In addition, we design an effective alternate updating strategy to promote mutual guidance between two modules for better shape and appearance consistency. Experiments conducted on DeepFashion benchmark dataset have demonstrated the superiority of our framework compared with existing networks.", "paperid": 3032562988, "normalizedname_level1": "artificial intelligence"}
{"index": 481, "text": "High resolution 3D mapping of road systems is currently being carried out by expensive Mobile Mapping Systems (MMS) but coverage is limited. Recently Low Cost Sensor (LCS) systems have been developed which use common, low cost, internal MEMS position sensors from mobile phones, but such sensors come with a reduced absolute and relative positional accuracy. This study investigates the registration of LCS maps within MMS maps to improve map coverage and lower costs. MMS and LCS maps of a real world environment are made and registration is performed using feature matching and Iterative Closest Point alignment. Accuracy of ICP alignment is approximately (10cm) and local convergence is possible up to (1m). A combination of feature matching and ICP is used to demonstrate accurate alignment from an initial error of (10m). An example of a LCS map aligned within a MMS map is presented to confirm the use of LCS systems to extend 3D mapping coverage.", "paperid": 2579905492, "normalizedname_level1": "artificial intelligence"}
{"index": 482, "text": "Organizations not only need to defend their IT systems against external cyber attackers, but also from malicious insiders, that is, agents who have infiltrated an organization or malicious members stealing information for their own profit. In particular, malicious insiders can leak a document by simply opening it and taking pictures of the document displayed on the computer screen with a digital camera. Using a digital camera allows a perpetrator to easily avoid a log trail that results from using traditional communication channels, such as sending the document via email. This makes it difficult to identify and prove the identity of the perpetrator. Even a policy prohibiting the use of any device containing a camera cannot eliminate this threat since tiny cameras can be hidden almost everywhere. To address this leakage vector, we propose a novel screen watermarking technique that embeds hidden information on computer screens displaying text documents. The watermark is imperceptible during regular use, but can be extracted from pictures of documents shown on the screen, which allows an organization to reconstruct the place and time of the data leak from recovered leaked pictures. Our approach takes advantage of the fact that the human eye is less sensitive to small luminance changes than digital cameras. We devise a symbol shape that is invisible to the human eye, but still robust to the image artifacts introduced when taking pictures. We complement this symbol shape with an error correction coding scheme that can handle very high bit error rates and retrieve watermarks from cropped and compressed pictures. We show in an experimental user study that our screen watermarks are not perceivable by humans and analyze the robustness of our watermarks against image modifications.", "paperid": 2855392440, "normalizedname_level1": "artificial intelligence"}
{"index": 483, "text": "When the number of categories is growing into thousands, large-scale image retrieval becomes an increasingly hard task. Retrieval accuracy can be improved by learning distance metric methods that separate categories in a transformed embedding space. Unlike most methods that utilize a single embedding to learn a distance metric, we build on the idea of boosted metric learning, where an embedding is split into a boosted ensemble of embeddings. While in general metric learning is directly applied on fine labels to learn embeddings, we take this one step further and incorporate hierarchical label information into the boosting framework and show how to properly adapt loss functions for this purpose. We show that by introducing several sub-embeddings which focus on specific hierarchical classes, the retrieval accuracy can be improved compared to standard flat label embeddings. The proposed method is especially suitable for exploiting hierarchical datasets or when additional labels can be retrieved without much effort. Our approach improves R@1 over state-of-the-art methods on the biggest available retrieval dataset (Stanford Online Products) and sets new reference baselines for hierarchical metric learning on several other datasets (CUB-200-2011, VegFru, FruitVeg-81). We show that the clustering quality in terms of NMI score is superior to previous works.", "paperid": 2911757592, "normalizedname_level1": "artificial intelligence"}
{"index": 484, "text": "Switching systems are systems comprising a set of continuous dynamics orchestrated by a switching signal. This type of system can represent a very broad spectrum of systems such as: power electronics, multi-controller systems, robotics, electromechanical systems and systems with discontinuities. As a result, the development of tools allowing analyze the dynamic properties such as observability is essential before any order design step. In this paper, a necessary and sufficient condition for the continuous state observability for a given periodic sequence of discrete modes is elaborated for switched linear system. The characterization of the continuous state observability is derived using geometrical tools. Concrete example as multilevel converter i.e two-cells is reported to highlight the derived results. Super twisting sliding mode observer are developed. This one is applied to the estimation of the floating capacitor voltage of the converter based on the load current measurement and the knowledge of the periodic sequence of discrete modes. Simulation results confirm the analytical demonstrations and prove the effectiveness of observer.", "paperid": 3010018309, "normalizedname_level1": "artificial intelligence"}
{"index": 485, "text": "Image is usually taken for expressing some kinds of emotions or purposes, such as love, celebrating Christmas. There is another better way that combines the image and relevant song to amplify the expression, which has drawn much attention in the social network recently. Hence, the automatic selection of songs should be expected. In this paper, we propose to retrieve semantic relevant songs just by an image query, which is named as the image2song problem. Motivated by the requirements of establishing correlation in semantic/content, we build a semantic-based song retrieval framework, which learns the correlation between image content and lyric words. This model uses a convolutional neural network to generate rich tags from image regions, a recurrent neural network to model lyric, and then establishes correlation via a multi-layer perceptron. To reduce the content gap between image and lyric, we propose to make the lyric modeling focus on the main image content via a tag attention. We collect a dataset from the social-sharing multimodal data to study the proposed problem, which consists of (image, music clip, lyric) triplets. We demonstrate that our proposed model shows noticeable results in the image2song retrieval task and provides suitable songs. Besides, the song2image task is also performed.", "paperid": 2964047692, "normalizedname_level1": "artificial intelligence"}
{"index": 486, "text": "Sweep scan is an emerging five-axis inspection technology of retrieving geometric data from free-form surfaces. Compared with the traditional surface inspection by coordinate measuring machine (CMM) that works in a point-by-point manner, sweep scan is able to make the stylus tip continuously sweep at high speed on the surface to inspect, whilst acquiring the 3-D point data accurately and efficiently. However, at present, for an arbitrary free-form surface, it still heavily depends on humans to manually generate a suitable sweep scan path. This paper presents a practical sweep scan path planning method, which can automatically generate an efficient sweep scan path for an arbitrary free-form surface. The resultant sweep scan path is able to cater to the shape of the surface to inspect and the unique kinematic characteristics of the typical five-axis inspection machine, so as to achieve a tremendous increase in inspection efficiency. The experiments performed by us show that when compared with some existing automatic sweep scan path generation algorithms such as the simple zigzag method, the proposed method is able to reduce the total inspection time by as much as seven times.  Note to Practitioners —This paper is motivated by the lack of effective automatic sweep scan path planning methods for arbitrary free-form surfaces. Although there is a rich body of five-axis CMM path planning methods for inspection of free-form surfaces, they are mainly designed for the traditional inspection mode, i.e., the point-by-point measurement. Compared with the traditional discrete way of CMM inspection, sweep scan has a quite different inspection mode, which tremendously boosts the inspection efficiency by maintaining the constant contact between the stylus and the surface to inspect. The traditional five-axis inspection path planning methods are no longer applicable to sweep scan. Up to date, only a very handful few of automatic sweep scan path planning methods are reported and they seem to be very difficult to implement and no optimality of inspection efficiency is discussed. We present a practical algorithm for automatic generation of sweep scan paths for inspection of an arbitrary free-form surface. The algorithm is novel in that, by considering both the surface shape and the unique kinematic characteristics of a typical five-axis inspection machine, it tries to globally minimize the total inspection time. In our experiments, the sweep scan paths, generated by the proposed method, are found to outperform that of some traditional simple sweep scan path generation methods such as the zigzag method by a large margin in terms of total inspection time (while the data acquisition accuracy is maintained at the same level). The method is particularly suitable for those industrial parts that are large but relatively smooth, such as windmill blades and automobile panels.", "paperid": 2799864686, "normalizedname_level1": "artificial intelligence"}
{"index": 487, "text": "In this paper, we propose a scheme for classification of maritime targets through fusion of images collected from dissimilar sensors with an objective to improve maritime domain awareness. Low- and medium-level fusion methods are applied to three types of image data—visual, thermal, multi-spectral—using features obtained from the speeded-up robust features algorithm. The goal was to implement the classification scheme using machine learning techniques. Results indicate that multi-spectral images from low-level fusion yielded the best classification performance. Artificial neural networks are used to derive the classification results and demonstrate the ability to obtain results in a timely manner that could accommodate near real-time classification.", "paperid": 2514045615, "normalizedname_level1": "artificial intelligence"}
{"index": 488, "text": "Word similarity (WS) plays an important role in natural language processing. Existing approaches to WS are mainly based on word embedding, which is obtained by massive and high-quality corpus, and they neglect insufficient corpus about some specific fields, and do not consider the prior knowledge which can provide useful semantic information to calculate the similarity of word pairs. In this paper, we propose a hybrid word representation method and combine multiple prior knowledge with context semantic information to address WS task. First, the core of our method is the construction of a related word set including word concept, character concept and word synonyms for each word, which extracted from existing knowledge bases, to enrich the semantic knowledge under small corpus. Then, we encode the related word set based on pre-trained word embedding model and aggregate these vectors into a related vector with semantic weights to obtain the prior knowledge of related word sets. Finally, we incorporate related vector into context vector of the word to train a specific WS task. Compared with baseline models, the experiments on similarity evaluation datasets validate the effectiveness of our hybrid model in WS task.", "paperid": 3040794994, "normalizedname_level1": "artificial intelligence"}
{"index": 489, "text": "One of the global main goal of the safety driving system is protecting the driver, passenger(s), car, and surrounding environment against accident which are caused by external and internal factors. Driver fatigue, one of the major internal factors, is a leading reason of vehicle breakdown according to a survey done by National Highway Traffic Safety Administration (NHTSA). Thus, it is necessary to build driver fatigue monitoring system. We, then, propose a technique based on optical imaging through digital camera that installed on the car dashboard. The camera detects and tracks the driver face. From the driver face, we can apply non-contact photoplesthymography (PPG) in order to get multiple physiological signals such as brainwave, cardiac and respiration pulses. Those physiological signals can be utilized to measure fatigue level. Alteration in facial features like eyes, mouth, and head, can be used to observe the driver fatigue as well. We propose to use supervised descent method (SDM) with scale-invariant feature transform (SIFT) to excerpt information from the facial features. To classify the fatigue level from those multiple parameters, support vector machine (SVM) will be implemented.", "paperid": 2578765098, "normalizedname_level1": "artificial intelligence"}
{"index": 490, "text": "The state-of-the-art online learning approaches are only capable of learning the metric for predefined tasks. In this paper, we consider a lifelong learning problem to mimic “human learning,” i.e., endowing a new capability to the learned metric for a new task from new online samples and incorporating the previous experiences. Therefore, we propose a new metric learning framework: lifelong metric learning (LML), which only utilizes the data of the new task to train the metric model while preserving the original capabilities. More specifically, the proposed LML maintains a common subspace for all learned metrics, named lifelong dictionary, transfers knowledge from the common subspace to learn each new metric learning task with task-specific idiosyncrasy, and redefines the common subspace over time to maximize performance across all metric tasks. For model optimization, we apply online passive aggressive optimization algorithm to achieve lifelong metric task learning, where the lifelong dictionary and task-specific partition are optimized alternatively and consecutively. Finally, we evaluate our approach by analyzing several multitask metric learning datasets. Extensive experimental results demonstrate effectiveness and efficiency of the proposed framework.", "paperid": 2963018216, "normalizedname_level1": "artificial intelligence"}
{"index": 491, "text": "With the continuous development of online learning platforms, educational data analytics and prediction have become a promising research field, which are helpful for the development of personalized learning system. However, the indicator's selection process does not combine with the whole learning process, which may affect the accuracy of prediction results. In this paper, we induce 19 behavior indicators in the online learning platform, proposing a student performance prediction model which combines with the whole learning process. The model consists of four parts: data collection and pre-processing, learning behavior analytics, algorithm model building and prediction. Moreover, we apply an optimized Logistic Regression algorithm, taking a case to analyze students' behavior and to predict their performance. Experimental results demonstrate that these eigenvalues can effectively predict whether a student was probably to have an excellent grade.", "paperid": 2745106175, "normalizedname_level1": "artificial intelligence"}
{"index": 492, "text": "This paper introduces the Attribute-Decomposed GAN, a novel generative model for controllable person image synthesis, which can produce realistic person images with desired human attributes (e.g., pose, head, upper clothes and pants) provided in various source inputs. The core idea of the proposed model is to embed human attributes into the latent space as independent codes and thus achieve flexible and continuous control of attributes via mixing and interpolation operations in explicit style representations. Specifically, a new architecture consisting of two encoding pathways with style block connections is proposed to decompose the original hard mapping into multiple more accessible subtasks. In source pathway, we further extract component layouts with an off-the-shelf human parser and feed them into a shared global texture encoder for decomposed latent codes. This strategy allows for the synthesis of more realistic output images and automatic separation of un-annotated attributes. Experimental results demonstrate the proposed method's superiority over the state of the art in pose transfer and its effectiveness in the brand-new task of component attribute transfer.", "paperid": 3035515747, "normalizedname_level1": "artificial intelligence"}
{"index": 493, "text": "The development of human-robot systems able to leverage the strengths of both humans and their robotic counterparts has been greatly sought after because of the foreseen, broad-ranging impact across industry and research. We believe the true potential of these systems cannot be reached unless the robot is able to act with a high level of autonomy, reducing the burden of manual tasking or teleoperation. To achieve this level of autonomy, robots must be able to work fluidly with its human partners, inferring their needs without explicit commands. This inference requires the robot to be able to detect and classify the heterogeneity of its partners. We propose a framework for learning from heterogeneous demonstration based upon Bayesian inference and evaluate a suite of approaches on a real-world dataset of gameplay from StarCraft II. This evaluation provides evidence that our Bayesian approach can outperform conventional methods by up to 12.8%.", "paperid": 3106187514, "normalizedname_level1": "artificial intelligence"}
{"index": 494, "text": "Photo response non-uniformity (PRNU) noise is a sensor pattern noise characterizing the imaging device. It has been broadly used in the literature for source camera identification and image authentication. The abundant information that the sensor pattern noise carries in terms of the frequency content makes it unique, and hence suitable for identifying the source camera and detecting image forgeries. However, the PRNU extraction process is inevitably faced with the presence of image-dependent information as well as other non-unique noise components. To reduce such undesirable effects, researchers have developed a number of techniques in different stages of the process, i.e., the filtering stage, the estimation stage, and the post-estimation stage. In this paper, we present a new PRNU-based source camera identification and verification system and propose enhancements in different stages. First, an improved version of the locally adaptive discrete cosine transform filter is proposed in the filtering stage. In the estimation stage, a new weighted averaging technique is presented. The post-estimation stage consists of concatenating the PRNUs estimated from color planes in order to exploit the presence of physical PRNU components in different channels. Experimental results on two image data sets acquired by various camera devices have shown a significant gain obtained with the proposed enhancements in each stage as well as the superiority of the overall system over related state-of-the-art systems.", "paperid": 2537160348, "normalizedname_level1": "artificial intelligence"}
{"index": 495, "text": "Genetic Programming (GP) has been around for over two decades and has been used in a wide range of practical applications producing human competitive results in several domains. In this paper we present a discussion and a proposal of a GP algorithm that could be conveniently implemented on an embedded system, as part of a broader research project that pursues the implementation of a complete GP system in a Field Programmable Gate Array (FPGA). Motivated by the significant time savings associated with such a platform, as well as low power consumption, low maintenance requirements, small size of the system and the possibility of performing several parallel processes. The proposal is focused on the Geometric Semantic Genetic Programming (GSGP) approach that has been recently introduced with promising results. GSGP induces a unimodal fitness landscape, simplifying the search process. The experimental work considers five variants of GSGP, that incorporate local search strategies, optimal mutations and alignment in error space. Best results were obtained by a simple variant that uses both the optimal mutation step and the standard geometric semantic mutation, using three difficult real-world problems to evaluate the methods, outperforming the original GSGP formulation in terms of fitness and empirical convergence.", "paperid": 2727672025, "normalizedname_level1": "artificial intelligence"}
{"index": 496, "text": "Based on convolutional neural network and face detection algorithm, this paper proposes a training sample expansion strategy, and a parallel convolutional network face detection algorithm for face features, occlusion and illumination detection, combined with Relu activation function and Dropout random regularization strategy. Network training not only speeds up the convergence of the network, but also improves the generalization ability. On this basis, the software based on face detection and feature point location is designed to realize the automatic loading of images and the face recognition function, to achieve accurate positioning of the face points, and to locate experiments on the LWF face database. The results show that the method is greatly improved in accuracy and reliability, and it can achieve robust and accurate estimation of key points.", "paperid": 3027675561, "normalizedname_level1": "artificial intelligence"}
{"index": 497, "text": "This paper proposes a novel generic one-class feature learning method based on intra-class splitting. In one-class classification, feature learning is challenging, because only samples of one class are available during training. Hence, state-of-the-art methods require reference multi-class datasets to pretrain feature extractors. In contrast, the proposed method realizes feature learning by splitting the given normal class into typical and atypical normal samples. By introducing closeness loss and dispersion loss, an intra-class joint training procedure between the two subsets after splitting enables the extraction of valuable features for one-class classification. Various experiments on three well-known image classification datasets demonstrate the effectiveness of our method which outperformed other baseline models in average.", "paperid": 2904870931, "normalizedname_level1": "artificial intelligence"}
{"index": 498, "text": "Clinicians are interested in the estimation of robust and relevant genetic signatures from gene sequencing data. Many machine learning approaches have been proposed trying to address well-known issues of this complex task (feature or gene selection, classification or model selection, and prediction assessment). Addressing this problem often requires a deep knowledge of these methods and some of them demand high computational resources that may not be affordable. In this paper, an exhaustive study that includes different types of feature selection methods and classifiers is presented, providing clinicians an useful insight of the most suitable methods for this purpose. Predictions assessment is performed using a bootstrap cross-validation strategy as an honest validation scheme. The results of this study for six benchmark datasets show that filter or embedded methods are preferred, in general, to wrapper methods according to their better statistical significant results, in terms of accuracy, and lower demand for computational resources.", "paperid": 2736281184, "normalizedname_level1": "artificial intelligence"}
{"index": 499, "text": "Tomographic Synthetic Aperture Radar (TomoSAR) has become a competitive remote sensing method of three-dimensional (3-D) reconstruction over urban areas. Raw TomoSAR point clouds are inevitably noise-corrupted, which would severely obstruct the reconstruction of building structures. Whereas, data segmentation and parameter tuning are required in current methods of 3-D building reconstruction, which influences the precision and efficiency of the reconstruction process. In this paper we propose a novel method using neural networks to reconstruct 3-D building structures from TomoSAR data. By using the proposed method, the precise 3-D surface of the building structure can be retrieved quickly. The proposed method also performs commendably in point cloud denoising. More importantly, our method achieves full automation of the reconstruction process, which does not require data segmentation or complex parameter adjusting. Experiment results demonstrate the effectiveness of the proposed method.", "paperid": 3080378341, "normalizedname_level1": "artificial intelligence"}
{"index": 500, "text": "A great advantage of multispectral technique is to pursue better recognition performance through band fusion. Adding more bands can build larger feature dimension space while bringing in more redundant information. This paper tries to optimize band set for multispectral dorsal hand recognition mainly in near infrared (NIR) light. Images at 35 bands are sampled uniformly from 700nm to 1040nm, and then band distribution is analyzed for multispectral biometric specialty. Multi-band selection is processed in two steps. First, the whole NIR region is divided into several band clusters according to maximum irrelevance principle. Second, representative bands are chosen from these clusters for recognition rate ranking. Our scheme focuses on accuracy and rapidity simultaneously. Experiment shows the robustness of improved clustering method and the high fusion performance. The proposed band selection method can be applied to other multispectral database with consecutive band feature change.", "paperid": 2921759621, "normalizedname_level1": "artificial intelligence"}
{"index": 501, "text": "Recent advancements in fields like Internet of Things (IoT), augmented reality, etc. have led to an unprecedented demand for miniature cameras with low cost that can be integrated anywhere and can be used for distributed monitoring. Mask-based lensless imaging systems make such inexpensive and compact models realizable. However, reduction in the size and cost of these imagers comes at the expense of their image quality due to the high degree of multiplexing inherent in their design. In this paper, we present a method to obtain image reconstructions from mask-based lensless measurements that are more photorealistic than those currently available in the literature. We particularly focus on FlatCam, a lensless imager consisting of a coded mask placed over a bare CMOS sensor. Existing techniques for reconstructing FlatCam measurements suffer from several drawbacks including lower resolution and dynamic range than lens-based cameras. Our approach overcomes these drawbacks using a fully trainable non-iterative deep learning based model. Our approach is based on two stages: an inversion stage that maps the measurement into the space of intermediate reconstruction and a perceptual enhancement stage that improves this intermediate reconstruction based on perceptual and signal distortion metrics. Our proposed method is fast and produces photo-realistic reconstruction as demonstrated on many real and challenging scenes.", "paperid": 3009113828, "normalizedname_level1": "artificial intelligence"}
{"index": 502, "text": "Liveness detection is an anti-spoofing technique for dealing with presentation attacks on biometrics authentication systems. Since biometrics are usually visible to everyone, they can be easily captured by a malignant user and replicated to steal someone's identity. In particular, fingerprints can be easily reproduced by using gummy materials and attached to the impostor's fingertips, making the attack go unnoticed by security personnel and camera networks. In this paper, the classical binary classification formulation (live/fake) is substituted by a deep metric learning framework that can generate a representation of real and artificial fingerprints and explicitly models the underlying factors that explain their inter-and intra-class variations. The framework is based on a deep triplet network architecture and consists of a variation of the original triplet loss function. Experiments show that the approach can perform liveness detection in real-time outperforming the state-of-the-art on several benchmark datasets.", "paperid": 2790385680, "normalizedname_level1": "artificial intelligence"}
{"index": 503, "text": "In order to assist recognition of driver, it is effective for driver to teach recognition objects in a visual way. However, it is expected that too much information is provided for a driver from the system and it cause him distraction. Therefore, information presentation without exaggeration and without omission is demanded for assistant system. In this paper, it is assumed that the objects which contribute to driver’s braking operation should be presented to him. However, these objects changes according to the facing driving situation. Therefore, a selection method of these objects in the appeared objects on driving environment based on a statistical driving behavior model is proposed in this paper. In this method, a driving behavior model is generated, which is consisted of objects detection model with deep neural network structure and time series correlation model between the appeared objects and braking operation with probabilistic model structure. The probability of contributing to braking operation for all appeared objects in driving environment is calculated based on the driving behavior model, and the objects with the high probability are selected as the object which contributes to braking operation.In the experiment, the selection and presentation accuracy of the object which contributes to braking operation was examined. As the results, it was confirmed that the appropriate object can be selected by using the proposed method, and this method has an effect of reducing false or unnecessary presentation information.", "paperid": 2954196949, "normalizedname_level1": "artificial intelligence"}
{"index": 504, "text": "Scene understanding is paramount in robotics, self-navigation, augmented reality, and many other fields. To fully accomplish this task, an autonomous agent has to infer the 3D structure of the sensed scene (to know where it looks at) and its content (to know what it sees). To tackle the two tasks, deep neural networks trained to infer semantic segmentation and depth from stereo images are often the preferred choices. Specifically, Semantic Stereo Matching can be tackled by either standalone models trained for the two tasks independently or joint end-to-end architectures. Nonetheless, as proposed so far, both solutions are inefficient because requiring two forward passes in the former case or due to the complexity of a single network in the latter, although jointly tackling both tasks is usually beneficial in terms of accuracy. In this paper, we propose a single compact and lightweight architecture for real-time semantic stereo matching. Our framework relies on coarse-to-fine estimations in a multi-stage fashion, allowing: i) very fast inference even on embedded devices, with marginal drops in accuracy, compared to state-of-the-art networks, ii) trade accuracy for speed, according to the specific application requirements. Experimental results on high-end GPUs as well as on an embedded Jetson TX2 confirm the superiority of semantic stereo matching compared to standalone tasks and highlight the versatility of our framework on any hardware and for any application.", "paperid": 3048395011, "normalizedname_level1": "artificial intelligence"}
{"index": 505, "text": "In this letter, we propose a machine learning solution for crowd-size classification in an indoor environment. Narrow-band radio frequency signals are used to identify a pattern according to the number of people. Experimental data collected by a low-cost software-defined radio platform are postprocessed by applying a feature mapping along with the random forest technique for classifying the crowd-size scenarios. The proposed solution has significant accuracy in classification performance.", "paperid": 2983266295, "normalizedname_level1": "artificial intelligence"}
{"index": 506, "text": "With the exponential growth of digital multimedia resources, in the real-world, most of the data are represented as a multi-modal form and usually with multiple semantic labels. Nowadays, Multi-modal Multi-label learning has become a very hot topic. However, previous methods either have not considered the relation between modalities and labels or the correlation among labels. In this paper, we considered the following three questions: (1) How to model the correlation among labels? (2) Is there a correlation between modality and label? (3) Whether the modal input order affects the prediction of individual instance, and how to find the most appropriate modal input sequence for each instance? To solve above problems, we proposed a novel method for Multi-modal Multi-label learning(MMML), which based on Encoder-Decoder with attention framwork named MMML-Attention(M3LA). The M3LA takes into account all of these issues. Specifically, benefit from the Encoder-Decoder with attention structure, on the one hand, M3LA can model the relation between modalities and labels. On the other hand, we introduce a correlation matrix to learn the correlation among labels, which can be obtained as parameter through the training process. It should be mentioned that label prediction occurs at every step of the decoder, and the prediction of the label is constantly corrected and then the most accurate prediction is obtained. To validate the effectiveness of the proposed method, we expermiented on widely used several benchmark datasets and compared with state-of-art approaches.", "paperid": 3090167799, "normalizedname_level1": "artificial intelligence"}
{"index": 507, "text": "The proportion of drivers causing traffic accidents due to fatigue driving has been increasing year by year, which has become one of the main causes of traffic accidents. Therefore, accurate and effective detection of driver fatigue is a hot research topic at present. In this article, the driver's head posture estimation based on face key points is used to judge fatigue. Firstly, the face image is collected from the camera in real time. The model-based method is used to estimate the head posture of the person. The face key points method based on the Dlib library is used to judge the eye state, the mouth state, the head turning posture of the person. The experimental results show that the head pose estimation method based on face key points can accurately judge the fatigue state, and has good real-time and accuracy.", "paperid": 3009901566, "normalizedname_level1": "artificial intelligence"}
{"index": 508, "text": "Probabilistic representations of movement primitives open important new possibilities for machine learning in robotics. These representations are able to capture the variability of the demonstrations from a teacher as a probability distribution over trajectories, providing a sensible region of exploration and the ability to adapt to changes in the robot environment. However, to be able to capture variability and correlations between different joints, a probabilistic movement primitive requires the estimation of a larger number of parameters compared to their deterministic counterparts, which focus on modeling only the mean behavior. In this article, we make use of prior distributions over the parameters of a probabilistic movement primitive to make robust estimates of the parameters with few training instances. In addition, we introduce general purpose operators to adapt movement primitives in joint and task space. The proposed training method and adaptation operators are tested in a coffee preparation and in robot table tennis task. In the coffee preparation task we evaluate the generalization performance to changes in the location of the coffee grinder and brewing chamber in a target area, achieving the desired behavior after only two demonstrations. In the table tennis task we evaluate the hit and return rates, outperforming previous approaches while using fewer task specific heuristics.", "paperid": 3009632987, "normalizedname_level1": "artificial intelligence"}
{"index": 509, "text": "The goal of document image quality assessment (DIQA) is to build a computational model which can predict the degree of degradation for document images. Based on the estimated quality scores, the immediate feedback can be provided by document processing and analysis systems, which helps to maintain, organize, recognize and retrieve the information from document images. Recently, the bag-of-visual-words (BoV) based approaches have gained increasing attention from researchers to fulfill the task of quality assessment, but how to use BoV to represent images more accurately is still a challenging problem. In this paper, we propose to utilize a sparse representation based method to estimate document image's quality with respect to the OCR capability. Unlike the conventional sparse representation approaches, we introduce the target quality scores into the training phase of sparse representation. The proposed method improves the discriminability of the system and ensures the obtained codebook is more suitable for our assessment task. The experimental results on a public dataset show that the proposed method outperforms other hand-crafted and BoV based DIQA approaches.", "paperid": 2428095924, "normalizedname_level1": "artificial intelligence"}
{"index": 510, "text": "This article analyzes the costume design of the Hakka Kaleidoscope opera, explore the Hakka ethnic and local customs and practices, in order to study the stage costume style description and display design, and summarizes some characteristics of stage costume design. Hope to work together with the stage clothing designer, in the creation of relevant works of art should vigorously carry forward the tradition and folk culture.", "paperid": 2739325566, "normalizedname_level1": "artificial intelligence"}
{"index": 511, "text": "Domain adaptive image retrieval includes single-domain retrieval and cross-domain retrieval. Most of the existing image retrieval methods only focus on single-domain retrieval, which assumes that the distributions of retrieval databases and queries are similar. However, in practical application, the discrepancies between retrieval databases often taken in ideal illumination/pose/background/camera conditions and queries usually obtained in uncontrolled conditions are very large. In this paper, considering the practical application, we focus on challenging cross-domain retrieval. To address the problem, we propose an effective method named Probability Weighted Compact Feature Learning (PWCF), which provides inter-domain correlation guidance to promote cross-domain retrieval accuracy and learns a series of compact binary codes to improve the retrieval speed. First, we derive our loss function through the Maximum A Posteriori Estimation (MAP): Bayesian Perspective (BP) induced focal-triplet loss, BP induced quantization loss and BP induced classification loss. Second, we propose a common manifold structure between domains to explore the potential correlation across domains. Considering the original feature representation is biased due to the inter-domain discrepancy, the manifold structure is difficult to be constructed. Therefore, we propose a new feature named Histogram Feature of Neighbors (HFON) from the sample statistics perspective. Extensive experiments on various benchmark databases validate that our method outperforms many state-of-the-art image retrieval methods for domain adaptive image retrieval. The source code is available at {https://github.com/fuxianghuang1/PWCF}.", "paperid": 3034971598, "normalizedname_level1": "artificial intelligence"}
{"index": 512, "text": "Extraction of relevant features is of significant importance for brain tumor segmentation systems. To improve brain tumor segmentation accuracy, the authors present an improved feature extraction component that takes advantage of the correlation between intracranial structure deformation and the compression resulting from brain tumor growth. Using 3D nonrigid registration and deformation modeling techniques, the component measures lateral ventricular (LaV) deformation in volumetric magnetic resonance images. By verifying the location of the extracted LaV deformation feature data and applying the features on brain tumor segmentation with widely used classification algorithms, the authors evaluate the proposed component qualitatively and quantitatively with promising results on 11 datasets comprising real and simulated patient images.", "paperid": 2311747147, "normalizedname_level1": "artificial intelligence"}
{"index": 513, "text": "The advent of DNA microarray technology has paved the way to providing increased opportunities to the molecular biologists to analyze the expression level of thousands of genes (features) in one experiment. The gene expression level provides the possibility of diagnosing various diseases such as cancer. In this regard, several computational techniques such as pattern classification approaches can be applied. However, the existence of a huge quantity of genes and very few patients' samples available hinders the classifier or machine learning techniques from producing accurate classification results. Most of these genes are irrelevant and redundant, which may deteriorate the classification performance. Therefore, gene selection is needed to select the most relevant genes. This paper proposes hybrid filter-wrapper gene selection method using Minimum Redundancy Maximum Relevancy (MRMR) as the filter approach and flower pollination algorithm (FPA) as the wrapper approach. MRMR was used to find the most important genes from all genes in the gene expression data, and FPA is employed in order to locate the most informative gene subset from the reduce set that obtained by MRMR. To test the accuracy and performance of the study's proposed method, extensive experiments are conducted and three microarray datasets are used. They include Colon, Breast, and Ovarian. A similar procedure has been performed on the Genetic algorithm (GA) in comparison with the proposed method (MRMR-FPA) in this study. The results concluded that the MRMR-FPA can be used as an alternative method to address the gene selection problem.", "paperid": 2899880384, "normalizedname_level1": "artificial intelligence"}
{"index": 514, "text": "This paper tackles the task of semi-supervised video object segmentation, i.e., the separation of an object from the background in a video, given the mask of the first frame. We present One-Shot Video Object Segmentation (OSVOS), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one-shot). Although all frames are processed independently, the results are temporally coherent and stable. We perform experiments on two annotated video segmentation databases, which show that OSVOS is fast and improves the state of the art by a significant margin (79.8% vs 68.0%).", "paperid": 2963253279, "normalizedname_level1": "artificial intelligence"}
{"index": 515, "text": "With advanced image journaling tools, one can easily alter the semantic meaning of an image by exploiting certain manipulation techniques such as copy clone, object splicing, and removal, which mislead the viewers. In contrast, the identification of these manipulations becomes a very challenging task as manipulated regions are not visually apparent. This paper proposes a high-confidence manipulation localization architecture that utilizes resampling features, long short-term memory (LSTM) cells, and an encoder–decoder network to segment out manipulated regions from non-manipulated ones. Resampling features are used to capture artifacts, such as JPEG quality loss, upsampling, downsampling, rotation, and shearing. The proposed network exploits larger receptive fields (spatial maps) and frequency-domain correlation to analyze the discriminative characteristics between the manipulated and non-manipulated regions by incorporating the encoder and LSTM network. Finally, the decoder network learns the mapping from low-resolution feature maps to pixel-wise predictions for image tamper localization. With the predicted mask provided by the final layer (softmax) of the proposed architecture, end-to-end training is performed to learn the network parameters through back-propagation using the ground-truth masks. Furthermore, a large image splicing dataset is introduced to guide the training process. The proposed method is capable of localizing image manipulations at the pixel level with high precision, which is demonstrated through rigorous experimentation on three diverse datasets.", "paperid": 2911605501, "normalizedname_level1": "artificial intelligence"}
{"index": 516, "text": "Offline Signature Verification (OSV) is a challenging pattern recognition task, especially when it is expected to generalize well on the skilled forgeries that are not available during the training. Its challenges also include small training sample and large intra-class variations. Considering the limitations, we suggest a novel transfer learning approach from Persian handwriting domain to multi-language OSV domain. We train two Residual CNNs on the source domain separately based on two different tasks of word classification and writer identification. Since identifying a person's signature resembles identifying one's handwriting, it seems perfectly convenient to use handwriting for the feature learning phase. The learned representation on the more varied and plentiful handwriting dataset can compensate for the lack of training data in the original task, i.e. OSV, without sacrificing the generalizability. Our proposed OSV system includes two steps: learning representation and verification of the input signature. For the first step, the signature images are fed into the trained Residual CNNs. The output representations are then used to train SVMs for the verification. We test our OSV system on three different signature datasets, including MCYT (a Spanish signature dataset), UTSig (a Persian one) and GPDS-Synthetic (an artificial dataset). On UTSIG, we achieved 9.80% Equal Error Rate (EER) which showed substantial improvement over the best EER in the literature, 17.45%. Our proposed method surpassed state-of-the-arts by 6% on GPDS-Synthetic, achieving 6.81 %. On MCYT, EER of 3.98% was obtained which is comparable to the best previously reported results.", "paperid": 3101813758, "normalizedname_level1": "artificial intelligence"}
{"index": 517, "text": "The use of multiple atlases is common in medical image segmentation. This typically requires deformable registration of the atlases (or the average atlas) to the new image, which is computationally expensive and susceptible to entrapment in local optima. We propose to instead consider the probability of all possible transformations and compute the expected label value (ELV), thereby not relying merely on the transformation resulting from the registration. Moreover, we do so without actually performing deformable registration, thus avoiding the associated computational costs. We evaluate our ELV computation approach by applying it to liver segmentation on a dataset of computed tomography (CT) images.", "paperid": 2957571329, "normalizedname_level1": "artificial intelligence"}
{"index": 518, "text": "In computer vision, the analysis of image contents plays a significant role to perform intelligent tasks such as object recognition and image retrieval. These contents can be low-level visual features or colour information within an image. For content-based image retrieval (CBIR), several methods have been proposed that focus on either low-level visual features extraction or the colour information, and very few works can be seen that retrieve the images by fusing both types of contents. Consequently, this work addresses the problem of combining low-level visual features with colour information that helps to improve the retrieval accuracy of CBIR. The proposed strategy extracts the low-level visual salient features with features from accelerated segment test feature descriptor and quantises the salient keypoints into a feature vector. The colour information of the image is extracted and segmented with non-linear L*a*b* colour space and quantised into a feature vector. The similarity for both the feature vectors including visual and colour features is computed and combined together. The top-rank images are retrieved for the obtained feature vector using the distance metric. The experimental results on two standard benchmark datasets show the improved efficiency and 85% accuracy of the proposed strategy over state-of-the-art methods.", "paperid": 2926677551, "normalizedname_level1": "artificial intelligence"}
{"index": 519, "text": "A variety of indoor applications require both accurate location and orientation, such as indoor navigation and augmented reality. This paper presents 3DLoc, with which you can find your location and orientation by pointing your smartphone camera at 3D features e.g., doors and entrances. Different from the previous image-based localization of matching features via SIFT or SURF, 3DLoc takes advantage of rules for 3D features, including the ratio between height and width, the orientation and the distribution on the 2D floor map. The features around users are regarded as a unique 3D signature for the location. Based on prior researches on vanishing points and indoor geometric reasoning, we propose an algorithm to extract the signature from captured images and robustly decode the signature to accurate location and orientation. In terms of efficiency and user-friendliness, a series of optimizations are adopted through fusion of smartphone sensors and vision. We conduct experiments on different floors of a typical office building via the prototype built on Huawei P7 and iPhone 5S. Ninety percent of errors for location and orientation are within 25cm and two de4rees, respectively. With a 2D floor map provided, KB (-KiloByte-) level storage is required for the additional 3D information.", "paperid": 2783998087, "normalizedname_level1": "artificial intelligence"}
{"index": 520, "text": "We propose, WarpGAN, a fully automatic network that can generate caricatures given an input face photo. Besides transferring rich texture styles, WarpGAN learns to automatically predict a set of control points that can warp the photo into a caricature, while preserving identity. We introduce an identity-preserving adversarial loss that aids the discriminator to distinguish between different subjects. Moreover, WarpGAN allows customization of the generated caricatures by controlling the exaggeration extent and the visual styles. Experimental results on a public domain dataset, WebCaricature, show that WarpGAN is capable of generating caricatures that not only preserve the identities but also outputs a diverse set of caricatures for each input photo. Five caricature experts suggest that caricatures generated by WarpGAN are visually similar to hand-drawn ones and only prominent facial features are exaggerated.", "paperid": 2966963399, "normalizedname_level1": "artificial intelligence"}
{"index": 521, "text": "Exploring potentially useful information from huge amount of textual data produced by microblogging services has attracted much attention in recent years. An important preprocessing step of microblog text mining is to convert natural language texts into proper numerical representations. Due to the short-length characteristics of microblog texts, using term frequency vectors to represent microblog texts will cause “sparse data” problem. Finding proper representations of microblog texts is a challenging issue. In this paper, we apply deep networks to map the high-dimensional representations of microblog texts to low-dimensional representations. To improve the result of dimensionality reduction, we take advantage of the semantic similarity derived from two types of microblog-specific information, namely the retweet relationship and hashtags. Two types of approaches, including modifying training data and modifying the training objective of deep networks, are proposed to make use of microblog-specific information. Experiment results show that the deep models perform better than traditional dimensionality reduction methods such as latent semantic analysis and latent Dirichlet allocation topic model, and the use of microblog-specific information can help to learn better representations.", "paperid": 2344041367, "normalizedname_level1": "artificial intelligence"}
{"index": 522, "text": "This paper presents two visual trackers from the different paradigms of learning and registration based tracking and evaluates their application in image based visual servoing. They can track object motion with four degrees of freedom (DoF) which, as we will show here, is sufficient for many fine manipulation tasks. One of these trackers is a newly developed learning based tracker that relies on learning discriminative correlation filters while the other is a refinement of a recent 8 DoF RANSAC based tracker adapted with a new appearance model for tracking 4 DoF motion. Both trackers are shown to provide superior performance to several state of the art trackers on an existing dataset for manipulation tasks. Further, a new dataset with challenging sequences for fine manipulation tasks captured from robot mounted eye-in-hand (EIH) cameras is also presented. These sequences have a variety of challenges encountered during real tasks including jittery camera movement, motion blur, drastic scale changes and partial occlusions. Quantitative and qualitative results on these sequences are used to show that these two trackers are robust to failures while providing high precision that makes them suitable for such fine manipulation tasks.", "paperid": 2592096661, "normalizedname_level1": "artificial intelligence"}
{"index": 523, "text": "It is a research hotspot in the intersection of stomatology and computer science that three-dimensional (3D) virtual tooth orthodontics, and plays an important role in the fields of orthodontic treatment and teaching. The 3D reconstruction of tooth is the basis of the virtual tooth orthodontic system, through which the geometric information of the tooth could be obtained freely. Firstly, the typical methods of acquiring tooth data were analyzed. Secondly, the present 3D reconstruction methods of tooth were compared of the ideas, advantages and disadvantages, and they were classified into six kinds based on point cloud, CT image, twodimensional contour slicing and so on. Lastly, the development of virtual orthodontic system is briefly analyzed. This paper's work is of theoretical significance and guidance for the research of 3D reconstruction of tooth.", "paperid": 2904492344, "normalizedname_level1": "artificial intelligence"}
{"index": 524, "text": "Due to the explosive increase in online videos, near-duplicate video retrieval (NDVR) has attracted much researcher attention. NDVR has very wide applications, such as copyright protection, online video monitoring, and automatic video tagging. Local features serve as elementary building blocks in many NDVR algorithms, and most of them exploit the local volume information using a bag of features (BOF) representation. However, such representation ignores potentially valuable information about the global distribution of interest points. Moreover, the discriminative power of the local descriptors is significantly reduced by the quantizer in BOF. Our motivation is that if we use the global features to classify the same or similar keyframes into the same class, it will be very useful in improving the performance of NDVR. In this paper, we present an improved radon transform (IR) feature which captures the detailed global geometrical distribution of interest points. It is calculated by using the 2D discrete Radon transform, and then applying a principal component analysis. Such IR feature is not only invariant to the geometry transformations but also robust to the noises. In addition, we propose a fusion strategy to combine the BOF representation with the global IR feature for further improving the recognition accuracy. Convincing experimental results on several publicly available datasets demonstrate that our proposed approach outperforms the state-of-the-art approaches in NDVR.", "paperid": 2903570154, "normalizedname_level1": "artificial intelligence"}
{"index": 525, "text": "The covariance/coherence matrices are the most common way of representing polarimetric information in the polarimetric synthetic aperture radar (PolSAR) data and have been extensively used in PolSAR classification. Since PolSAR covariance and coherence matrices are Hermitian positive-definite, they form a nonlinear manifold, rather than Euclidean space. Though the geodesic distance measures defined on a manifold are suitable for describing similarities of PolSAR matrix data, the nonlinearity of the manifold often makes the involved optimization problems awkward. To address this problem, we propose to embed the manifold-based PolSAR data into a high (infinite)-dimensional reproducing kernel Hilbert space by Stein kernel and log-Euclidean kernel. Besides, we introduce the composite kernel into the sparse representation classification in order to exploit the spatial context information of PolSAR data. The proposed method is assessed using different PolSAR datasets. Experimental results demonstrate the superior performance compared with the methods without the use of contextual information.", "paperid": 2791225170, "normalizedname_level1": "artificial intelligence"}
{"index": 526, "text": "Advanced persistent threats (APT) have increased in recent times as a result of the rise in interest by nation-states and sophisticated corporations to obtain high profile information. Typically, APT attacks are more challenging to detect since they leverage zero-day attacks and common benign tools. Furthermore, these attack campaigns are often prolonged to evade detection. We leverage an approach that uses a provenance graph to obtain execution traces of host nodes in order to detect anomalous behavior. By using the provenance graph, we extract features that are then used to train an online adaptive metric learning. Online metric learning is a deep learning method that learns a function to minimize the separation between similar classes and maximizes the separation between dis-similar instances. We compare our approach with baseline models and we show our method outperforms the baseline models by increasing detection accuracy on average by 11.3 % and increases True positive rate (TPR) on average by 18.3 %.", "paperid": 3048000332, "normalizedname_level1": "artificial intelligence"}
{"index": 527, "text": "Medical image segmentation plays an important role in digital medical research, therapy planning, and computer aided diagnosis. However, the existence of noise and low contrast make automatic liver segmentation remains an open challenge. In this work we focus on a novel variational semi-automatic liver segmentation method. First, we used the signed distance functions (SDF) representing pattern shapes to build statistical shape model. Then global Gaussian fitting energy and enforced local feature fitting energy were established to guide the PCA-based topological transformation. We used the unconstrained shape coefficients and geometric transformation parameters to make the proposed method robust in a wide variety of pathological cases. Experiments on two public available datasets demonstrated that the proposed liver segmentation method achieves competitive results to that of the state-of-the-art.", "paperid": 2701226783, "normalizedname_level1": "artificial intelligence"}
{"index": 528, "text": "It is relatively difficult for handicapped users, especially those without both hands, to input characters through a keyboard [1][2]. Moving a pointer with a foot and using a screen keyboard enable the handicapped to input characters; however, minute movement is required to handle it. In this paper, we propose a simple key input method using a device with a few switch buttons. ON/OFF, such as pressing a button, swinging the arm, kicking with the leg, or moving the chin up and down is very easy input and can also be used for inputting keys with these simple devices. Thus, we can use them for inputting characters using our method.", "paperid": 2783988007, "normalizedname_level1": "artificial intelligence"}
{"index": 529, "text": "In this paper, authors based on data of questionnaire to discuss, according to discussion results to suggest appearance/function to robotics and its support system for aged people. This research uses people's familiar view, and targets to make robotics help/assist people rather than let people feel disturb. The basic data for our research is collected by questionnaire. The questionnaire is constructed by several items that include people's background data and the trend of using electronic equipment. These items help construct different clusters and the robot's image that aged people imaged. In this paper, people's different needs and situations are discussed. Data analysis and data mining are applied. From the research results, aged people's opinions, their ideal robot/robotics' image become clear, furthermore, the possibility appearance/function of robot/robotics and its support system are given sharp. This paper is a self-criticism research to developed robot and robotic system, hoping find a new way on this researching area and developing a better assistant robot for aged people.", "paperid": 2798335630, "normalizedname_level1": "artificial intelligence"}
{"index": 530, "text": "Recently, deep learning algorithms, especially fully convolutional network based methods, have become very popular in the field of remote sensing. However, these methods are implemented and evaluated through various datasets and deep learning frameworks. There has not been a package that covers these methods in a unified manner. In this study, we introduce a computer vision package termed Geoseg that focuses on building segmentation and outline extraction. Geoseg implements nine state-of-the-art models as well as utility scripts needed to conduct model training, logging, evaluation, and visualization. The implementation of Geoseg emphasizes unification, simplicity, and flexibility. The performance and computational efficiency of all implemented methods are evaluated by a comparison experiment using a unified, high-quality aerial image dataset.", "paperid": 2984899327, "normalizedname_level1": "artificial intelligence"}
{"index": 531, "text": "Image segmentation is one of crucial stages of video processing used for detection of pedestrians in infrared (IR) vision. The paper presents a study of passive (typically far IR) technologies for IR vision and an analysis of the state-of-the-art in the extraction of information from IR images. A deep testing of segmentation methods was performed for IR images with a specially prepared benchmark of 162 IR video frames with pedestrians. The initial tests included two segmentation methods: the single threshold and the Otsu method. The obtained results are promising as the effectiveness reaches ca. 82% for both techniques.", "paperid": 2881882319, "normalizedname_level1": "artificial intelligence"}
{"index": 532, "text": "Snoring is often associated with serious health risks such as obstructive sleep apnea and heart disease and may require targeted surgical interventions. In this regard, research into automatically and unobtrusively analysing the site of blockages that cause snore sounds is growing in popularity. Herein, we investigate the use of low level image texture features in classification of four specific types of snore sounds. Specifically, we explore histogram of local binary patterns (LBP) in dense grid of rectangular regions and histogram of oriented gradients (HOG) extracted from colour spectrograms for snore sound characterisation. Support vector machines with homogeneous mapping are used in the classification stage of the proposed method. Various experimental works are carried out with both LBP and HOG descriptors on the INTERSPEECH ComParE 2017 snoring sub-challenge dataset. Results presented indicate that LBP descriptors are better than the HOG descriptors in snore type detection and fusion of the LBP and HOG descriptors produces stronger results than either individual descriptor. Further, when compared to the challenge baseline and state-of-the-art deep spectrum features, our approach achieved relative percentage increases in unweighted average recall of 23.1% and 8.3% respectively.", "paperid": 2899050939, "normalizedname_level1": "artificial intelligence"}
{"index": 533, "text": "The EMG signals are being used in electronic systems with biofeedback control for tracking and classifying of hand motion. These systems present a challenge in identifying the movement due to the variation of the EMG signals between subjects, therefore different pattern recognition techniques have been implemented to overcome this challenge. In response to the previous problem, the present study compares the performance of both K — means and SVM methods to identify five individual movements of the hand. Therefore two techniques of classification were implemented, the first one consist of classifying the movements individually. while the second classifies all five movements through technic based on decision trees. Also this paper analyses the influence of the signal normalization over the performance of the classification. In general, SVM classifier performed better against K — means in the two tests with the error percentage below 9%.", "paperid": 2555457973, "normalizedname_level1": "artificial intelligence"}
{"index": 534, "text": "We present a novel means of describing local image appearances using binary strings. Binary descriptors have drawn increasing interest in recent years due to their speed and low memory footprint. A known shortcoming of these representations is their inferior performance compared to larger, histogram based descriptors such as the SIFT. Our goal is to close this performance gap while maintaining the benefits attributed to binary representations. To this end we propose the Learned Arrangements of Three Patch Codes descriptors, or LATCH. Our key observation is that existing binary descriptors are at an increased risk from noise and local appearance variations. This, as they compare the values of pixel pairs: changes to either of the pixels can easily lead to changes in descriptor values and compromise their performance. In order to provide more robustness, we instead propose a novel means of comparing pixel patches. This ostensibly small change, requires a substantial redesign of the descriptors themselves and how they are produced. Our resulting LATCH representation is rigorously compared to state-of-the-art binary descriptors and shown to provide far better performance for similar computation and space requirements.", "paperid": 1549945066, "normalizedname_level1": "artificial intelligence"}
{"index": 535, "text": "Given the potential X-ray radiation risk to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. The current main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction, but they need to access original raw data whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, the deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation and lesion detection.", "paperid": 3106320098, "normalizedname_level1": "artificial intelligence"}
{"index": 536, "text": "This paper presents a SSD (Single Shot multibox Detector) based aircraft detection method for airport video surveillance. The original SSD is not fast and accurate enough to meet the requirements of such real-time applications as airport surveillance. We introduce ResNet50 into SSD by using ResNet50 instead of the feature selection step in SSD framework. The proposed method and the original SSD are evaluated and compared based on a self-made aircraft database, which includes various cases as rainy, hazy weather, small targets, etc. Compared with original SSD, the proposed method is much faster, and the average accuracy is increased by 3%. Additional experiments based on public Pascal VOC database also indicate that the proposed method is better than the original SSD.", "paperid": 3015454476, "normalizedname_level1": "artificial intelligence"}
{"index": 537, "text": "Applied Academics is both a trend within pioneering educational institutions as well as a demand from the current generations of students at all levels. The first semesters of an engineering curricula focus on developing a solid theoretical basis in Mathematics, Physics and Programming before becoming immersed in practical projects. Therefore, first-year engineering students usually struggle to visualize the practical applications of their studies. Advancing towards an educational model based on competencies, the following workshop was an effort to increase engineering students’ engagement and to launch their development at a first stage. This interactive workshop was designed and implemented in an introductory engineering course where students were able to understand how a Star Wars BB8 commercial prototype droid is built and how it works. This droid worked as a great example of a well-known robot that integrates the different disciplines of the engineering programs involved in the workshop: Mechanical, Industrial, Automotive, Electrical, and Mechatronics. More than 600 freshmen took this workshop, which resulted in satisfactory outcomes. Results suggest that this kind of activity will prevent the abandonment of engineering studies. Students were really engaged in the workshop and showed curiosity and interest in understanding what was inside the famous robot and how it worked, given its innovative design. The students enjoyed the experience and realized the main differences between the engineering disciplines involved according to their application in this practical example. This workshop also helped them to reaffirm their decision on an Engineering Major and to motivate them to become skilled to be able to create this kind of technology.", "paperid": 2947969111, "normalizedname_level1": "artificial intelligence"}
{"index": 538, "text": "Many model-based Visual Odometry (VO) algorithms have been proposed in the past decade, often restricted to the type of camera optics, or the underlying motion manifold observed. We envision robots to be able to learn and perform these tasks, in a minimally supervised setting, as they gain more experience. To this end, we propose a fully trainable solution to visual ego-motion estimation for varied camera optics. We propose a visual ego-motion learning architecture that maps observed optical flow vectors to an ego-motion density estimate via a Mixture Density Network (MDN). By modeling the architecture as a Conditional Variational Autoencoder (C-VAE), our model is able to provide introspective reasoning and prediction for ego-motion induced scene-flow. Additionally, our proposed model is especially amenable to bootstrapped ego-motion learning in robots where the supervision in ego-motion estimation for a particular camera sensor can be obtained from standard navigation-based sensor fusion strategies (GPS/INS and wheel-odometry fusion). Through experiments, we show the utility of our proposed approach in enabling the concept of self-supervised learning for visual ego-motion estimation in autonomous robots.", "paperid": 2963461686, "normalizedname_level1": "artificial intelligence"}
{"index": 539, "text": "Article describes the development of a software complex that allows the processing of synchronous recordings of surface electrocardiograms and intracardiac electrograms. The developed software and algorithmic complex allows visual assessment of signals, automated recording analysis, determination of characteristic signal points and their joint parameters, including intervalograms of various sections, their temporal characteristics and the construction of a classification model on their basis.", "paperid": 3012255719, "normalizedname_level1": "artificial intelligence"}
{"index": 540, "text": "Facial expression recognition is an important computer vision problem with various applications. In this study, we investigate the effectiveness of features derived from facial landmarks in facial expression recognition. Distances between two combinations of facial landmarks constitute a distance vector. Features we use are the changes in the distance vectors extracted from expressive and neutral states of the face. The obtained feature vector contains elements that are relatively useless in expression recognition. By applying forward sequential feature selection, a subset of the most effective elements is formed. The chosen features are classified using a multi-class support vector machine. The performance of the proposed method is measured using Extended Cohn-Kanade dataset with seven expressions (anger, contempt, disgust, fear, happy, sad and surprised) and resulted in 89.9% mean class recognition accuracy.", "paperid": 2429725500, "normalizedname_level1": "artificial intelligence"}
{"index": 541, "text": "There are many vehicle navigation systems in existence. They provide directions following routes based on speed, traffic, major or minor roads and places of interest. Although guidance systems are getting increasingly more sophisticated, to our knowledge none of them can provide a recommendation based on subjective preferences. This contribution studies classification algorithms that can provide this very feature. Given all possible paths between geographical locations, the proposed method classifies the available paths, making possible the choice of a trajectory with subjective characteristics.", "paperid": 3098241797, "normalizedname_level1": "artificial intelligence"}
{"index": 542, "text": "Image denoising is an important step in the field of image processing. Presence of noise can lead to various obstacles in the way of proper analysis of images to extract information from it like misinterpretation of data, loss in the usability of the image etc. Denoised images are used in various applications such as in medical diagnosis, ultrasound imaging, satellite imaging, pattern recognition etc. Different image denoising techniques are already in existence that uses different filters to remove noise. Fuzzy logic is a soft computing technique that allows for approximations and partial truths. The benefit of using fuzzy logic for denoising purpose is to increase the tractability, robustness and effectiveness of the existing traditional denoising methods. This paper presents a novel fuzzy based method for removal of speckle noise, which mostly affects ultrasound and SAR images.", "paperid": 2798439192, "normalizedname_level1": "artificial intelligence"}
{"index": 543, "text": "In view of the incremental dimensionality reduction problem of existing non-linear dimensionality reduction methods, a novel algorithm, based on locality constrained dictionary learning (LCDL), is proposed in this study. During the dictionary learning process, the neighbourhood size of some potential landmarks on a non-linear manifold is constrained to maintain the intrinsic local geometric feature of the datasets. Meanwhile, to improve the dictionary's discrimination ability, a structured dictionary is learnt by LCDL, whose sub-dictionaries are class-specific. Then sparse coding and its reconstruction errors are used for classification. The experimental results of dimensionality reduction prove that, compared with the existing methods, the proposed method can solve the out of sample extension and large-scale datasets problems efficiently. In addition, the experimental results of face, gender, and object category classification demonstrate that the authors' algorithm outperforms some competing dictionary learning methods.", "paperid": 2508240147, "normalizedname_level1": "artificial intelligence"}
{"index": 544, "text": "Recent work proposes new algorithms for feature selection based on a Bayesian hierarchical model that places priors on both the identity of all features, and the identity-conditioned feature-label distribution. Given training data, Bayesian inference can be used to predict the feature identities. While algorithms developed in prior work rely on certain independence assumptions, in this work we present a new algorithm, with low computational complexity, designed for a family of Bayesian models that each assume different block covariance structures. We show the new algorithm, and the previous algorithm assuming independent features, have robust performance across the family of models under synthetic data, and provide results from real colon cancer microarray data.", "paperid": 2709089753, "normalizedname_level1": "artificial intelligence"}
{"index": 545, "text": "Human activity recognition is an active research area in the computer science because it is widely used in the fields of the security monitoring, health assessment, human machine interaction and other human related content searching. In this paper, a computer vision model based on the deep learning algorithm is proposed, which can recognize the human physical activity based on the skeleton data of the human body from the sensor of Microsoft Kinect. This model uses the human skeletons data from the CAD-60 dataset to recognize the human physical activity without using any prior knowledge. It can reduce the works on the stage of data preprocessing and feature extraction. It can also improve the generalization performance and robustness of the model, and give a better understanding of the human physical activity. Different tricks which can improve the performance of the neural networks, such as some regularization methods and other activation functions are tested. Finally, a convolutional neural network is used for the feature extraction, and a multilayer perceptron is used as the following classifier. The model can recognize twelve types of activities and the accuracy rate is 81.8%. It demonstrates that it is very effective to use the convolutional neural network to supervised learning and this model applies to human physical activity recognition.", "paperid": 2476501661, "normalizedname_level1": "artificial intelligence"}
{"index": 546, "text": "Realistic human model has a wide range of requirements in 3D content creation. A model with high-quality texture map can display human body surface details in low facets which could be toughly represented by geometric mesh. Image-based texture mapping suffers from discontinuities due to geometry inaccuracy, camera pose drifts, and illumination changes. In this paper, we propose a keyframe-based texture map generation method to obtain more desired texture mapping results. Our method firstly acquire the keyframes by performing a spatio-temporal sampling strategy, rather than just sampling keyframes according to time interval. Then, we apply an efficient patch-based optimization to the keyframes to make the texture data in different views alinged with each other. Finally, we generate a texture atlas from the aligned texture and the simplified mesh. Experimental results demonstrate that our method can get realistic human models with low facets and competitive details within short minutes.", "paperid": 2946672461, "normalizedname_level1": "artificial intelligence"}
{"index": 547, "text": "Coding in social sciences is a process that involves the categorisation of qualitative or quantitative data in order to facilitate further analysis. Coding is usually a manual process that involves a lot of effort and time to produce codes with high validity and interrater reliability. Although automated methods for quantitative data analysis are largely used in social sciences, there are only a few attempts at automatically or semi-automatically coding the data collected in qualitative studies. To address this problem, in this work we propose an approach for automated coding of social behaviours and environments based on verbatim transcriptions of everyday conversations. To evaluate the approach, we analysed the transcripts from three datasets containing recordings of everyday conversations from: (1) young healthy adults (German transcriptions), (2) elderly healthy adults (German transcriptions), and (3) young healthy adults (English transcriptions). The results show that it is possible to automatically code the social behaviours and environments based on verbatim transcripts of the recorded conversations. This could reduce the time and effort researchers need to assign accurate codes to transcribed conversations.", "paperid": 2964256656, "normalizedname_level1": "artificial intelligence"}
{"index": 548, "text": "The contemporary adoption of Cyber-Physical Systems and improvements in robotic applications in industrial scenarios demands for horizontal integration mechanisms with already existing automation equipment, controlled by PLCs. This paper aims to shorten the gap between the automation and robotics domain, by proposing an Interprocess Communication method to establish interoperability between robotic systems and automation equipment in a reliable and straightforward manner. In particular, this paper introduces a novel approach for linking ROS and IEC 61131–3 by way of shared memory interfaces, enabling and promoting their interactions. Moreover, this paper addresses the applied synchronization mechanism for handling concurrent accesses to the shared memory location, explores data type mapping between ROS and IEC 61131–3, and identifies some practical industrial applications.", "paperid": 2893315649, "normalizedname_level1": "artificial intelligence"}
{"index": 549, "text": "The quality of image captured by smartphone camera is one of the most important factors influencing consumers’ choice of mobile phones. Since the objective evaluation methods specifically designed for the quality assessment of smartphone camera image are relatively rare, it is meaningful to design an effective model for this challenge. In this paper, we propose a carefully-designed Convolutional Neural Network (CNN) with residual block to predict image quality without a reference image. Within the network structure, the feature extraction and regression are integrated into one optimization process. The input of network is selected using the saliency map generated by SalGAN. Experimental results show that the model proposed can obtain a better performance for quality assessment of smartphone images on all four aspects viz. color, exposure, noise and texture than the traditional noreference image quality assessment (NR IQA) methods.", "paperid": 3034750850, "normalizedname_level1": "artificial intelligence"}
{"index": 550, "text": "In the case of small signal-to-noise ratio, the performance of traditional speech endpoint detection algorithm drops rapidly, sometimes it even cannot work normally. Based on wavelet transform and multi-resolution analysis, this paper analyzes and studies the wavelet coefficient variance algorithm and sub band average energy algorithm in speech endpoint detection. It optimizes these two algorithms by using the frequency-domain difference between speech and noise. The scheme combines the advantages of PCA and RBF neural network to complement each other, and proposes a speech endpoint detection approach WaRBF. The simulation results show that WaRBF algorithm improves the accuracy of speech endpoint detection, which has better antinoise and robustness. The detection results are more stable and reliable, which shows better practical application value.", "paperid": 3109728701, "normalizedname_level1": "artificial intelligence"}
{"index": 551, "text": "We investigated the psychological effects of UHDTV viewing. UHDTV not only increased the spatio-temporal resolution but also expanded the color gamut and dynamic range. Although the introduction of a wide color gamut (WCG) and high dynamic range (HDR) made it possible to express more faithful images, it is unknown how it contributes to the viewer's benefit. We verified the image impression enhancement effect due to the introduction of HDR and WCG through a subjective evaluation test. The results indicated that the two factors work additively for impression enhancement and HDR appears to be the dominant factor.", "paperid": 2885186683, "normalizedname_level1": "artificial intelligence"}
{"index": 552, "text": "Machine Learning (ML) allows us to craft a system’s behavior based on examples instead of being explicitly programmed or designed. In our research, we show that ML can be applied to mimic some conventional radar signal processing algorithms and remedy known underperformance of these algorithms. In particular, by taking the CA-CFAR as use case, we train a feedforward artificial neural network (ANN) on a dataset that contains the inputs and outputs of the CFAR sliding window. In addition, the same ANN is fed with desired input/output combinations where the CA-CFAR is known to give undesired results, for example in case of large clutter discontinuities. Through computer simulations we show that the still computationally friendly ML-based CFAR outperforms the classic CA-CFAR algorithm, which leads the way for further research on applying ML to detection in the radar processing chain.", "paperid": 2994862554, "normalizedname_level1": "artificial intelligence"}
{"index": 553, "text": "Deep learning approaches to generic (non-semantic) segmentation have so far been indirect and relied on edge detection. This is in contrast to semantic segmentation, where DNNs are applied directly. We propose an alternative approach called Deep Generic Segmentation (DGS) and try to follow the path used for semantic segmentation. Our main contribution is a new method for learning a pixel-wise representation that reflects segment relatedness. This representation is combined with a CRF to yield the segmentation algorithm. We show that we are able to learn meaningful representations that improve segmentation quality and that the representations themselves achieve state-of-the-art segment similarity scores. The segmentation results are competitive and promising.", "paperid": 3034512663, "normalizedname_level1": "artificial intelligence"}
{"index": 554, "text": "As technology evolves, its consumers gain considerable advantages to bring prosperity for all humankind. It is so in medical environment. Even though there always has been standards in hospital or other related medical sites, it is possible for people with the help of technology to study about simple theory of pathology and find another mechanism to meet those standards, i.e., to create new method for healing illnesses. For consumer use, creating the new method can be of a significant benefit for the case of maximizing usability and minimizing cost, and inventing Electrocardiography method is a good example. It is considered difficult for laymen if they want to assess their own heart condition following the rule defined, as so the cost they should afford. Motivated by this problem, this paper investigates detrended fluctuation analysis (DFA) to measure heart electric signal. DFA scales the autocorrelation of nonstationary signal, which can be found in human heartbeat in the form of Electrocardiogram wave. DFA was implemented in a developed Electrocardiogram (ECG) device, created with a low-cost Raspberry pi 2 as the core and some other sensors. As for home environment, smoking habit was considered as the performance metric. The experimental result reveals a cardiac disparity between smoker and nonsmoker, showing a new way of determining smoking habit effect using DFA.", "paperid": 2736951511, "normalizedname_level1": "artificial intelligence"}
{"index": 555, "text": "In this paper, we consider the position control problem of nonholonomic mobile robots, i.e., the regulation of mobile robots to a desired position specified by the image position of a feature point onboard the mobile robot, by using visual feedback information from an overhead fixed camera. Many vision-based control approaches have been proposed for motion control of nonholonomic mobile robots, however, they usually assume that exact or approximate knowledge of full/partial intrinsic and/or extrinsic parameters of the camera can be available, and large or even very small errors in these parameters can deteriorate the control performance, reduce the control accuracy, and even affect the system stability. Hence, it is interesting and highly desirable to develop vision-based controllers without depending on the camera parameters, from both control performance and controller implementation perspectives. With this in mind, we propose novel image-based position control schemes for nonholonomic mobile robots completely without knowing the camera parameters. In the proposed schemes, neither accurate nor approximate knowledge about the camera intrinsic and extrinsic parameters is required, and the totally unknown camera can be mounted on the ceiling with an arbitrary pose, which can make the controller implementation very simple and flexible. Experimental results are provided to show the feasibility and effectiveness of the proposed schemes.", "paperid": 2783421923, "normalizedname_level1": "artificial intelligence"}
{"index": 556, "text": "Most of the work contributed in RDH using image as host has been carried out using grey images. The multiphase nature of color images make them more convenient to high payload applications. This paper presents an interpolation based RDH scheme for color images. The data has been embedded using various Bit Substitution Patterns (BSP) to obtain application specific parameters like PSNR and payload. A particular BSP decides the number of bits embedded and the perceptual performance obtained. The scheme besides being reversible is capable of detecting any tamper caused due to various signal processing and geometric attacks. This has been ensured by embedding a fragile watermark interleaved with the embedding data and scattered throughout various phases of color image.", "paperid": 3091054338, "normalizedname_level1": "artificial intelligence"}
{"index": 557, "text": "A problem of surgery is an infection of patient. In this paper, we presented a method to control medical image in an operating room by using only a hand. The proposed methods consisted of five steps, namely 1) data acquisition from Leap Motion sensor 2) hand visualization with color mapping 3) close and open hand classification 4) hand gesture recognition and 5) command interpretation. The system has total ten commands divided to six commands on program screen, namely, waiting, selection, searching next image in left and right direction, and increasing and decreasing brightness, and four commands on button; namely, zoom in, zoom out, clockwise rotation, and counterclockwise rotation. An accuracy rate average is 95.83%. The results show that the proposed method performs effectively. The advantage of the proposed method is one hand can control the image.", "paperid": 2919341498, "normalizedname_level1": "artificial intelligence"}
{"index": 558, "text": "Multivariate time series data are littered with missing values across many domains. Often the patterns of missing data points reflect conscious decisions by the data collector, and thus may contain correlations that can be used to more accurately classify the data. Previous works propose machine learning models that are capable of detecting these correlations in order to achieve highly accurate results. We review the literature and identify a rich variety of strategies along the machine learning pipeline for handling missing values, including forward imputation, appending additional missing indicators, and others. We also study different deep learning methods for handling time series data, namely GRU and LSTM cells. We then design an experimental study for investigating the relative effectiveness of different state-of-the-art methods for handling missing values to more fully comprehend the intricacies of missing data. For the experimental evaluation study, we utilize MIMIC-III, a publicly available critical care dataset composed of Electronic Health Records (EHR) for over 58,000 hospital admissions collected at Beth Israel Deaconess Medical Center from 2001 to 2012. In particular, our experimental study compares variety of missingness-aware machine learning methods for predicting patient mortality, a benchmark task for this database. We validate in general that extracting information from missing values indeed improves predictive accuracy, and we observe that GRU and LSTM cells perform comparably with the forward imputation method further impacting the resulting accuracy for both models.", "paperid": 3097873146, "normalizedname_level1": "artificial intelligence"}
{"index": 559, "text": "What's the most important thing for people to know about the full-body exoskeleton from Sarcos Robotics, which can turn an assembly-line worker into a superhero? \"We're taking orders,\" says Sarcos CEO Ben Wolff.", "paperid": 2908508679, "normalizedname_level1": "artificial intelligence"}
{"index": 560, "text": "Orthonormality constraints, in which parameter sets are constrained to be perpendicular to each other and of unit length, are important for many estimation, detection, and classification tasks. Such constraints are not appropriate in all practical scenarios, however. In this paper, we describe simple adaptive algorithms that adjust a matrix so that its rows are close to orthonormality after adaptation, as specified by user-selectable bounds on pairwise inner products and squared vector lengths. The algorithms have rapid convergence. Applications to independent component analysis and deep learning system training show the benefits of the approach.", "paperid": 3013824111, "normalizedname_level1": "artificial intelligence"}
{"index": 561, "text": "This paper presents an interactive image segmentation approach in which we formulate segmentation as a probabilistic estimation problem based on the prior user intention. Instead of directly measuring the relationship between pixels and labels, we first estimate the distances between pixel pairs and label pairs using a probabilistic framework. Then, binary probabilities with label pairs are naturally converted to unary probabilities with labels. The higher order relationship helps improve the robustness to user inputs. To improve segmentation accuracy, a likelihood learning framework is proposed to fuse the region and the boundary information of the image by imposing a smoothing constraint on the unary potentials. Furthermore, we establish an equivalence relationship between likelihood learning and likelihood diffusion and propose an iterative diffusion-based optimization strategy to maintain computational efficiency. Experiments on the Berkeley segmentation data set and Microsoft GrabCut database demonstrate that the proposed method can obtain better performance than the state-of-the-art methods.", "paperid": 2890143105, "normalizedname_level1": "artificial intelligence"}
{"index": 562, "text": "Lip features and contour detection is an important aspect of computer vision, having many application domains. This research conveys various aspects of the related topics and presents an elliptical mathematical approach followed by image processing methods such as morphological operation to extract lip contour. Lip contour detection starts from mouth area which is segmented from face image area and then it fits an elliptical contour on lip area by evaluating image features such as edges and corner points thus identify lips and its properties. Later morphological approach is introduced to eliminate and compensate contour points. This application is suitable to run on embedded electronic devices specially considered Advanced RISC Machine, well known as ARM. Face detection itself a complicated task thus core application perform several image processing steps to define face area properly. In the domain of Human Computer Interface System human skin color is determined by using color map. This is also a necessary component for face area detection. This research conveys necessary information regarding this issue such as color space and classification which have pivotal role to define Lip Contour from a detected face area.", "paperid": 2589268251, "normalizedname_level1": "artificial intelligence"}
{"index": 563, "text": "This study aimed the analysis of the positional and geometric accuracy of objects in orthomosaics obtained through different unmanned aerial vehicle (UAV) data processing software covering an area located within Universidade do Vale do Rio dos Sinos – UNISINOS in Sao Leopoldo, RS. A total of nine ground control points (GCP) and twenty checkpoints were surveyed in order register and classify the processed orthomosaics according to the cartographic accuracy standard – Padrao de Exatidao Cartografica (PEC). Four software was employed to process the UAV data: Pix4D mapper, Agisoft PhotoScan, Menci APS and Bentley Context Capture. The results obtained from each software were compared and identified the smallest distortions when processing with and without ground control points. The flight was executed at a height of 90m with 60% sidelap and 80% overlap using an ST800 UAV equipped with a Sony NEX-7 small format non-metric camera with 24 megapixels resolution. The software GeoPEC was used to classify the orthomosaics according to PEC. For data processed with ground control points all orthomosaics were classified “Class A” in 1/500 scale, however, only Menci APS did not present a trend line via t-student test. On the other hand, Menci APS presented the worst results without the ground control points. In processing with GCP, all orthomosaics obtained optimum results with an approximated error of 2,5 m2, about 0,03% of the area.", "paperid": 2901486271, "normalizedname_level1": "artificial intelligence"}
{"index": 564, "text": "Abstractive summarization is a important task in natural language processing field. In previous work, the sequence-to-sequence based models are widely used for abstractive summarization task. However, most of the current abstractive summarization models still suffer from two problems. One is that it is difficult for these models to learn an accurate source contextual representation from the redundancy and noisy source text at each decoding step. Another is the information loss problem, which is ignored in previous work. The inability of these models to effectively exploit previously generated words led to this problem. In order to address these two problems, in this paper, we propose a novel keyword and generated word attention model. Specifically, the proposed model first employs the hidden state of decoder to capture relevant keywords and previously generated words contextual at each time step. The model then utilizes obtained keywords and generated words contextual to create keywords-aware and generated words-aware source contextual, respectively. The keywords contextual contributes to learn an accurate source contextual representation, and the generated words contextual can alleviate the information loss problem. Experimental results on a popular Chinese social media dataset demonstrate that the proposed model outperforms baselines and achieves the state-of-the-art performance.", "paperid": 2978236860, "normalizedname_level1": "artificial intelligence"}
{"index": 565, "text": "Brain-computer interface (BCI) has emerged as a promising technology to explore physiological activities and functional states of the human brain. This paper presents an Electroencephalogram (EEG) signals processing system, which consists of the compression process, reconstruction process and the classification process. The EEG signals is reconstructed with 5.318±0.08 root mean square error and 0.881±0.06 structural similarity index in short CPU time. The experiments on the two classes motor imagery EEG signals reaches up to 92% accuracy with the proposed feature extraction method. Compared with prior works, the proposed work is able to achieve better performance with high fidelity and low computational complexity.", "paperid": 2954790909, "normalizedname_level1": "artificial intelligence"}
{"index": 566, "text": "The Electrocardiogram (ECG) is a representation of the electrical events of the cardiac cycle. Each event has a distinctive waveform and the study of wave form can lead to greater insight into a patient's cardiac pathophysiology. ECG is the biological signal and it represents the electrical activity of the heart. The signal is recorded by placing the electrode on the human body surface and the recorded signal includes several types of noises such as power line interference, electrode contact noise, muscle contractions, baseline wander, electro surgical noise, instrumental noise muscle contractions and composite noise. The proposed work is to develop a system which is used for removing or filtering the artifacts present in the given input signal. The input signal is an synthetic signal which consists of power line interference noise and composite noise as artifacts. The Complementary Ensemble Empirical Mode Decomposition (CEEMD) and Kalman Smoother methods are used for developing de-noising system for effective filtering of noise which is generated during the ECG signal recording. The combination of two methods are proposed in this work for better filtering performance. Pre-processing of the given input signal is performed by using band pass filter and decomposition of signal by wavelet transformation methods. The developed system performance can be evaluated by using SNR (Signal to Noise Ratio) and RMSE (Root Mean Square Error) and the results are tabulated. The results shows better performance and strongly recommend that, combined system performance gives better result compare to individual system results.", "paperid": 2809064230, "normalizedname_level1": "artificial intelligence"}
{"index": 567, "text": "In this paper will be presented an original thermal dataset designed for training machine learning models for person detection. The dataset contains 7412 thermal images of humans captured in various scenarios while walking, running, or sneaking. The recordings are captured in the LWIR segment of the electromagnetic (EM) in various weather condition-clear, fog and rain at different distances from the camera, different body positions (upright, hunched) and movement speeds (regular walking, running). In addition to the standard lens of the camera, we used a telephoto lens for recording, and we compared the image quality at different weather conditions and at different distances in both cases to set parameters that provide the level of detail that is enough to detect the person.", "paperid": 2960262294, "normalizedname_level1": "artificial intelligence"}
{"index": 568, "text": "Currently, mean subtraction, median removal, singular value decomposition (SVD), Principal component analysis (PCA) and Independent component analysis (ICA) areverypopular approaches to extract the buried target information in presence of clutter and background noise for GPR applications. Clutter and background reduction and detection of low dielectric constant buried object with variable soil conditionsare the challenging tasks in GPR. But available techniques are not able to extract the non-metallic target information, due to low dielectric constant. Therefore, this paper proposes a neural network and statistical mean to standard deviation threshold based approach for subtracting background and for enhancing the detection of low dielectric constant buried object. ANN approach is based on the collection of large amount background data with soil moisture variation. These background data statistically analysed to compute the mean to standard deviation thresholding. After that, motion filter estimate the actual pixel intensity of PVC pipe in linear manner. The results show that the enhanced target detection and background subtraction are achieved directly from proposed trained neural network.", "paperid": 2548155295, "normalizedname_level1": "artificial intelligence"}
{"index": 569, "text": "Computational techniques for binding-affinity prediction and molecular docking have long been considered in terms of their utility for drug discovery. With the advent of deep learning, new supervised learning techniques have emerged which can utilize the wealth of experimental binding data already available. Here we demonstrate the ability of a fully convolutional neural network to classify molecules from their Simplified Molecular-Input Line-Entry System (SMILES) strings for binding affinity to HIV proteins. The network is evaluated on two tasks to distinguish a set of molecules which are experimentally verified to bind and inhibit HIV-1 Protease and HIV-1 Reverse Transcriptase from a random sample of drug-like molecules. We report 98% and 93% classification accuracy on the respective tasks using a computationally efficient model which outperforms traditional machine learning baselines. Our model is suitable for virtually screening a large set of drug-like molecules for binding to HIV or other protein targets.", "paperid": 2888120835, "normalizedname_level1": "artificial intelligence"}
{"index": 570, "text": "In view of the phenomenon that the factors of occluded target and it's changed background lead to failure in the process of tracking, a MTF (Mean-shift by TWH and FBerror) tracking algorithm is proposed. Firstly, TargetWeighted Histogram (TWH) is introduced to describe target in Mean-shift tracking framework, i.e., using local-background of target to weaken inner-background features of all-region in order to make target features prominent in tracking process, secondly, FB-error restriction is introduced, the predicted results of target current position and the calculated results of mean-shift vector are combined together to estimate the final target location of time t by using weighted function about FBerror. The experimental results show that the proposed tracking algorithm has great breakthrough on tracking accuracy.", "paperid": 2765885335, "normalizedname_level1": "artificial intelligence"}
{"index": 571, "text": "We consider the problem of point target detection on images and focal plane arrays (FPA). Imaging sensors are becoming ubiquitous tools in several applications, such as biomedical systems, autonomous surveillance systems, target tracking systems, and robotics. In these applications, matched filter and template matching are commonly used detection strategies, however, these approaches are unable to provide sub-pixel accuracy and avenues for adaptive pixel-width selection for computationally efficient image processing. In this paper, we derive the maximum likelihood estimator (MLE) of target location on images. The proposed MLE is optimal under the assumption that the FPA contains a point target that has its signal intensity spread in multiple image pixels in the form of a Gaussian point spread function (PSF) with known standard deviation. Further, we derive the Cramer-Rao lower bound (CRLB) of the estimate and present the hypothesis test for target acceptance, resulting in a novel maximum likelihood detector (MLD) for images. Simulation results are provided to validate the performance of the proposed MLE and MLD; it is shown that the MLE is efficient in very low SNR values, starting at −15 dB, and the MLD achieves probability of detection of near unity with zero false alarms starting at 0 dB.", "paperid": 2744044201, "normalizedname_level1": "artificial intelligence"}
{"index": 572, "text": "Protein-protein interactions (PPIs) play a central role in many biological processes. Although a large amount of human PPI data has been generated by high-throughput experimental techniques, they are very limited compared to the estimated 130 000 protein interactions in humans. Hence, automatic methods for human PPI-detection are highly desired. This work proposes a novel framework, i.e., Low-rank approximation-kernel Extreme Learning Machine (LELM), for detecting human PPI from a protein's primary sequences automatically. It has three main steps: 1) mapping each protein sequence into a matrix built on all kinds of adjacent amino acids; 2) applying the low-rank approximation model to the obtained matrix to solve its lowest rank representation, which reflects its true subspace structures; and 3) utilizing a powerful kernel extreme learning machine to predict the probability for PPI based on this lowest rank representation. Experimental results on a large-scale human PPI dataset demonstrate that the proposed LELM has significant advantages in accuracy and efficiency over the state-of-art approaches. Hence, this work establishes a new and effective way for the automatic detection of PPI.", "paperid": 2315196278, "normalizedname_level1": "artificial intelligence"}
{"index": 573, "text": "Tongue diagnosis is an important way of monitoring human health status in traditional Chinese medicine. As a key step of achieving automatic tongue diagnosis, the major challenges for robust and accurate segmentation and identification of tongue body in tongue images lay in the large variations of tongue appearance, e.g., tongue texture and tongue coating, caused by different diseases for different patients. To cope with these challenges, we propose a novel end-to-end model for multi-task learning of tongue localization and segmentation, named TongueNet, in which pixel-level prior information is utilized for supervised training of deep convolutional neural network. Firstly, we introduce a feature pyramid network based on the designed context-aware residual blocks for the extraction of multi-scale tongue features. Then, the region of interests (ROIs) of tongue candidates are located in advance from the extracted feature maps. Finally, finer localization and segmentation of tongue body are conducted based on the feature maps of ROIs. Quantitative and qualitative comparisons on real-world datasets show that the proposed TongueNet achieves state-of-the-art performance for the segmentation of tongue body in terms of both robustness and accuracy.", "paperid": 2979519420, "normalizedname_level1": "artificial intelligence"}
{"index": 574, "text": "Current vehicle detection and tracking in imagery characterised by large ground coverage, low resolution and low frame rate data, such as Wide Area Motion Imagery (WAMI), does not reliably sustain vehicle tracks through start-stop movement profiles. This limits the continuity of tracks and its usefulness in higher level analysis such as pattern of behaviour or activity analysis. We develop and implement a two-step registration method to create well-registered images which are used to generate a novel low-noise representation of the static background context which is fed into our Context Convolutional Neural Network (C-CNN) detector. This network is unique as the C-CCN learns changing features in the scene and thus produces reliable, sustained vehicle detection independent of motion. A quantitative evaluation against WAMI imagery is presented for a Region of Interest (ROI) of the WPAFB 2009 annotated dataset [1]. We apply a Kalman filter tracker with WAMI-specific adaptions to the single frame C-CNN detections, and evaluate the results with respect to the tracking ground truth. We show improved detection and sustained tracking in WAMI using static background contextual information and reliably detect all vehicles that move, including vehicles that become stationary for short periods of time as they move through stop-start manoeuvres.", "paperid": 2998492669, "normalizedname_level1": "artificial intelligence"}
{"index": 575, "text": "A hands-free operation is a solution for people who require a hand to do an action but both right and left hands are busy carrying something. There are many techniques, and most of them use sensors to check a command from humans such as voice and movement. A kick gesture is one technique that people can kick into the air to invoke an operation of a target device such as a kick-activation liftgate of a car. In this paper, we use a microwave sensor to detect the movement of a human's foot and employ machine learning techniques to analyses the sensor data. It has found that the Logistic Regression technique provides the best accuracy, and the model can be simply programmed in an embedded system.", "paperid": 2886665809, "normalizedname_level1": "artificial intelligence"}
{"index": 576, "text": "We demonstrate “Blurry (Sticky) Finger” in which one uses the unfocused blurred finger, sense of proprioception, to aim, point and directly select a distant object in the real world with both eyes open. We showcase two demo applications. The first illustrates the accuracy and usability of the proposed method with the target objects lying at a fixed depth on a monitor. The second is an AR based object inquiry system, a more practical application. The user aims and encircles a real 3D object whose image is captured with the eye-to-camera offset compensated. The image is searched through the data base with the result augmented on an OST display.", "paperid": 2585567194, "normalizedname_level1": "artificial intelligence"}
{"index": 577, "text": "Steady state visual evoked potential (SSVEP)-based brain computer interface (BCI) systems has attracted paramount amount of attention due to their higher signal to noise ratio and high information transfer rate. In this paper a SSVEP-BCI-based on a convolutional neural network (CNN) classifier is presented. The visual stimulation is provided to the participants with with LED matrices blinking at 6, 7, 8 and 9 Hz respectively. A wireless EEG amplifier, the g.Nautilus was used to acquire the electroencephalogram (EEG) signals from eight parietal and occipital electrodes. The features were derived using Fast Fourier Transformation (FFT) of the 8 channels using a 2s moving window in the form of 8 × 8 grey scale images. The proposed CNN architecture has provided superior average accuracy of 94.7% for four subjects, compared to the average accuracy of 87.4% of the state of the art canonical correlation analysis (CCA) performance.", "paperid": 2910115612, "normalizedname_level1": "artificial intelligence"}
{"index": 578, "text": "The concept of affordances facilitates the encoding of relations between actions and effects in an environment centered around the agent. Such an interpretation has important impacts on several cognitive capabilities and manifestations of intelligence, such as prediction and planning. In this paper, a new framework based on denoising Auto-encoders (dA) is proposed which allows an agent to explore its environment and actively learn the affordances of objects and tools by observing the consequences of acting on them. The dA serves as a unified framework to fuse multi-modal data and retrieve an entire missing modality or a feature within a modality given information about other modalities. This work has two major contributions. First, since training the dA is done in continuous space, there will be no need to discretize the dataset and higher accuracies in inference can be achieved with respect to approaches in which data discretization is required (e.g. Bayesian networks). Second, by fixing the structure of the dA, knowledge can be added incrementally making the architecture particularly useful in online learning scenarios. Evaluation scores of real and simulated robotic experiments show improvements over previous approaches while the new model can be applied in a wider range of domains.", "paperid": 2409171770, "normalizedname_level1": "artificial intelligence"}
{"index": 579, "text": "Popular local feature extraction schemes, such as SIFT, are robust when changes in illumination, translation and scale occur, and play an important role in visual content retrieval. However, these solutions are not very robust to 3D object rotations and camera viewpoint changes. In such scenarios, the emerging and richer lenslet light field image representation can provide additional information such as multiple perspectives and depth data. This paper introduces a new lenslet light field imaging dataset and studies the retrieval performance when popular 2D visual descriptors are applied. The new dataset consists of 25 Lisbon landmarks captured with a lenslet camera from different perspectives. Moreover, this paper proposes and assesses straightforward extensions of visual 2D descriptor matching for lenslet light field retrieval. The experimental results show that gains up to 14% can be obtained with a light field representation when compared to a 2D imaging conventional representation.", "paperid": 2748071844, "normalizedname_level1": "artificial intelligence"}
{"index": 580, "text": "The number of road accidents in the world is increasing every year due to driver negligence. Unintended lane departure and rear end collisions are some of the main reason behind road accidents in the freeway. This project presents an efficient, robust Lane Departure Warning System (LDWS) and a frontal collision warning system, which work on different illumination conditions. The system uses a monoscopic dashboard camera fitted in the windshield of the car. The algorithm makes a birds-eye view (top-view) of the road using Inverse Perspective Mapping. Hough transform is applied on this IPM to find the candidate points of lanes, and finally RANSAC Bezier spline fitting is done to find out the actual lanes. To detect vehicles, Hough transform is applied on the image to check for horizontal lines made by the vehicle. Multithreding is done to improve the performance of the system and to utilize maximum system resources.", "paperid": 2798758914, "normalizedname_level1": "artificial intelligence"}
{"index": 581, "text": "In home-based elderly care service, how to precisely recognize activities is a key issue in the design and implementation of context-aware service for elderly people. Existing research works reveal that those approaches ignore the characteristics of activity diversity, and similarity and the features of activities of elderly people at home, so recognition accuracy of those approaches are not high enough for real-life applications. Thus, in this paper, we first study the types of activities in home-based elderly care service. Then, we propose a two-stage elderly home activity recognition method based on random forest and activity similarity. The method uses improved random forest to obtain a preliminary result in the first stage. Then, the correlation between activity, location, and time is employed to judge the rationality of the result. The similarity of activities is further used to correct the results in the second stage. We set up a series of experiments to evaluate the effectiveness and efficiency of our approach.", "paperid": 2911378276, "normalizedname_level1": "artificial intelligence"}
{"index": 582, "text": "We present two techniques to improve landmark localization in images from partially annotated datasets. Our primary goal is to leverage the common situation where precise landmark locations are only provided for a small data subset, but where class labels for classification or regression tasks related to the landmarks are more abundantly available. First, we propose the framework of sequential multitasking and explore it here through an architecture for landmark localization where training with class labels acts as an auxiliary signal to guide the landmark localization on unlabeled data. A key aspect of our approach is that errors can be backpropagated through a complete landmark localization model. Second, we propose and explore an unsupervised learning technique for landmark localization based on having a model predict equivariant landmarks with respect to transformations applied to the image. We show that these techniques, improve landmark prediction considerably and can learn effective detectors even when only a small fraction of the dataset has landmark labels. We present results on two toy datasets and four real datasets, with hands and faces, and report new state-of-the-art on two datasets in the wild, e.g. with only 5% of labeled images we outperform previous state-of-the-art trained on the AFLW dataset.", "paperid": 2962887041, "normalizedname_level1": "artificial intelligence"}
{"index": 583, "text": "Convolutional Neural Networks (CNNs) have revolutionized performances in several machine learning tasks such as image classification, object tracking, and keyword spotting. However, given that they contain a large number of parameters, their direct applicability into low resource tasks is not straightforward. In this work, we experiment with an application of CNN models to gastrointestinal landmark classification with only a few thousands of training samples through transfer learning. As in a standard transfer learning approach, we train CNNs on a large external corpus, followed by representation extraction for the medical images. Finally, a classifier is trained on these CNN representations. However, given that several variants of CNNs exist, the choice of CNN is not obvious. To address this, we develop a novel metric that can be used to predict test performances, given CNN representations on the training set. Not only we demonstrate the superiority of the CNN based transfer learning approach against an assembly of knowledge driven features, but the proposed metric also carries an 87% correlation with the test set performances as obtained using various CNN representations.", "paperid": 2925126079, "normalizedname_level1": "artificial intelligence"}
{"index": 584, "text": "In Diabetic Retinopathy, red lesions are consisting of micro-aneurysms and haemorrhages. The paper deals with the proper detection of micro-aneurysms and haemorrhages which are found in fundus images using an automated computer vision. Morphological operations are performed to extract out all the possible candidates that have similar pixel intensity as that of the red lesions. To reject the blood vessels effectively, Gabor filter is used in this paper. Discriminatory features are extracted and fed to train SVM classifier for the proper classification of the micro-aneurysms and haemorrhages. The algorithm developed is tested on 168 fundus images taken from DIARETDBI AND MESSIDOR databases. It achieved an overall accuracy of 93% and 91.8% in classifying the micro-aneurysms and haemorrhage respectively. Proposed work is efficient and the result are encouraging to use in real time applications.", "paperid": 2966612105, "normalizedname_level1": "artificial intelligence"}
{"index": 585, "text": "In this paper, an image-based humanoid robot pose recognition system is designed and implemented to recognize humanoid robot pose and some objects position in the field. Robot Operating System (ROS) is used to establish the software development framework for the image recognition system. The image recognition system includes feature matching, region of interest (ROI) capture, background subtraction, edge detection, and object segmentation. Then the Inverse Perspective Mapping (IPM) is used to determine the location of humanoid robot and some objects. Experimental results show that the proposed robot pose recognition system can simultaneously recognize and track both of obstacle, humanoid robot and its pose.", "paperid": 2979649235, "normalizedname_level1": "artificial intelligence"}
{"index": 586, "text": "The most common activity people do in daily life is walking. Gait is an action that involves the whole body. The use of two legs in a harmonious manner is called walking for the purpose of moving from one position to another. Gait is person-specific and can be used to distinguish like fingerprints, palmprints, and iris. In this study, it is aimed to determine the gender of the persons with the gait parameters obtained by the wearable sensors. For this purpose, a total of 50 gait that consist of 23 female and 27 male gait were examined and 321 gait parameters were calculated for one gait. Gender classification success rates are calculated via three different classification algorithms as Support Vector Machine (SVM), k-nearest neighbors (k-NN) and Decision Tree classification algorithms and validated by leave one out cross validation (LOOCV) method. The most successful result in gender classification on generated walking data is provided by decision tree method.", "paperid": 2831336136, "normalizedname_level1": "artificial intelligence"}
{"index": 587, "text": "Objective:  in this paper we propose a system to detect a subject's sympathetic reaction, which is related to unexpected or challenging events during a car drive.  Methods:  we use the Electrocardiogram (ECG) signal and the Skin Potential Response (SPR) signal, which has several advantages with respect to other Electrodermal (EDA) signals. We record one SPR signal for each hand, and use an algorithm that, selecting the smoother signal, is able to remove motion artifacts. We extract statistical features from the ECG and SPR signals in order to classify signal segments and identify the presence or absence of emotional events via a Supervised Learning Algorithm. The experiments were carried out in a company which specializes in driving simulator equipment, using a motorized platform and a driving simulator. Different subjects were tested with this setup, with different challenging events happening on predetermined locations on the track.  Results:  we obtain an Accuracy as high as 79.10% for signal blocks and as high as 91.27% for events.  Conclusion:  results demonstrate the good performance of the presented system in detecting sympathetic reactions, and the effectiveness of the motion artifact removal procedure.  Significance:  our work demonstrates the possibility to classify the emotional state of the driver, using the ECG and EDA signals and a slightly invasive setup. In particular, the proposed use of SPR and of the motion artifact removal procedure are crucial for the effectiveness of the system.", "paperid": 3017298754, "normalizedname_level1": "artificial intelligence"}
{"index": 588, "text": "The paper discusses an evaluation of visual odometry accuracy with respect to available lighting. Very extensive test data (along one country-side road in New Zealand) have been recorded at day and at night. Used sensors are stereo cameras and an inertial measurement unit (IMU). The paper discusses odometry results for the cases when using visual odometry only (i.e. based on the stereo camera data), or additionally also using the IMU. The paper also presents 3D point cloud reconstruction under low-light conditions by using visual odometry and IMU combined.", "paperid": 2912671664, "normalizedname_level1": "artificial intelligence"}
{"index": 589, "text": "We introduce our machine-learning method to remove the fog and haze in image. Our model is based on CycleGAN, an ingenious image-to-image translation model, which can be applied to de-hazing task. The datasets that we used for training and testing are creatd according to the atmospheric scattering model. With the change of the adversarial loss from cross-entropy loss to hinge loss, and the change of the reconstruction loss from MAE loss to perceptual loss, we improve the performance measure of SSIM value from 0.828 to 0.841 on the NYU dataset. With the Middlebury stereo datasets, we achieve an SSIM value of 0.811, which is significantly better than the baseline CycleGAN model.", "paperid": 3010705637, "normalizedname_level1": "artificial intelligence"}
{"index": 590, "text": "Proactive recommender systems are intelligent systems that provide (i.e. push) pertinent recommendations to the users based on their current tasks or interests. The recommendation algorithms employed in these systems usually compute similarity score or build up a model offline using training data for producing online recommendations. As training in proactive recommender systems when the availability of items changes often and rapidly is very time consuming, existing recommendation algorithms are less effective in such application domains. To address this problem, we present a proactive recommender system that generates real time recommendations using the proposed Extreme Learning Machine based Imputation-Boosted Collaborative Filtering (ELMICF) algorithm. Extreme Learning Machine (ELM) is a machine learning algorithm which considerably reduces the time required for training the system due to the very fast learning process of ELM. It has been used in literature for numerous classification, generalization and prediction applications. ELMICF first employs an imputation technique to handle data sparseness in the input rating matrix and then uses the ELM as a classifier to predict the novel ratings. A prototype of the system has been implemented for restaurant recommendations to show the feasibility of our proposed approach. The performance of ELMICF is compared with MLP/ANN and naive based classification techniques using normalized Discounted Cumulative Gain (nDCG), average precision, training time and mean prediction time metrics.", "paperid": 2547110907, "normalizedname_level1": "artificial intelligence"}
{"index": 591, "text": "Extracting discriminative and robust features from video sequences is the first and most critical step in human action recognition. In this paper, instead of using handcrafted features, we automatically learn spatio-temporal motion features for action recognition. This is achieved via an evolutionary method, i.e., genetic programming (GP), which evolves the motion feature descriptor on a population of primitive 3D operators (e.g., 3D-Gabor and wavelet). In this way, the scale and shift invariant features can be effectively extracted from both color and optical flow sequences. We intend to learn data adaptive descriptors for different datasets with multiple layers, which makes fully use of the knowledge to mimic the physical structure of the human visual cortex for action recognition and simultaneously reduce the GP searching space to effectively accelerate the convergence of optimal solutions. In our evolutionary architecture, the average cross-validation classification error, which is calculated by an support-vector-machine classifier on the training set, is adopted as the evaluation criterion for the GP fitness function. After the entire evolution procedure finishes, the best-so-far solution selected by GP is regarded as the (near-)optimal action descriptor obtained. The GP-evolving feature extraction method is evaluated on four popular action datasets, namely KTH, HMDB51, UCF YouTube, and Hollywood2. Experimental results show that our method significantly outperforms other types of features, either hand-designed or machine-learned.", "paperid": 2084793887, "normalizedname_level1": "artificial intelligence"}
{"index": 592, "text": "Research in similarity measures for time series clustering and classification has produced promising results since the emerge of data mining and artificial intelligence. However, the significant scale and phase variances of sequences within the same cluster, constitute challenges calling for the quest of correct partitions. In this research, we are trying to address the problem using the Shape-Distance Ratio (SDR) similarity measure (SIM). SDR adopts curve fitting and it applies a segmented method for short-length sequences which are divided into several segments using sliding windows. The optimal similar segments between curve and objective sequence are found in the windows. This measure was used to process raw data. We have compared the SDR similarity measure with other state-of-the-art distance measures. The experimental results clearly show that SDR offers an effective SIM for time series data. Then a hand-craft is presented to evaluate the performance of our proposed method in clustering task.", "paperid": 2973666316, "normalizedname_level1": "artificial intelligence"}
{"index": 593, "text": "Fractional anisotropy derived from the single-tensor model (FADTI) in diffusion MRI (dMRI) is the most widely used metric to characterize white matter (WM) micro-architecture in disease, despite known limitations in regions with extensive fiber crossing. Due to time constraints and interest in collecting multiple clinical samples and MRI scan types, complex HARDI acquisition protocols are rare in clinical population dMRI studies. Under such constraints, the tensor distribution function (TDF) can still be used to reconstruct multiple underlying fibers by representing the diffusion profile as a probabilistic mixture of tensors. Here we set out to better profile WM deficits in Alzheimer's disease (AD) by comparing the standard FADTI and TDF-derived FA (FATDF) in (1) WM network connectivity and voxel-based analyses of diagnostic differences, and (2) for picking up associations with clinical cognitive ratings and hippocampal volume. Ultimately, the TDF approach may be more sensitive and accurate than corresponding DTI-derived measures.", "paperid": 2438558636, "normalizedname_level1": "artificial intelligence"}
{"index": 594, "text": "A compressed video quality assessment dataset based on the just noticeable difference (JND) model, called MCL-JCV, is recently constructed and released. In this work, we explain its design objectives, selected video content and subject test procedures. Then, we conduct statistical analysis on collected JND data. We compute the difference between every two adjacent JND points and propose an outlier detection algorithm to remove unreliable data. We also show that each JND difference group can be well approximated by a normal distribution so that we can adopt the Gaussian mixture model (GMM) to characterize the distribution of multiple JND points. Finally, it is demonstrated by experimental results that the proposed JND analysis performed in the difference domain, called the D-method, achieves a lower BIC (Bayesian information criteria) value than the previously proposed G-method.", "paperid": 2511458122, "normalizedname_level1": "artificial intelligence"}
{"index": 595, "text": "The Machine Type Communication Devices (MTCDs) are usually based on Internet Protocol (IP), which can cause billions of connected objects to be part of the Internet. The enormous amount of data coming from these devices are quite heterogeneous in nature, which can lead to security issues, such as injection attacks, ballot stuffing, and bad mouthing. Consequently, this work considers machine learning trust evaluation as an effective and accurate option for solving the issues associate with security threats. In this paper, a comparative analysis is carried out with five different machine learning approaches: Naive Bayes (NB), Decision Tree (DT), Linear and Radial Support Vector Machine (SVM), KNearest Neighbor (KNN), and Random Forest (RF). As a critical element of the research, the recommendations consider different Machine-to-Machine (M2M) communication nodes with regard to their ability to identify malicious and honest information. To validate the performances of these models, two trust computation measures were used: Receiver Operating Characteristics (ROCs), Precision and Recall. The malicious data was formulated in Matlab. A scenario was created where 50% of the information were modified to be malicious. The malicious nodes were varied in the ranges of 10%, 20%, 30%, 40%, and the results were carefully analyzed.", "paperid": 2943985317, "normalizedname_level1": "artificial intelligence"}
{"index": 596, "text": "Human perception of surface stickiness is closely related to intermittent slip dynamics, or stiction. In this work, we develop a method for real-time closed-loop rendering of surface stiction on an electroadhesive surface haptic display, and test it on a custom-built tribometer. We perform a psychophysical study to determine the effectiveness of a single, user-adjustable parameter on perceived surface stickiness, and elucidate what aspect of friction shapes the percept.", "paperid": 2970357784, "normalizedname_level1": "artificial intelligence"}
{"index": 597, "text": "We present a self-supervision method for 3D hand pose estimation from depth maps. We begin with a neural network initialized with synthesized data and fine-tune it on real but unlabelled depth maps by minimizing a set of data-fitting terms. By approximating the hand surface with a set of spheres, we design a differentiable hand renderer to align estimates by comparing the rendered and input depth maps. In addition, we place a set of priors including a data-driven term to further regulate the estimate's kinematic feasibility. Our method makes highly accurate estimates comparable to current supervised methods which require large amounts of labelled training samples, thereby advancing state-of-the-art in unsupervised learning for hand pose estimation.", "paperid": 2963859396, "normalizedname_level1": "artificial intelligence"}
{"index": 598, "text": "We address the problem of 3-D reconstruction using neuromorphic cameras (also known as  event-driven  cameras), which are a new class of vision-inspired imaging devices. Neuromorphic cameras are becoming increasingly popular for solving image processing and computer vision problems as they have significantly lower data rates than conventional frame-based cameras. We develop a neuromorphic-camera-based Fringe Projection Profilometry (FPP) system. We use the Dynamic Vision Sensor (DVS) in the DAVIS346 neuromorphic camera for acquiring measurements. Neuromorphic FPP is faster than a single-line-scanning method. Also, unlike frame-based FPP, the efficacy of the proposed method is not limited by the background while acquiring measurements. The working principle of the DVS also allows one to efficiently handle shadows thereby preventing ambiguities during 2-D phase unwrapping.", "paperid": 3049757280, "normalizedname_level1": "artificial intelligence"}
{"index": 599, "text": "Optical coherence tomography (OCT), as a non-destructive and high-resolution fingerprint acquisition technology, is robust against poor skin conditions and resistant to spoof attacks. It measures fingertip information on and beneath skin as 3D volume data, containing the surface fingerprint, internal fingerprint and sweat glands. Various methods have been proposed to extract internal fingerprints, which ignore the inter-slice dependence and often require manually selected parameters. In this article, a modified U-Net that combines residual learning, bidirectional convolutional long short-term memory and hybrid dilated convolution (denoted as BCL-U Net) for OCT volume data segmentation and two fingerprint reconstruction approaches are proposed. To the best of our knowledge, it is the first time that simultaneous and automatic extraction is performed for surface fingerprint, internal fingerprint and sweat gland. The proposed BCL-U Net utilizes the spatial dependence in OCT volume data and deals with segmentation of objects with diverse sizes to achieve accurate extraction. Comparisons have been performed to demonstrate the advantages of the proposed method. A thorough evaluation of the recognition abilities of internal and surface fingerprints is conducted using a dataset significantly larger than previous studies. Four databases containing internal and surface fingerprints are generated from 1572 OCT volume data by the proposed method. The internal fingerprint matching experiment has achieved a lowest equal error rate (EER) of 0.95%. Mixed internal and surface fingerprint matching experiment is also performed and achieves an EER of 3.67%, verifying the consistency of the internal and surface fingerprints. The matching experiments for fingers under poor skin conditions show a 2.47% EER of internal fingerprints that is much lower than that of surface fingerprints, which proves the advantage of internal fingerprints and indicates the potential of the internal fingerprints to supplement or replace the surface fingerprints for some specific applications.", "paperid": 3049644255, "normalizedname_level1": "artificial intelligence"}
{"index": 600, "text": "Robotics is one of the many tools that is making a substantial difference as the world is experiencing the fourth industrial revolution. To ease control over this engineering marvel substantially, Reinforcement Learning (RL) has paved its way in recent years quite remarkably. RL enables robots to become self-aware towards carrying out a specific task followed by user operations. For decades of rigorous endeavor, this research field has gone through numerous groundbreaking developments and it will be the same for the coming days. Therefore, this paper steps in to enlighten the scientific community with a systemic review of the published research papers within the past decade. The bibliographic data that is extracted from the papers are analyzed using an automated tool named Vosviewer with respect to some parameters. Substantial excerpts from the most influential papers are highlighted in this work. Furthermore, this paper points out the global research practice in this field. The paper also generates some intriguing questions and answers them in regards to the research topic. After reading this paper, future researchers will have a firm idea in the RL-based robotics and will be able to incorporate in their own research.", "paperid": 3089760622, "normalizedname_level1": "artificial intelligence"}
{"index": 601, "text": "P300-speller is a communication system based on brain-computer interface (BCI) which allows users to input characters by focused attention. Support vector machine (SVM) ensemble has been successfully applied to classify in the P300-speller. However, large scale of training data was needed for the sub-classifiers to ensure the performance of classification. Subjects gradually got fatigue during the period of training data collection, which resulted in an obvious difference of EEG data from early to later and affected the performance of classification. In present study, we adopted a random selection strategy to construct the training set for SVM sub-classifiers in a BCI P300-speller with familiar face paradigm. Our results showed that the random selection strategy improved the classification accuracy of SVM ensemble in BCI P300-speller.", "paperid": 2521827144, "normalizedname_level1": "artificial intelligence"}
{"index": 602, "text": "Commercial unmanned aerial vehicles, or drones, are getting increasingly popular in the last few years. The fact that these drones are highly accessible to public may bring a range of security and technical issues to sensitive areas such as airfields and military bases. Consequently, drone detection and state identification are becoming very crucial and essential for governments and security agencies. This paper proposes a deep learning based approach for drone detection, type identification and state identification using a multi-channel 1-dimensional convolutional neural network. The deep learning model is trained utilizing a publicly published database for drone's radio frequency signals. The proposed model can be used to produce new features that can represent the whole dataset in a more compact form which enables the use of classical machine learning algorithms for classification.", "paperid": 3025996032, "normalizedname_level1": "artificial intelligence"}
{"index": 603, "text": "The rise of machine learning in image processing has created a gap between trainable data-driven and classical model- driven approaches: While learning-based models often show superior performance, classical ones are often more transparent. To reduce this gap, we introduce a generic wavelet shrinkage function for denoising which is adaptive to both the wavelet scales as well as the noise standard deviation. It is inferred from trained results of a tightly parametrised function which is inherited from nonlinear diffusion. Our proposed shrinkage function is smooth and compact while only using two parameters. In contrast to many existing shrinkage functions, it is able to enhance image structures by amplifying wavelet coefficients. Experiments show that it outperforms classical shrinkage functions by a significant margin.", "paperid": 3016150487, "normalizedname_level1": "artificial intelligence"}
{"index": 604, "text": "Inspired by how the human brain employs more neural pathways when increasing the focus on a subject, we introduce a novel twin cascaded attention model that outperforms a state-of-the-art image captioning model that was originally implemented using one channel of attention for the visual grounding task. Visual grounding ensures the existence of words in the caption sentence that are grounded into a particular region in the input image. After a deep learning model is trained on visual grounding task, the model employs the learned patterns regarding the visual grounding and the order of objects in the caption sentences, when generating captions. We report the results of our experiments in three image captioning tasks on the COCO dataset. The results are reported using standard image captioning metrics to show the improvements achieved by our model over the previous image captioning model. The results gathered from our experiments suggest that employing more parallel attention pathways in a deep neural network leads to higher performance. Our implementation of NTT is publicly available at: https://github.com/zanyarz/NeuralTwinsTalk.", "paperid": 3103619067, "normalizedname_level1": "artificial intelligence"}
{"index": 605, "text": "Comic panel extraction, i.e., decomposing a comic page image into panels, has become a fundamental technique for meeting many practical needs of mobile comic reading such as comic content adaptation and comic animating. Most of existing approaches are based on handcrafted low-level visual patterns and heuristics rules, thus having limited ability to deal with irregular comic panels. Only one existing method is based on deep learning and achieves better experimental results, but its architecture is redundant and its time efficiency is not good. To address these problems, we propose an end-to-end, two-stage quadrilateral regressing network architecture for comic panel detection, which inherits the architecture of Faster R-CNN. At the first stage, we propose a quadrilateral region proposal network for generating panel proposals, based on a newly proposed quadrilateral regression method. At the second stage, we classify the proposals and refine their shapes with the proposed quadrilateral regression method again. Extensive experimental results demonstrate that the proposed method significantly outperforms the existing comic panel detection methods on multiple datasets by F1-score and page accuracy.", "paperid": 2896482341, "normalizedname_level1": "artificial intelligence"}
{"index": 606, "text": "This paper presents development and evaluation of an intelligent algorithm for swarm mobile robots cooperation. This algorithm can be shared between collections of robots to cooperate in order to achieve search and rescue tasks. A binary dragonfly algorithm has been modified by considering two more behaviors; obstacle avoidance and communication constrains. The implemented algorithm has been tested to check its performance in reaching the best solution and to reach an optimal solution within relatively shorter time. The performance of the robotic dragonfly algorithm has been compared with other search and rescue algorithms and the obtained results demonstrate its features in cooperation to reach a single objective.", "paperid": 2905391203, "normalizedname_level1": "artificial intelligence"}
{"index": 607, "text": "Facial action unit (AU) intensity estimation plays an important role in affective computing and human-computer interaction. Recent works have introduced deep neural networks for AU intensity estimation, but they require a large amount of intensity annotations. AU annotation needs strong domain expertise and it is expensive to construct a large database to learn deep models. We propose a novel knowledge-based semi-supervised deep convolutional neural network for AU intensity estimation with extremely limited AU annotations. Only the intensity annotations of peak and valley frames in training sequences are needed. To provide additional supervision for model learning, we exploit naturally existing constraints on AUs, including relative appearance similarity, temporal intensity ordering, facial symmetry, and contrastive appearance difference. Experimental evaluations are performed on two public benchmark databases. With around 2% of intensity annotations in FERA 2015 and around 1% in DISFA for training, our method can achieve comparable or even better performance than the state-of-the-art methods which use 100% of intensity annotations in the training set.", "paperid": 2799151537, "normalizedname_level1": "artificial intelligence"}
{"index": 608, "text": "Power equipment is an important part of the power system and the focus of power system operation and maintenance. Infrared anomaly detection technology is an effective means to detect abnormalities of power equipment because of its safety, simplicity and intuitiveness. Through training the YOLOv3 network by infrared images collected in the field, this work can achieve real-time detection of power equipment and fault points on the Jetson Nano, and determines which areas of the power equipment are abnormal. The trained YOLOv3 model is tested. The mAP value of the model is 34.63%, the recall rate is 21%, and the temperature anomaly area and power equipment could be marked. The running time on the Jetson Nano was 0.7-0.9 s (the recognition time was less than 1s), which satisfies the requirements for power equipment testing.", "paperid": 3016128373, "normalizedname_level1": "artificial intelligence"}
{"index": 609, "text": "Nowadays, there is a high demand for product detection in the background of shelves. Considering the structure of the shelf and the placement of products, this paper proposes a shelf product detection method based on RFBNet and combined with traditional image processing methods. The method firstly uses the edge detection and other image preprocessing methods to separate the shelves layer by layer and then detects the image of each shelf layer by the deep neural network. Finally, eliminate incorrect results based on the placement characteristics of the product, thereby improving the detection accuracy. We established a synthetic training dataset by a randomly pasting method, and the images in test dataset are captured in real scenes. The results show that this method can obtain better detection accuracy on test images with 0.95 for mAP and 0.89 for F1-Score.", "paperid": 3000792678, "normalizedname_level1": "artificial intelligence"}
{"index": 610, "text": "Indoor object classification is a key element for indoor navigation assistance systems. Indoor objects knowledge helps Visually Impaired People (VIP) in their indoor navigation and facilitates their daily life. This paper proposes a new classification system used especially for indoor object recognition based on Deep Convolutional Neural Network (DCNN) model which can be implemented on mobile embedded platforms. Experimental results obtained using natural images (with natural illumination) from the MCIndoor 20000 dataset show that the proposed approach achieves almost100% accuracy for indoor object classification.", "paperid": 2969296069, "normalizedname_level1": "artificial intelligence"}
{"index": 611, "text": "Existing dominant approaches for cross-modal video-text retrieval task are to learn ajoint embedding space to measure the cross-modal similarity. However, these methods rarely explore long-range dependency inside video frames or textual words leading to insufficient textual and visual details. In this paper, we propose a stacked convolutional deep encoding network for video-text retrieval task, which considers to simultaneously encode long-range and short-range dependency in the videos and texts. Specifically, a multi-scale dilated convolutional (MSDC) block within our approach is able to encode short-range temporal cues between video frames or text words by adopting different scales of kernel size and dilation size of convolutional layer. A stacked structure is designed to expand the receptive fields by repeatedly adopting the MSD- C block, which further captures the long-range relations between these cues. Moreover, to obtain more robust textual representations, we fully utilize the powerful language model named Transformer in two stages: pretraining phrase and fine-tuning phrase. Extensive experiments on two different benchmark datasets (MSR-VTT, MSVD) show that our proposed method outperforms other state-of-the-art approaches.", "paperid": 3035043893, "normalizedname_level1": "artificial intelligence"}
{"index": 612, "text": "A real-time multipoint-based object detector - EMPDet is proposed in this paper to improve the processing speed with reasonable sacrifice in accuracy. A lightweight neural network block is proposed and integrated into the compact hourglass networks to reduce the consumption in image feature extraction. The channel mechanism is used to enhance the performance of the convolutional neural network to screen shallow semantic information in high-resolution feature maps. Experiments results on the detection benchmark (Microsoft COCO) show that the proposed detector has superior performance compared to the current most popular YOLOv3 under reasonable overhead.", "paperid": 3081668718, "normalizedname_level1": "artificial intelligence"}
{"index": 613, "text": "Community participation and involvement plays a big role in disaster risk reduction. This paper made use of the feedback from public on how local communities can be better prepared in times of disaster. Main goal of this study is to automatically assign qualitative responses into its appropriate category in disaster management using bidirectional recurrent neural network. In building the BRNN model, data corpus was split into training set (85%) and testing set (15%), which achieved acceptable average accuracy rate of 81.67%, 81.17% precision, 81.67% recall and 80.81% f-measure. Output of the classifier showed that the top four priority needs of the respondents in DRR fall under the categories of education and training; communication and coordination; dissemination of information alerts and warnings/ early warning system; and role of local authority. The validated results generated is a useful feedback to concerned agencies, specifically in the Province of Albay in enhancing their existing disaster management plans. Future work may add trained data to achieve higher performance results. Using other hyperparameters in the configuration of neural networks may also be considered for better evaluation result of the classification model.", "paperid": 2916825593, "normalizedname_level1": "artificial intelligence"}
{"index": 614, "text": "Hidden Markov fields have been widely used in image processing thanks to their ability to characterize spatial information. In such models, the process of interest   $X$    is hidden and is to be estimated from an observable process    $Y$  . One common way to achieve the associated inference tasks is to define, on one hand, the prior distribution   $p(x)$   ; and on the other hand, the noise distribution   $p(y|x)$   . While it is commonly established that the prior distribution is given by a Markov random field, the noise distribution is usually given through a set of Gaussian densities; one per each label. Hence, observed pixels belonging to the same class are assumed to be generated by the same Gaussian density. Such assumption turns out, however, to be too restrictive in some situations. For instance, due to light conditions, pixels belonging to a same label may present quite different visual aspects. In this letter, we overcome this drawback by considering an auxiliary field   $U$   in accordance with the triplet Markov field formalism. Experimental results on simulated and real images demonstrate the interest of the proposed model with respect to the common hidden Markov fields.", "paperid": 2520029346, "normalizedname_level1": "artificial intelligence"}
{"index": 615, "text": "In many countries, bicycling has emerged as a viable alternative to motorized means of transport. Citizens rely on bicycles to commute to their workplaces, transport goods, and use them for sports and leisure activities. Available maps are, however, often scarce of information with relevance for cyclists. Besides the presence of tracks, their intersections, and approximations of their inclinations (through contour lines), little further annotations are available. In particular, the surface type of a track (e.g., asphalt, cobbled paving, or soil) is rarely provided, despite the fact that it determines how easily the track can be passed in diverse weather conditions. Cyclists will often only discover the exact track conditions by the time they pass it (or are unable to pass due to it being washed out or flooded by rain). In this work, we present SURF, a pervasive computing application which allows to detect a track's surface type using an opportunistic bicycle-centric sensing system. SURF relies on the processing of images (collected using a handlebar-mounted smartphone) by means of machine learning tools. We evaluate SURF using more than 67, 000 training images collected during actual bicycle rides, and show how the system can determine five major surface types of bikeways at an accuracy of 99.51%.", "paperid": 2950202048, "normalizedname_level1": "artificial intelligence"}
{"index": 616, "text": "Compared with conventional narrowband radar, ultra-wideband (UWB) radar has strong anti-interference performance, low-frequency, and wide-frequency characteristics, a good penetrating ability, a high-resolution range, and a good target-recognition ability. It is effective for the detection of weak signals such as breathing or motion of the human body. Therefore, a UWB radar is widely used in the field of human body target detection for earthquake and snow disasters. At present, through-wall human target detection technology using a UWB radar has two challenging problems. First, UWB radar data has a dynamic acquisition process, whereas existing detection technologies mostly employ static learning models, resulting in an inability to process and learn data features online. There is a need to address target recognition based on sensor-network data stream. Second, UWB radar faces the problem of unbalanced data classification in the identification of through-wall targets, i.e., target recognition under small-sample conditions. To address these issues, this paper proposes an adaptive incremental recursive least-squares regression parameter estimation method based on an adaptive variable sliding window, which performs Gaussian function fitting on the data streams and adapts to the mean square error and self-adaptation variable sliding window threshold comparison to adaptively block dynamic data streams. The tensor space theory is used to extract and fuse the multisensor data, and the tensor depth learning algorithm is used to improve the recognition accuracy of the target detection under small-sample conditions. To evaluate the feasibility of the proposed algorithm, we use three UWB radars to build a multistate recognition system for human targets. The data stream adaptive block effect, single and multisensor classification effects were tested under small-sample conditions. The experimental results indicate that the proposed algorithm not only accurately segmented the dynamic data streams but also effectively realized multisensor information fusion and improved the real-time target monitoring under small-sample conditions.", "paperid": 2888825851, "normalizedname_level1": "artificial intelligence"}
{"index": 617, "text": "Feasibility of applying compressive sensing (CS) to ultrasound radio-frequency (RF) data to produce elastography is investigated. The research also compares the performance of various CS frameworks associated with three common model bases (Fourier transform, discrete cosine transform (DCT), and wave atom (WA)) and two reconstruction algorithms (l 1  minimization and block sparse Bayesian learning (BSBL)) using the quality of B-mode images and elastograms from the RF data subsampled and reconstructed by each framework. Results suggest that CS reconstruction adopting BSBL algorithm with DCT model basis can yield the best results for all the measures tested, and the maximum data reduction rate for producing readily discernable elastograms is around 60%.", "paperid": 2754065964, "normalizedname_level1": "artificial intelligence"}
{"index": 618, "text": "Recurrent Neural Networks (RNNs) are currently state of art tools for processing and classifying data sequences. This work aims to exploit these capabilities in Long-Short Term Memory (LSTM) networks which are a powerful variant of RNNs for encoding the birds' trajectory data into state vectors. These vectors should encapsulate the contextual information about the immediate trajectory coordinates. Therefore, they can generate new trajectory points based on their state and the latest output. However, probabilistic behavior of birds, effects of environment and noisy nature of measurements pose challenges for training and testing of the LSTM network models. This study solely focuses on the effects of spatial context and their significance in subsequent outputs to achieve compact representation of the traversed trajectory. Therefore, trajectory coordinates of birds were used as input to LSTM networks to learn spatial path features encoded in hidden vectors of the network. In the end, t-SNE method is used to visualize the state vectors in lower dimensional space embeddings and It was observed that these vectors contained contextual information about the traversed path.", "paperid": 2751063202, "normalizedname_level1": "artificial intelligence"}
{"index": 619, "text": "This research aims to extract consequent problem events as a cause-effect concept pair series, from teen-drug addiction web-boards. The extracted consequent problem events benefit for a problem analysis in a solving system through a Causal Loop representation. The research has three problems; how to determine a causative/effect event concept based on a verb phrase expression with an overlap problem between causative-verb concept set and effect-verb concept set, how to determine cause-effect concept pair series from several verb phrases, and how to develop a Causal Loop representation from the extracted cause-effect concept pair series. Therefore, we apply an event rate to solve the overlap problem. We then propose using N-WordCo to determine the cause-effect concept pair series and also use a similarity score to develop the Causal Loop representation. The research results provide a high precision of the problem event extraction from the documents.", "paperid": 3005759475, "normalizedname_level1": "artificial intelligence"}
{"index": 620, "text": "The internet is teeming with an ocean worth of information and combing through all that in order to find what one wants can become a daunting task if one does not possess the right tools and techniques. This paper explores one such technique, exploiting the rapidly responsive Long-Short Term Memory Recurrent Neural Networks (LSTM-RNNs) by harnessing the machine learning capabilities of neural networks and eventually, provides contextual search results at the finger tips of the user of the system.", "paperid": 2920171826, "normalizedname_level1": "artificial intelligence"}
{"index": 621, "text": "Sparse coding is widely used in signal and image processing. Highly related to sparse coding method, independent component analysis (ICA) can be used to build a statistical model for image processing. However, in practice, when used in image processing, the effect or efficiency of different ICA algorithms are not well studied. To fill this gap, in this paper, the image denoising performance of four classical ICA algorithms, namely, two different implementations of basic Fast-ICA, natural gradient algorithm and optimized Fast-ICA are studied. Firstly, assumptions required by sparse coding method and ICA algorithms are briefly introduced. Secondly, feature extraction and image denoising experiments are conducted to compare the performance of different ICA algorithms. The experiment results show that all ICA algorithms mentioned above can be used to explore natural image feature and image denoising, but the results are not always similar. The optimized Fast-ICA algorithm outperforms the other algorithms.", "paperid": 2765431541, "normalizedname_level1": "artificial intelligence"}
{"index": 622, "text": "A heterogeneous information network (HIN) is used to model objects of different types and their relationships. Objects are often associated with properties such as labels. In many applications, such as curated knowledge bases for which object labels are manually given, only a small fraction of the objects are labeled. Studies have shown that transductive classification is an effective way to classify and to deduce labels of objects, and a number of transductive classifiers have been put forward to classify objects in an HIN. We study the performance of a few representative transductive classification algorithms on HINs. We identify two fundamental properties, namely, cohesiveness and connectedness, of an HIN that greatly influence the effectiveness of transductive classifiers. We define metrics that measure the two properties. Through experiments, we show that the two properties serve as very effective indicators that predict the accuracy of transductive classifiers. Based on cohesiveness and connectedness we derive (1) a black-box tester that evaluates whether transductive classifiers should be applied for a given classification task and (2) an active learning algorithm that identifies the objects in an HIN whose labels should be sought in order to improve classification accuracy.", "paperid": 2535373932, "normalizedname_level1": "artificial intelligence"}
{"index": 623, "text": "Retinal vessel segmentation takes a significant part in an automated diabetic retinopathy screening task. However, this can be a challenging job because of the low contrast retinal images and the presences of retinal pathologies. Hence, in this paper, we propose a novel matched filter based on the modified Chebyshev type I function for retinal blood vessels candidates detection. The proposed method is combined with the pre-processing and the post-processing phases to have a complete retinal vessel segmentation scheme. The retinal images from the DRIVE and STARE databases, which are equipped with the ground truths are used to evaluate our proposed method in the segmentation scheme. Using our method, the achieved average levels of sensitivity, specificity, and accuracy are 0.756, 0.973, and 0.954, for the DRIVE database, and 0.731, 0.972, and 0.953, for the STARE database, being better than other presented methods. The high results indicate that our method is reliable to be used in an automated detection tool for diabetic retinopathy.", "paperid": 2754170490, "normalizedname_level1": "artificial intelligence"}
{"index": 624, "text": "Machine learning is an inevitable outcome of the development of artificial intelligence research to a certain stage. It has become the most popular technology in the fields of computer vision and natural language processing. Learning techniques such as inductive logic programming, neural network-based connectionist learning technology, and statistical learning theory are constantly evolving. The shortcomings of various learning techniques in data representation and result processing have become a concern of many scholars. As one of the cutting-edge science and technology in the 21st century, artificial intelligence has a profound impact on education. This research is based on the artificial intelligence in Visualization Application for nearly 12 years. It has carried out visual analysis of research hotspots and frontiers. In addition, this study also discusses the research content through cluster analysis, discusses the influence of artificial intelligence on Chinese education field, and reflects on it.", "paperid": 2998959834, "normalizedname_level1": "artificial intelligence"}
{"index": 625, "text": "Convolutional Neural Networks (CNNs) have been widely applied in biomedical image classification, but the classification of upper gastrointestinal diseases, especially gastric cancer, has not been further studied. In this paper, we compare the difference between the medical image and the natural image. We have found that simply making the network structure deeper does not improve the performance of medical image classification model, and sometimes it will be worse. Inspired by the residual connection, we propose a shallow network model, which can converge quickly and achieve high accuracy. In an upper digestive tract classification dataset, we demonstrate the proposed model can achieve high accuracy.", "paperid": 2998666704, "normalizedname_level1": "artificial intelligence"}
{"index": 626, "text": "Focusing on the fabric defect detection with periodic-pattern and pure-color texture, an algorithm based on Direction Template and Image Pyramid is proposed. The detection process is divided into two stages: model training and defect localization. During the model training stage, we construct an Image Pyramid for each fabric image that does not contain any defects. Then, Stacked De-noising Convolutional Auto-Encoder (SDCAE) is used for image reconstruction, its training sets are created by randomly extracting image blocks from image pyramid, which makes the feature information of the image block more abundant and the reconstruction effect of the model more remarkable. During the defect localization stage, the image to be detected is divided into a number of blocks, and is reconstructed by using the trained SDCAE model. Then, the candidate defective image blocks are roughly located by using the Structural Similarity Index Measurement after the image reconstruction. Subsequently, direction template is introduced to solve the problem of fabric deformation caused by factors such as fabric production environment and photographic angle. We select the direction template of the images to be detected, filter the candidate defective blocks, and further reduce false detection rate of the proposed algorithm. Furthermore, there is no need to calculate size of periodic-pattern during detection for periodic textured fabric. The algorithm is also suitable for defect detection for pure-color fabrics. The experimental results show that the proposed algorithm can achieve better defect localization accuracy, and receive better results in detection of pure-color fabrics, compared with traditional methods.", "paperid": 2994857183, "normalizedname_level1": "artificial intelligence"}
{"index": 627, "text": "In this paper, we propose a new approach to global mapping of ground free spaces from aerial views in structured outdoor environments. The presented approach makes a topological mosaicing based on free space skeletonization and graph matching. The obtained environment model is a ground traversability map represented as a hybrid topological/metrical graph, which is a very suitable representation for ground navigation and planing. To validate this approach, the proposed algorithm is applied on aerial views provided by a UAV evolving over an experimental site and is compared with a recent state-of-the-art mosaicing solution.", "paperid": 2807820561, "normalizedname_level1": "artificial intelligence"}
{"index": 628, "text": "This paper reviews the first challenge on spectral image reconstruction from RGB images, i.e., the recovery of whole-scene hyperspectral (HS) information from a 3-channel RGB image. The challenge was divided into 2 tracks: the \"Clean\" track sought HS recovery from noiseless RGB images obtained from a known response function (representing spectrally-calibrated camera) while the \"Real World\" track challenged participants to recover HS cubes from JPEG-compressed RGB images generated by an unknown response function. To facilitate the challenge, the BGU Hyperspectral Image Database [4] was extended to provide participants with 256 natural HS training images, and 5+10 additional images for validation and testing, respectively. The \"Clean\" and \"Real World\" tracks had 73 and 63 registered participants respectively, with 12 teams competing in the final testing phase. Proposed methods and their corresponding results are reported in this review.", "paperid": 2892288283, "normalizedname_level1": "artificial intelligence"}
{"index": 629, "text": "Human action monitoring can be advantageous to remotely monitor the status of patients or elderly person for intelligent healthcare. Human action recognition enables efficient and accurate monitoring of human behaviors, which can exhibit multifaceted complexity attributed to disparities in viewpoints, personality, resolution and motion speed of individuals, etc. The spatial-temporal information plays an important role in the human action recognition. In this paper, we proposed a novel deep learning architecture named as recurrent 3D convolutional neural network (R3D) to extract effective and discriminative spatial-temporal features to be used for action recognition, which enables the capturing of long-range temporal information by aggregating the 3D convolutional network entries to serve as an input to the LSTM (Long Short-Term Memory) architecture. The 3D convolutional network and LSTM are two effective methods for extracting the temporal information. The proposed R3D network integrated these two methods by sharing a shared 3D convolutional network in sliding windows on video streaming to capturing short-term spatial-temporal features into the LSTM. The output features of LSTM encapsulate the long-range spatial-temporal information representing high-level abstraction of the human actions. The proposed algorithm is compared to traditional and the-state-of-the-art and deep learning algorithms. The experimental results demonstrated the effectiveness of the proposed system, which can be used as smart monitoring for remote healthcare.", "paperid": 2890209713, "normalizedname_level1": "artificial intelligence"}
{"index": 630, "text": "In 3-D video (3DV) applications, depth-image-based rendering (DIBR) has been widely employed to synthesize virtual views. However, this approach is performed in a frame-based way, meaning each whole frame is dealt with and the characteristics of different regions in the frame are ignored. As a result, redundant pixels in some regions are abused during the subsequent warping and blending stage. This paper proposes a region-aware 3-D warping approach for DIBR in which warped frames are reasonably divided beforehand so that only the indispensable regions are used. With the proposed scheme, it is possible to avoid noneffective and repeated pixels during the warping stage. In addition, the blending process is also saved. The experimental results show that compared to the state-of-the-art VSRS3.5 and VSRS-1D-fast algorithms, our approach can achieve significant computation savings without sacrificing synthesis quality.", "paperid": 2326638477, "normalizedname_level1": "artificial intelligence"}
{"index": 631, "text": "In this paper, Gene Expression Programming (GEP) based a wind turbine healthy condition identification model is proposed using generator current signals. Proposed GEP approach is capable to achieve very high classification accuracy. This is the first attempt to design such type of classifier using GEP for health condition identification of wind turbine. The beauty of proposed approach is to analyze the faults accurately with less process time. Moreover, proposed approach can also perform the self optimization process as it uses the function of both GA and GP in combine manner. Raw data of permanent magnet synchronous generator (PMSG) stator current is preprocessed through empirical mode decomposition (EMD) method to develop Intrinsic Mode functions (IMFs). Classifier uses the decision tree to further prune these IMFs to most relevant input variables which serve as input to GEP fault classifier. We compare performance of proposed GEP classifier with other AI based classifiers such as ANN and SVM. Obtained results and performance comparison shows that our proposed GEP based classifier could serve as an important tool for wind turbine fault diagnosis.", "paperid": 2766129993, "normalizedname_level1": "artificial intelligence"}
{"index": 632, "text": "This study has the purpose to investigate the potential to downstreaming of biomedicine researches in Indonesia based on scientific publications. It is therefore necessary to extract unstructured information in natural language-based scientific publications. This paper reports result from an investigation on a classification model of the downstreaming potential of biomedical research publications in Indonesia based on text-mining. The predictive computational model was built by testing three classifier algorithms namely KNN, Naive Bayes and SVM, where the results show that the Naive Bayes-based model performs best.", "paperid": 2798423693, "normalizedname_level1": "artificial intelligence"}
{"index": 633, "text": "Contour detection is an important step in contour based object analysis in 2D images. We present a novel method for contour detection optimized for contour traversal tasks in 2D images. The method is based on morphological operations and detects a one-pixel wide contour around objects in binary images. Performance of the method is evaluated on ground truth images from our dataset created by manually tracing the contour in images. Proposed method achieves high DICE coefficient overlap to ground truth images and superior detection compared to other state-of-the-art methods.", "paperid": 2904367742, "normalizedname_level1": "artificial intelligence"}
{"index": 634, "text": "In this paper, we present a novel image representation approach for paranasal sinus segmentation in computed tomography (CT) images of the brain. Our proposed method is based on a fully convolutional network (FCN), which is extensively used in a variety of computer vision applications. Experimental results demonstrate that our proposed method is efficient and effective for paranasal sinus segmentation.", "paperid": 2904646091, "normalizedname_level1": "artificial intelligence"}
{"index": 635, "text": "Intrusion detection is classified as NP-Hard in the literature even today. Also supervised learning also termed classification, when performed on high dimensional documents has problem from the noise or outliers, which make the text classification inaccurate and leads to reduced accuracy by classifiers. We discuss the feature reduction methods which we adopted to achieve dimensionality reduction. In the Feature Extraction process, the high dimensional text documents are projected onto their corresponding low dimensional representation in feature space through using algebraic rules and transformations. The objective is to find optimal transformation matrix corresponding the input high dimensional document feature matrix. This objective is achieved in this thesis by using the concept of feature clustering and through clustering the features into a optimal set of clusters by designing a novel fuzzy membership function. The membership function designed retains the original distribution of words in the documents which is the importance of this approach.", "paperid": 2557266189, "normalizedname_level1": "artificial intelligence"}
{"index": 636, "text": "With the flow of time, the application of different kinds of intelligent systems in many sectors like security, medical operations, detecting critical diseases, space researches, industrial heavy works, automated vehicles, and many others are increasing all over the of the world, and an intelligent system works by the use of its ability of image recognition. Furthermore, image recognition has been a notable subject in the scope of digital systems in most of the works we do today. Moreover, high-dimensional data from the physical world is obtained in order to produce statistical or representative knowledge by image recognition. In this study, a mutated image recognition technique has been recommended. For the work, different objects from different images were recognized by using a trained convolutional neural network and also the accuracy of the convolutional neural network was measured to examine the performance of the system. The evaluation of the accuracy of image recognition is the main continuation of this work which was done by modifying the system of updating weights in back-propagation. We used small filters of convolution in our work. We tried in this work to demonstrate that by modifying the weight updating system a vital advancement can be reached for greater efficiency in image recognition and applying it the convolutional neural network. Inception-v3, which is trained for the ImageNet Large Visual Recognition Challenge was used in our work and we found our results to be better. It was also pointed that the correctness of the outcomes from our designed system is far better than the state-of-art standards.", "paperid": 2938332306, "normalizedname_level1": "artificial intelligence"}
{"index": 637, "text": "We propose a new incremental aggregation algorithm for multi-image deblurring with automatic image selection. The primary motivation is that current burst deblurring methods do not handle well situations in which misalignment or out-of-context frames are present in the burst. These real-life situations result in poor reconstructions or manual selection of the images that are used to deblur. Automatically selecting the best frames within the burst to improve the base reconstruction is challenging because the number of possible images fusions is equal to the power set cardinal. Here, we approach the multi-image deblurring problem as a two steps process. First, we successfully learn a comparison function to rank a burst of images using a deep convolutional neural network. Then, an incremental Fourier burst accumulation with a reconstruction degradation mechanism is applied fusing only less blurred images that are sufficient to maximize the reconstruction quality. Experiments with the proposed algorithm have shown superior results when compared to other similar approaches, outperforming other methods described in the literature in previously described situations. We validate our findings on several synthetic and real datasets.", "paperid": 2971245923, "normalizedname_level1": "artificial intelligence"}
{"index": 638, "text": "The task of learning from imbalanced datasets has been widely investigated in the binary, multi-class and multilabel scenarios. Although this problem also affects hierarchical datasets, to the best of our knowledge, there are no works in the literature that deal with imbalanceness in hierarchical contexts. In this paper we propose metrics to measure \"how imbalanced\" is a Hierarchical Multi-Label Dataset, in addition to an approach to deal with this imbalanceness using Multi-Label resampling techniques. The proposed technique is based on the conversion of the dataset labels to a strictly multi-label format, applying wellknown multi-label resampling techniques and then converting the dataset back to its hierarchical taxonomy. The experimental evaluation over a highly imbalanced Music Genre Recognition dataset achieved promising results, with an increase of 0.2337 in the Avg-AUROC metric in relation to the original dataset.", "paperid": 2905142888, "normalizedname_level1": "artificial intelligence"}
{"index": 639, "text": "The article considers the task of classifying fractal time series based on the construction of their recurrence plots. Short realizations of EEG signals were used as input data. Two classification machine learning methods were considered: in the first case, quantitative fractal and recurrent characteristics of the time series were classification features, in the second case, image recognition of recurrence plots was carried out. The results showed fairly high classification quality for both methods, and relative advantage of the image classification method.", "paperid": 3088852387, "normalizedname_level1": "artificial intelligence"}
{"index": 640, "text": "Deep Learning models have revolutionized many research fields already. However, the raw eye movement data is still typically processed into discrete events via threshold-based algorithms or manual labelling. In this work, we describe a compact 1D CNN model, which we combined with BLSTM to achieve end-to-end sequence-to-sequence learning. We discuss the acquisition process for the ground truth that we use, as well as the performance of our approach, in comparison to various literature models and manual raters. Our deep method demonstrates superior performance, which brings us closer to human-level labelling quality.", "paperid": 2805368802, "normalizedname_level1": "artificial intelligence"}
{"index": 641, "text": "Hyperspectral image classification has attracted considerable interest in recent years. The previous classification methods are usually based on single-kernel or composite-kernel machines. In this paper, a novel regularization framework referred to least-squares support vector machine in sum space (LS-SVM-SS) of reproducing kernel Hilbert space (RKHS) is proposed for the classification of hyperspectral images using spectral signatures or local binary pattern features. The method is designed to simultaneously approximate the low- and high-frequency components of the target classification function with multiscale kernels. In the newly proposed scheme, LS-SVM-SS carries out the supervised learning and train a closed-form discriminant function to directly implement the multiclass classification. In contrast to multiple-kernel learning (MKL) by one-step method or two-step method, we can obtain a noniterative optimization procedure. Experiments are conducted on three real hyperspectral datasets. The corresponding experimental results demonstrate that the LS-SVM-SS method achieves good generalization performance in most cases compared with several state-of-the-art methods, which is better than that in any single-kernel RKHS. In addition, the proposed framework of multiscale kernels classifier opens a wide field for future developments in hyperspectral image classification.", "paperid": 2770495564, "normalizedname_level1": "artificial intelligence"}
{"index": 642, "text": "With suggested computational post-processing workflow for correcting optical distortions, the Fresnel lens can finally be used in lightweight and inexpensive computer vision sensors. Common methods for image enhancement do not comprehensively address the blurring artifacts caused by strong chromatic aberrations in images produced by a simple Fresnel optical system. To deliver image quality acceptable for general-purpose color imaging, we propose a computational post-capture processing to enhance the quality of images acquired with a 256-level Fresnel lens. The PSNR quality measure is then applied to estimate resulting quality for different deblurring techniques. A novel technique that removes chromatic blur without computationally expensive deconvolution can be considered a breakthrough as it finally enables in-camera embedded post-processing.", "paperid": 2608602932, "normalizedname_level1": "artificial intelligence"}
{"index": 643, "text": "This paper presents a novel hybrid optimization approach based on a genetic algorithm that combines selfish gene and altruism view of evolution. The purpose of the present research is to develop a new optimization approach to solve path-planning problems, particularly to be used in robot trajectories planning. A brief discussion about selfish versus altruism is made in the perspective of genes, its integration in the chromosome (individuals) and the forces involved in the evolution process of genes, individuals and populations. The SAGA (Selfish-Altruist Genetic Algorithm) is the generalization of the Genetic Algorithms (GA), where the basic variables are the genes (characters or words) as non-autonomous entities, grouped in a Chromosome structure. The proposed hybrid approach was applied to a path-planning problem, in a continuous search space, to show its effectiveness in complex and interdependent sub-paths and evolution processes. Genes-centred evolution improved local sub-paths as sub-processes in a Chromosome-centred evolution and resulted in improved global planning trajectories when compared with standard genetic algorithm.", "paperid": 2944451240, "normalizedname_level1": "artificial intelligence"}
{"index": 644, "text": "Reconstructing dense, volumetric models of real-world 3D scenes is important for many tasks, but capturing large scenes can take significant time, and the risk of transient changes to the scene goes up as the capture time increases. These are good reasons to want instead to capture several smaller sub-scenes that can be joined to make the whole scene. Achieving this has traditionally been difficult: joining sub-scenes that may never have been viewed from the same angle requires a high-quality camera relocaliser that can cope with novel poses, and tracking drift in each sub-scene can prevent them from being joined to make a consistent overall scene. Recent advances, however, have significantly improved our ability to capture medium-sized sub-scenes with little to no tracking drift: real-time globally consistent reconstruction systems can close loops and re-integrate the scene surface on the fly, whilst new visual-inertial odometry approaches can significantly reduce tracking drift during live reconstruction. Moreover, high-quality regression forest-based relocalisers have recently been made more practical by the introduction of a method to allow them to be trained and used online. In this paper, we leverage these advances to present what to our knowledge is the first system to allow multiple users to collaborate interactively to reconstruct dense, voxel-based models of whole buildings using only consumer-grade hardware, a task that has traditionally been both time-consuming and dependent on the availability of specialised hardware. Using our system, an entire house or lab can be reconstructed in under half an hour and at a far lower cost than was previously possible.", "paperid": 2784988069, "normalizedname_level1": "artificial intelligence"}
{"index": 645, "text": "The rise of big data and artificial intelligence techniques such as deep learning has lead to an exponential increase in stored data in various fields, including medical imaging, genetics and financial trading. Sharing these increasing amounts of data for research is challenging, as privacy risks increase with the increased size of data. Physically moving very large datasets to researchers is inconvenient, as download or sending physical hard disks are not optimal. Research on sensitive data is often not possible, as sharing is not legal. The popularity of container-based technologies such as Docker has revolutionized the way applications are deployed, due to their self-sufficient, light-weight and portable nature. In this paper, we propose a novel distributed platform using containers for simple execution and evaluation of research applications on the data owner's infrastructure, bringing the algorithms to the data. This approach avoids the cumbersome transfer of large datasets and can help circumventing problems linked to non-shareable data by providing a sandboxed execution environment with read-only access to the data. At no point the data leave the data owner's site, giving researchers access to their evaluation results, only, and not the data themselves. The presented proof-of-concept confirms the feasibility of a distributed container-based evaluation platform for large and/or sensitive data. This has several advantages, including execution of code instead of submission of result files and availability of otherwise inaccessible data. The container architecture allows for minimal computational overhead, no software dependency management on the infrastructure, distributed runtime environment and isolation of processes from the underlying host system. A version addressing various identified architectural and security-related challenges has the potential to be deployed in a production setting and therefore allows researchers to gain insights from previously inaccessible data. One goal is to target hospitals with increasingly strong local infrastructure for storage and computation, needed for artificial intelligence based decision support (genetics and imaging).", "paperid": 2888937027, "normalizedname_level1": "artificial intelligence"}
{"index": 646, "text": "In most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector. This feature vector is then subjected to a hashing function that produces a binary hash code. In previous work, the aggregating and the hashing processes are designed independently. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization produces aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, we also propose a fast version of the recently-proposed Binary Autoencoder to be used in our proposed framework. We perform extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features. Our results suggest that the proposed framework achieves significant improvements over the state of the art.", "paperid": 2963916624, "normalizedname_level1": "artificial intelligence"}
{"index": 647, "text": "This paper provides a dual-mode real-time lip-sync system for a bionic dinosaur robot. Different from traditional mono-modality control systems, our system is constructed with different controllers and classifiers in both time domain and frequency domain. Specially, a classifier in time domain is designed to extract the sound features including pitch and intensity. Meanwhile, a nonlinear mapping relationship between time-domain feature parameters and mouth open angles is particularly designed. In time domain, an efficient algorithm consisting of original and modified short-term average amplitude difference function (AMDF) is applied for frequency measurement. With the goal of predicting the curve of mouth open, we train the audio data of dinosaurs to get a frequency classifier by Support Vector Machine with racial basis function (RBF-SVM), which has a relatively high accuracy. Finally, extensive experiments validate the effectiveness of this proposed system on a real bionic dinosaur robot.", "paperid": 2913700756, "normalizedname_level1": "artificial intelligence"}
{"index": 648, "text": "High dynamic range (HDR) imaging has potential to facilitate computer vision tasks such as image matching where lighting transformations hinder the matching performance. However, little has been done to quantify the gains with different possible HDR representations for vision algorithms like feature extraction. In this paper, we evaluate the performance of the full feature extraction pipeline, including detection and description, on ten different image representations: low dynamic range (LDR), seven different tone mapped (TM) HDR and two HDR imaging (linear and log encoded) representations. We measure the impact of using these different representations for feature matching using mean average precision (mAP) scores on four illumination change datasets. We perform feature extraction using four popular schemes in the literature: SIFT, SURF, BRISK, FREAK. With respect to previous studies, our observations confirm the advantages of HDR over conventional LDR imagery, and the fact that HDR linear values are not appropriate for vision tasks. However, HDR representations that work best for keypoint detection are not necessarily optimal when the full feature extraction is taken into account.", "paperid": 2577315989, "normalizedname_level1": "artificial intelligence"}
{"index": 649, "text": "This paper evaluates the use of machine learning prediction models for assessing the quality of experience perceived by mobile network subscribers under mobility conditions. Input data are taken from a single measuring point available at commercial subscribers’ smartphones. A sequence data classifier based on a type of recurrent neural network, the long shortterm memory network, has been implemented and compared with two simpler machine learning models. A set of nine relevant network parameters, mainly related to the signal level and the signal quality of the serving and the neighbour cells, has been considered as inputs for the prediction model. The prediction model has been applied to estimate the downlink TCP performance on a set of non-intrusive drive tests. The overall performance achieved on the test set is around 80%, a really good result considering the size of the dataset.", "paperid": 3039624821, "normalizedname_level1": "artificial intelligence"}
{"index": 650, "text": "In this paper, we propose a fast novel nonlinear filtering method named Relative-Energy (Rel-En), for robust short-term event extraction from biomedical signals. We developed an algorithm that extracts short- and long-term energies in a signal and provides a coefficient vector with which the signal is multiplied, heightening events of interest. This algorithm is thoroughly assessed on benchmark datasets in three different biomedical applications, namely ECG QRS-complex detection, EEG K-complex detection, and imaging photoplethysmography (iPPG) peak detection. Rel-En successfully identified the events in these settings. Compared to the state-of-the-art, better or comparable results were obtained on QRS-complex and K-complex detection. For iPPG peak detection, the proposed method was used as a preprocessing step to a fixed threshold algorithm that lead to a significant improvement in overall results. While easily defined and computed, Rel-En robustly extracted short-term events of interest. The proposed algorithm can be implemented by two filters and its parameters can be selected easily and intuitively. Furthermore, Rel-En algorithm can be used in other biomedical signal processing applications where a need of short-term event extraction is present.", "paperid": 2677240081, "normalizedname_level1": "artificial intelligence"}
{"index": 651, "text": "Due to their relative ease of handling and low-cost, inertial measurement unit (IMU) based joint angle measurements are used for a widespread range of applications. These include sports performance, gait analysis and rehabilitation (e.g. Parkinson's disease monitoring or post-stroke assessment). However, a major downside of current algorithms recomposing human kinematics from IMU data is that they require calibration motions and/or the careful alignment of the IMUs respective to their body segment. In this article, we propose a new method, which is alignment free and self-calibrated using the arbitrary movements of the user and an initial zero reference arm pose. The proposed method utilizes real time optimization to identify the two dominant axes of rotation of the elbow joint. Using a two degree of freedom joint mimicking the human elbow, the performance of the algorithm was assessed by comparing the angles obtained from two IMUs to the ones obtained from a marker-based optical tracking system. The self-calibration proved to converge within seconds and the RMS errors with respect to the optical reference system were below 5°. Our method can be particularly useful in the field of telerehabilitation, where precise manual sensor to segment alignment as well as precise, predefined calibration movements are impractical.", "paperid": 2344388314, "normalizedname_level1": "artificial intelligence"}
{"index": 652, "text": "Face recognition has attained a greater importance in bio-metric authentication due to its non-intrusive property of identifying individuals at varying stand-off distance. Face recognition based on multi-spectral imaging has recently gained prime importance due to its ability to capture spatial and spectral information across the spectrum. Our first contribution in this paper is to use extended multi-spectral face recognition in two different age groups. The second contribution is to show empirically the performance of face recognition for two age groups. Thus, in this paper, we developed a multi-spectral imaging sensor to capture facial database for two different age groups (≤ 15years and ≥ 20years) at nine different spectral bands covering 530nm to 1000nm range. We then collected a new facial images corresponding to two different age groups comprises of 168 individuals. Extensive experimental evaluation is performed independently on two different age group databases using four different state-of-the-art face recognition algorithms. We evaluate the verification and identification rate across individual spectral bands and fused spectral band for two age groups. The obtained evaluation results shows higher recognition rate for age groups ≥ 20years than ≤ 15years, which indicates the variation in face recognition across the different age groups.", "paperid": 2565085068, "normalizedname_level1": "artificial intelligence"}
{"index": 653, "text": "The population of people with disabilities in the world, including disability of hand function, has increased significantly from year to year. Developing a prosthetic hand that is reliable, ergonomic, based on stream data input and functions like a human hand is a challenge in current research. The development of knowledge and technology has now reached a stage that allows the use of body signals to operate artificial hand systems. One application of the development of knowledge and technology is the use of EMG signals from Myo Armband sensors as input signals from the prosthetic hand. Implementation of this research requires two stages of research, namely initial research and further research. The initial research phase focuses on the capture and processing of EMG signals while further research focuses on preparing prosthetic hands with all the mechanisms needed. This research is an initial study that begins with electromyography signal taking using Myo Armband Device mounted on human hands. The signal obtained is then extracted using the Root Mean Square (RMS) method and classified using the Adaptive Neuro-Fuzzy Inference System (ANFIS). The results of this initial study were in the form of EMG signal pattern recognition. Recognition of the EMG signal pattern from the Myo Armband sensor using the RMS and ANFIS methods for 7 hand signals including Rest, Power Grasp, Hook, Pinch Grip, Tripod, Thumb and Index in this study resulted in an accuracy rate of 98.09 percent. Referring to the accuracy value obtained shows that the results of this initial study can be used as input in the prosthetic hand control system which will be developed in subsequent studies.", "paperid": 3097810625, "normalizedname_level1": "artificial intelligence"}
{"index": 654, "text": "Acute lymphoblastic leukemia is a type of cancer which attacks blood cells and spinal cord. A patient needs to conduct early detection to avoid more severe conditions. In this research, we proposed a new model to detect acute lymphoblastic leukemia by microscopic images. We divide fives stages to classify acute lymphoblastic leukemia, i.e. An image enhancement, an image segmentation, noise removal, feature extraction, and classification. Firstly, we enhanced the green channel before the segmentation process. Secondly, we employed the entropy method to obtain the best threshold value. However, the segmentation results have delivered small regions besides the main object. Thirdly, we have to remove the small objects before feature extraction. In addition, We extract the main object using energy, entropy, shanon entropy, and the object circularity. Lastly, we modified a learning vector quantization. The proposed algorithm synchronized the weight value, which has the maximum probability. We have evaluated our proposed algorithm using the Acute Lymphoblastic Leukemia Image Database (ALL-IDB2). Our proposed method has delivered 96.15% maximum accuracy. It proved that the proposed method has outperformed to the other methods, i.e. leukemia detection using Fuzzy, perceptron, and support vector machine", "paperid": 2998057515, "normalizedname_level1": "artificial intelligence"}
{"index": 655, "text": "Information hiding is a method that can effectively transmit secret messages on the Internet or mobile environment. Among all kinds of information hiding methods, dual-images reversible information hiding technology has been paid a lot of attention recently because it has better image quality and embedding capacity and realizes the concept of secret sharing. Lu et al. proposed a block folding based reversible dual-images hiding scheme in 2017. They split the secret information into two sections and encode them into smaller digits to improve the quality of the camouflage image. However, this method requires an additional pixel to record section numbers, that will limit the amount of information stored. This study considers the complexity of the block to analysis how many bits can be concealed in the pixel to solve the problem. Two thresholds are used to control the image quality. Experimental results show that the proposed scheme indeed improves the hiding performance.", "paperid": 2993692270, "normalizedname_level1": "artificial intelligence"}
{"index": 656, "text": "In this article an efficient pointer recognition algorithm is proposed to identify the pointer and it is used in real-time testing the scale of the dashboard pointer. The algorithm can be used to identify any type of dashboard pointer such as red color pointer, yellow color pointer and white color pointer etc. Pointer recognition is divided into two parts; configuration and testing. The parameters are required in testing of the dashboard such as the minimum, maximum and nonuniform scale of the dashboard. These parameters are collected in the configuration interface. These parameters are loaded when testing. The scale value of pointer is calculated according to the parameters after pointer position is detected. Configurations are setup for different types of dashboard so that any types of dashboard pointer can be detected. If all the scale values of the test points are correct values within an allowable error and the instrument is considered qualified during the test. Otherwise that the instrument is considered to be defective. Finally pointer recognition algorithm is applied to automobile instrument quality detection and has achieved good results.", "paperid": 2789887939, "normalizedname_level1": "artificial intelligence"}
{"index": 657, "text": "Multi- Target Regression (MTR) has recently gained a great deal of attention due to a large number of realworld applications being identified. Several MTR algorithms have been proposed and more continue to be developed. The main objective of all MTR prediction strategies is to use inter-target dependencies to improve prediction efficiency. In this research, we explore the affect of feature selection on MTR problems. We observe that using ordinary feature selection techniques with Single Target (ST) approach can give at par results compared to MTR methods, and in some cases, even surpass them.", "paperid": 3021505335, "normalizedname_level1": "artificial intelligence"}
{"index": 658, "text": "Electroencephalogram (EEG) signals have been widely used to analyze brain activities so as to diagnose certain brain-related diseases. They are usually recorded for a fairly long interval with adequate resolution, consequently requiring a considerable amount of memory space for storage and transmission. Recently compressed sensing (CS) has been proposed in order to effectively compress EEG signals. However, its performance is closely dependent on how a compression dictionary is built. Through our study, we notice that building the best fit over-complete Gabor dictionary plays an important role in this task. In this paper, we evaluate the effect of different time and frequency step sizes in building Gabor atoms on the performance of EEG signal compression using CS with three common EEG databases used by the research community. Taking the Normalized Mean Square Error (NMSE) as a performance metric, we present a quantitative study with an attempt to provide more insight on how to adopt CS in EEG signal compression.", "paperid": 2898765653, "normalizedname_level1": "artificial intelligence"}
{"index": 659, "text": "In this work, a novel outlier detection method is presented in which the data from the visual inspection of manufactured wafers are combined with the data from the electrical test. Three different implementations are built with increasing complexity in order to detect outliers that are not detected by a traditional outlier detection method such as the Dynamic Part Average Testing (DPAT). The screening parameters are constructed as a reformulation of the DPAT formulas, integrating information from visual inspection and the layout of the used product. The proposed VEDPAT algorithms are applied to a total of 25 wafers spread over 5 lots in order to compare their effectiveness. The results show that a method that combines the available information with the layout is able to effectively screen out outliers at the expense of only a very small yield loss. Also, details and microscope pictures of the false alarms and outliers detected by the method are presented.", "paperid": 3039718103, "normalizedname_level1": "artificial intelligence"}
{"index": 660, "text": "Sensorimotor learning, namely the process of understanding the physical world by combining visual and motor information, has been recently investigated, achieving promising results for the task of 2D/3D object recognition. Following the recent trend in computer vision, powerful deep neural networks (NNs) have been used to model the “sensory” and “motor” information, namely the object appearance and affordance. However, the existing implementations cannot efficiently address the spatio-temporal nature of the human-object interaction. Inspired by recent work on attention-based learning, this paper introduces an attention-enhanced NN-based model that learns to selectively focus on parts of the physical interaction where the object appearance is corrupted by occlusions and deformations. The model's attention mechanism relies on the confidence of classifying an object based solely on its appearance. Three metrics are used to measure the latter, namely the prediction entropy, the average N-best likelihood difference, and the N-best likelihood dispersion. Evaluation of the attention-enhanced model on the SOR3D dataset reports 33% and 26% relative improvement over the appearance-only and the spatio-temporal fusion baseline models, respectively.", "paperid": 2890882354, "normalizedname_level1": "artificial intelligence"}
{"index": 661, "text": "Object detection in challenging situations such as scale variation, occlusion, and truncation depends not only on feature details but also on contextual information. Most previous networks emphasize too much on detailed feature extraction through deeper and wider networks, which may enhance the accuracy of object detection to certain extent. However, the feature details are easily being changed or washed out after passing through complicated filtering structures. To better handle these challenges, the paper proposes a novel framework, multi-scale, deep inception convolutional neural network (MDCN), which focuses on wider and broader object regions by activating feature maps produced in the deep part of the network. Instead of incepting inner layers in the shallow part of the network, multi-scale inceptions are introduced in the deep layers. The proposed framework integrates the contextual information into the learning process through a single-shot network structure. It is computational efficient and avoids the hard training problem of previous macro feature extraction network designed for shallow layers. Extensive experiments demonstrate the effectiveness and superior performance of MDCN over the state-of-the-art models.", "paperid": 2962758212, "normalizedname_level1": "artificial intelligence"}
{"index": 662, "text": "Lossy compression is widely used in practice of image processing. However, noise present in images is not always taken into account in lossy compression and evaluation of its performance. Spatially correlated noise is considered even more rarely. This paper addresses just this case showing that there are certain peculiarities typical for it. Possible presence of optimal operation point is demonstrated for high intensity noise. Several techniques of lossy compression including standard and modern ones are analyzed. Their advantages and drawbacks are studied.", "paperid": 2343292875, "normalizedname_level1": "artificial intelligence"}
{"index": 663, "text": "Robots act in their environment through sequences of continuous motor commands. Because of the dimensionality of the motor space, as well as the infinite possible combinations of successive motor commands, agents need compact representations that capture the structure of the resulting displacements. In the case of an autonomous agent with no a priori knowledge about its sensorimotor apparatus, this compression has to be learned. We propose to use Recurrent Neural Networks to encode motor sequences into a compact representation, which is used to predict the consequence of motor sequences in term of sensory changes. We show that sensory prediction can successfully guide the compression of motor sequences into representations that are organized topologically in term of spatial displacement.", "paperid": 2962914439, "normalizedname_level1": "artificial intelligence"}
{"index": 664, "text": "Most of the current word segmentation methods are rule-based and traditional machine learning methods. Universal word segmentation tools do not work well in the field such as metallurgy. Domain-specific Chinese word segmentation is rarely studied. In recent years, with the development of deep learning, the neural network has been proved to be effective in Chinese word segmentation. However, this promising performance relies on large-scale training data. Neural networks with conventional architectures cannot achieve the desired results in low-resource datasets due to the lack of labeled training data. This paper takes the field of metallurgy as an example and proposes a domain-specific Chinese word segmentation based on Bi-directional long-short term memory (Bi-directional LSTM) model in the metallurgical field. First, the word segmentation model is obtained by using the Bi-directional LSTM model to train the internal and external domain knowledge. Then, a series of tuning parameters are carried out and the label probability of the word is combined with the weight. Finally, the result of word segmentation is obtained by label inference layer. The experimental results show that the proposed method can create a better word segmentation effect in the field of metallurgy.", "paperid": 2910398204, "normalizedname_level1": "artificial intelligence"}
{"index": 665, "text": "The aim of this study is to support medical experts to be able to make an order among large number of automatic registration. The experts could tackle with the most problematic cases due to the inaccuracy of automatic registration procedure in the vicinity of the bronchus to help virtual bronchoscopy (VB) systems. Functional images (e.g. PET) can be projected on the relevant part of the organ that is examined in VB systems. We collected cases where the difference between the time of low-dose (ldCT) and diagnostic CT (hdCT) was less than one year. Altogether 22 anonymous ldCT and hdCT studies were selected in this study. Based on the literature, a potential candidate for image registration was elastix. We applied a specific in-house developed application for image preprocessing, before the elastix registration. We tried to resolve the goodness of the entire registration process by visual judgment combining it with special numerical features. Numerical data include the mutual information, standardized mutual information, Kullback-Leibler entropy, cross correlation, L1norm, L2norm square. We found satisfying correlation between mutual information and visual judgment in the close vicintiy of airtree. We calculated confident intervals for MI of acceptable and rejected registrations about the mean values of it by bootstraping method: [0.27, 0.36], [0.13, 0.19].", "paperid": 2971792233, "normalizedname_level1": "artificial intelligence"}
{"index": 666, "text": "This research investigated several haptic interfaces designed to reduce mistakes in Morse code reception. Results concluded that a bimanual setup, discriminating dots/dashes by left/right location, reduced the amount of errors to only 56.6 percent of the errors compared to a unimanual setup that used temporal discrimination to distinguish dots and dashes.", "paperid": 2748344579, "normalizedname_level1": "artificial intelligence"}
{"index": 667, "text": "Biomedical Image Processing is the latest emerging tool in medical research used for the early detection of cancers. Artificial Intelligence can be used in the medical field to diagnose diseases at an early stage. Computed Tomography (CT Scans) of lungs of the patients from Lung Image Database Consortium (LIDC) is used as input data for image processing. In pre-processing stage conversion of RGB image to gray-scale image takes place because RGB images are too complex to process. Gray-scale image is further converted to Binary image. After Image Processing, the input images become more efficient and refined. These are input for the Convolution Neural Network. Convolution Filtering, Max Pooling filtering are steps in CNN which train the data to predict whether lung image is cancerous (malignant) or non-cancerous (benign). Deep Learning is a newer branch of Artificial Intelligence research will help in better performance in CNN based systems. The proposed system will also take into account the processing power and time delay of the cancer detection process for efficiency.", "paperid": 2953221965, "normalizedname_level1": "artificial intelligence"}
{"index": 668, "text": "Traditional intra prediction usually utilizes the nearest reference line to generate the predicted block when considering strong spatial correlation. However, this kind of single-line-based method does not always work well due to at least two issues. One is the incoherence caused by the signal noise or the texture of other objects, where this texture deviates from the inherent texture of the current block. The other reason is that the nearest reference line usually has worse reconstruction quality in block-based video coding. Due to these two issues, this paper proposes an efficient multiple-line-based intra-prediction scheme to improve coding efficiency. Besides the nearest reference line, further reference lines are also utilized. The further reference lines with a relatively higher quality can provide potentially better prediction. At the same time, the residue compensation is introduced to calibrate the prediction of boundary regions in a block when we utilize further reference lines. To speed up the encoding process, this paper designs several fast algorithms. The experimental results show that compared with HM-16.9, the proposed fast search method achieves a 2.0% bit saving on average and up to 3.7% by increasing the encoding time by 112%.", "paperid": 2558288778, "normalizedname_level1": "artificial intelligence"}
{"index": 669, "text": "In this paper, we propose a two-layered multi-task attention based neural network that performs sentiment analysis through emotion analysis. The proposed approach is based on Bidirectional Long Short-Term Memory and uses Distributional Thesaurus as a source of external knowledge to improve the sentiment and emotion prediction. The proposed system has two levels of attention to hierarchically build a meaningful representation. We evaluate our system on the benchmark dataset of SemEval 2016 Task 6 and also compare it with the state-of-the-art systems on Stance Sentiment Emotion Corpus. Experimental results show that the proposed system improves the performance of sentiment analysis by 3.2 F-score points on SemEval 2016 Task 6 dataset. Our network also boosts the performance of emotion analysis by 5 F-score points on Stance Sentiment Emotion Corpus.", "paperid": 3100732114, "normalizedname_level1": "artificial intelligence"}
{"index": 670, "text": "The study of rodent animal's social behavior has a key role in the field of biology and medicine, and it's a challenge to track multiple animals individually in the group experiment. The trajectories swap is a common problem in multiple mice tracking, and it is difficult to be solved by single vision method. This paper discusses a hybrid tracking method using RFID (Radio Frequency Identification) and computer vision. It first adopt the nearest neighbor method to link the positions of each target in image and form the original trajectories. Then location data recorded by the RFID system are fused with the trajectories identified by the vision system. Once the trajectories swap appears, the method uses the RFID location data to correct the identities of the trajectories. This paper presents the design of the vision tracking and RFID location system, and the data fusion algorithm of vision and RFID. It also presents the performance of the method with experimental tests.", "paperid": 2547225280, "normalizedname_level1": "artificial intelligence"}
{"index": 671, "text": "Discrete choice models are widely used to explain transportation behaviors, including a household's decision to own a car. They show how some distinct choice of human behavior or preference influences a decision. They are also used to project future demand estimates to support policy exploration. This latter use for prediction is indirectly aligned with and conditional to the model's estimation which aims to fit the observed data. In contrast, machine learning models are derived to maximize prediction accuracy through mechanisms such as out-of-sample validation, non-linear structure, and automated covariate selection, albeit at the expense of interpretability and sound behavioral theory. We investigate how machine learning models can outperform discrete choice models for prediction of car ownership using transportation household survey data from Singapore. We compare our household car ownership model (multinomial logit model) against various machine learning models (e.g. Random Forest, Support Vector Machines) by using 2008 data to derive, i.e. estimate models that we then use to predict 2012 ownership. The machine learning models are inferior to the discrete choice model when using discrete choice features. However, after engineering features more appropriate for machine learning they are superior. These results highlight both the cost of applying machine learning models in econometric contexts and an opportunity for improved prediction and better urban policy making through machine learning models with appropriate features.", "paperid": 2745104550, "normalizedname_level1": "artificial intelligence"}
{"index": 672, "text": "Both stock recommendations from sell-side analysts and online user generated content from crowds have great significance in the stock market. We examine and compare different effects of analyst attitude and crowd sentiment on stock prices in this article with data from CSMAR. By estimating a multivariate linear regression model, we find that although the wisdom of both experts and crowds has impact on stock prices, the latter's impact on stock prices prevails. We also adopt LightGBM, a novel machine learning model, to predict stock trends based on empirical results. Portfolio returns of different models also suggest that crowd wisdom is more valuable for creating investment strategy than expert wisdom. And it is necessary to take the wisdom of both experts and crowds into consideration when making investment decision.", "paperid": 3006562962, "normalizedname_level1": "artificial intelligence"}
{"index": 673, "text": "Image thresholding is an extensively accepted segmentation practice to extract the section of attention from a digital picture. Here, multi-thresholding is projected for the RGB picture with Social Group Optimization (SGO) algorithm. The chief motivation of this work is to investigate the presentation of well-known image segmentation procedure known as Kapur’s function. SGO and Kapur integrated procedures considered to enhance RGB picture stained with noises, like Gaussian (GN) and Speckle (SN). The capability of Kapur’s function is established with the well-known image quality measures available. The simulation outcome authenticates that, for the considered problem, Kapur’s offers better result for the original and noise stained images.", "paperid": 2914492341, "normalizedname_level1": "artificial intelligence"}
{"index": 674, "text": "Due to the hype in our industry in the last couple of years, there is a growing mismatch between software tools machine learning practitioners wish for, what they would truly need for their work, what's available (either commercially or open source) and what tool developers and researchers focus on. In this talk we will give a couple of examples of this mismatch. Several surveys and anecdotal evidence show that most practitioners work most of the time (at least in the modeling phase) with datasets that t in the RAM of a single server, therefore distributed computing tools are very of- ten overkill. Our benchmarks (available on github [1]) of the most widely used open source tools for binary classification (various implementations of algorithms such as linear methods, random forests, gradient boosted trees and neural networks) on such data show over 10x speed and over 10x RAM usage difference between various tools, with \"big data\" tools being the most inefficient. Significant performance gains have been obtained by those tools that incorporate various low-level (close to CPU and memory architecture) optimizations. Nevertheless, we will show that even the best tools show degrading performance on the multi-socket servers featuring a high number of cores, systems that have become widely accessible more recently. Finally, while most of this talk is about performance, we will also argue that machine learning tools that feature high-level easy-to-use APIs provide increasing productivity for practitioners and therefore are preferable.", "paperid": 2742879731, "normalizedname_level1": "artificial intelligence"}
{"index": 675, "text": "Intelligent fault diagnosis of machines for early recognition of faults saves industry from heavy losses occurring due to machine breakdowns. This paper proposes a process with a generic data mining model that can be used for developing acoustic signal-based fault diagnosis systems for reciprocating air compressors. The process includes details of data acquisition, sensitive position analysis for deciding suitable sensor locations, signal pre-processing, feature extraction, feature selection, and a classification approach. This process was validated by developing a real time fault diagnosis system on a reciprocating type air compressor having 8 designated states, including one healthy state, and 7 faulty states. The system was able to accurately detect all the faults by analyzing acoustic recordings taken from just a single position. Additionally, thorough analysis has been presented where performance of the system is compared while varying feature selection techniques, the number of selected features, and multiclass decomposition algorithms meant for binary classifiers.", "paperid": 2290122975, "normalizedname_level1": "artificial intelligence"}
{"index": 676, "text": "Robot teleoperation has received increasing attention in recent years, being driven mainly by the wide variety of applications in remote or dangerous environments. With the expansion of teleoperated robotics operations, there is also a growing demand for more efficient interfaces for human-robot interaction. Haptic devices allow the user to interact with the remote environment through a mechanical force provided by the joystick. Studies show that force feedback significantly improves operator performance. This paper presents the development of a haptic teleoperation system for the ABB IRB 120 industrial robotic manipulator and BarrettHand BH8-282 robotic hand, using a Geomagic Touch X haptic device, all integrated with ROS. Real and simulated experiments were performed. A group of participants underwent a simulation test and an evaluation questionnaire, validating the system's usability and the acceptance of the force feedback.", "paperid": 2908226385, "normalizedname_level1": "artificial intelligence"}
{"index": 677, "text": "This paper describes an integrated method of Principal Component Analysis(PCA) and Phase Shm Migration(PSM) for GPR data processing. The localization of subsurface objects is carried out by PSM. When the migration method is used the image is defocused due to the ground reflections and is tackled by incorporating PCA based on singular value decomposition(SVD). This approach can point out the most prominent singular values corresponding to both clutter and the useful data to filter out the radargram. Apart from that PCA can provide remarkable data compression. The effectiveness of this method 7 is validated by the synthetic data generated by gprMax at different target locations. The results demonstrate that the method generates well localized images.", "paperid": 3082860260, "normalizedname_level1": "artificial intelligence"}
{"index": 678, "text": "The poster details the development of Rogue Robotics, an underwater robotics organization founded by high school students in Monmouth County, New Jersey. The mission of the organization is to provide members of varying backgrounds and technical skill the opportunity to explore hands-on robotics through the design, construction, and testing of an underwater vehicle in preparation for the annual Marine Advanced Technology Education (MATE) ROV competition. The primary challenge discussed in the paper is the robot development process and methods for addressing the missions tasked. Establishing a company structure based on specialized divisions and focusing on design simplicity maximized efficiency and robot performance. Our approach to addressing the problems tasked by MATE was tested at the regional competition in Villanova, Pennsylvania, in which we qualified for the international level. Our success in competition and positive team reflections demonstrated our solution was effective and met the intended goals.", "paperid": 2981813748, "normalizedname_level1": "artificial intelligence"}
{"index": 679, "text": "This paper presents an image-based approach to estimate the motorcycle roll angle. The algorithm estimates directly the absolute roll to the road plane by means of a basic monocular camera. This means that the estimated roll angle is not affected by the road bank which is often a problem for vehicle observation and control purposes. For each captured image, the algorithm uses a numeric roll loop based on some simple knowledge of the road geometry. For each iteration, a bird-eye-view of the road is generated with the inverse perspective mapping technique. Then, a road marker filter associated with the well-known clothoid model are used respectively to track the road separation lanes and approximate them with mathematical functions. Finally, the algorithm computes two distinct areas between the two-road separation lanes. Its performances are tested by means of the motorcycle simulator BikeSim. This approach is very promising since it does not require any vehicle or tire model and is free of restrictive assumptions on the dynamics.", "paperid": 2906723871, "normalizedname_level1": "artificial intelligence"}
{"index": 680, "text": "Fundamental changes over time of surface EMG signal characteristics are a challenge for myocontrol algorithms controlling prosthetic devices. These changes are generally caused by electrode shifts after donning and doffing, sweating, additional weight or varying arm positions, which results in a change of the signal distribution—a scenario often referred to as covariate shift. A substantial decrease in classification accuracy due to these factors hinders the possibility to directly translate EMG signals into accurate myoelectric control patterns outside laboratory conditions. To overcome this limitation, we propose the use of supervised adaptation methods. The approach is based on adapting a trained classifier using a small calibration set only, which incorporates the relevant aspects of the nonstationarities, but requires only less than 1 min of data recording. The method was tested first through an offline analysis on signals acquired across 5 days from seven able-bodied individuals and four amputees. Moreover, we also conducted a three day online experiment on eight able-bodied individuals and one amputee, assessing user performance and user-ratings of the controllability. Across different testing days, both offline and online performance improved significantly when shrinking the training model parameters by a given estimator towards the calibration set parameters. In the offline data analysis, the classification accuracy remained above 92% over five days with the proposed approach, whereas it decreased to 75% without adaptation. Similarly, in the online study, with the proposed approach the performance increased by 25% compared to a test without adaptation. These results indicate that the proposed methodology can contribute to improve robustness of myoelectric pattern recognition methods in daily life applications.", "paperid": 2418845879, "normalizedname_level1": "artificial intelligence"}
{"index": 681, "text": "In this paper, we propose a novel binary local representation for RGB-D video data fusion with a structure-preserving projection. Our contribution consists of two aspects. Toacquire a general feature for the video data, we convert the problem to describing the gradient fields of RGB and depth information of video sequences. With the local fluxes of the gradient fields, which include the orientation and the magnitude of the neighborhood of each point, a new kind of continuous local descriptor called Local Flux Feature(LFF) is obtained. Then the LFFs from RGB and depth channels are fused into a Hamming space via the Structure Preserving Projection (SPP). Specifically, an orthogonal projection matrix is applied to preserve the pairwise structure with a shape constraint to avoid the collapse of data structure in the projected space. Furthermore, a bipartite graph structure of data is taken into consideration, which is regarded as a higher level connection between samples and classes than the pairwise structure of local features. Theextensive experiments show not only the high efficiency of binary codes and the effectiveness of combining LFFs from RGB-D channels via SPP on various action recognition benchmarks of RGB-D data, but also the potential power of LFF for general action recognition.", "paperid": 1944630830, "normalizedname_level1": "artificial intelligence"}
{"index": 682, "text": "Morphological Filter based Distributed Canny edge detection algorithm for Raspberry Pi platform using Simulink model is presented in this paper. Traditional canny edge detection algorithm uses frame based statistics which gives high accuracy but computationally more complex. Also canny algorithm is more sensitive to noise. In this experiment, an attempt is made to make canny algorithm more robust to noise using morphological filtering. Here canny algorithm is implemented at block level without any compromise in edge detection performance. If frame level statistics are used for threshold selection, it would result in either loss of edges or surplus edge detection. To solve this problem threshold selection is made based on type of block. Smooth and texture pixel counts are calculated for image block. Instead of using probability, actual pixel counts are used to calculate threshold. This makes threshold selection block more adaptive. Finally, objective analysis is carried out which shows proposed block based distributed algorithm is better than traditional frame based algorithm, especially in presence of impulse noise.", "paperid": 2578210874, "normalizedname_level1": "artificial intelligence"}
{"index": 683, "text": "Histopathological examination is today’s gold standard for cancer diagnosis. However, this task is time consuming and prone to errors as it requires a detailed visual inspection and interpretation of a pathologist. Digital pathology aims at alleviating these problems by providing computerized methods that quantitatively analyze digitized histopathological tissue images. The performance of these methods mainly relies on the features that they use, and thus, their success strictly depends on the ability of these features by successfully quantifying the histopathology domain. With this motivation, this paper presents a new unsupervised feature extractor for effective representation and classification of histopathological tissue images. This feature extractor has three main contributions: First, it proposes to identify salient subregions in an image, based on domain-specific prior knowledge, and to quantify the image by employing only the characteristics of these subregions instead of considering the characteristics of all image locations. Second, it introduces a new deep learning-based technique that quantizes the salient subregions by extracting a set of features directly learned on image data and uses the distribution of these quantizations for image representation and classification. To this end, the proposed deep learning-based technique constructs a deep belief network of the restricted Boltzmann machines (RBMs), defines the activation values of the hidden unit nodes in the final RBM as the features, and learns the quantizations by clustering these features in an unsupervised way. Third, this extractor is the first example for successfully using the restricted Boltzmann machines in the domain of histopathological image analysis. Our experiments on microscopic colon tissue images reveal that the proposed feature extractor is effective to obtain more accurate classification results compared to its counterparts.", "paperid": 2899683012, "normalizedname_level1": "artificial intelligence"}
{"index": 684, "text": "Inertial and magnetic sensors are widely used for different pattern recognition applications. In this paper, features extracted using time- and frequency-domain analysis are compared for human movement classification. Applied data were collected using wrist-mounted Wireless Sensor Network (WSN) motes equipped with 9 degree of freedom (9DOF) sensor boards. Data acquisition was done with the help of multiple subjects. To explore the capabilities of the used sensor types, different feature sets were generated and tested using multiple sensor combinations, and the feature extraction was tested utilizing raw sensor signals and computed magnitudes. The classification was done using MultiLayer Perceptron (MLP) neural networks. The obtained results show that the time-domain features (TDFs) provide higher classification efficiencies than frequency-domain features (FDFs). The highest obtained classification rate on unknown data was 91.74% using TDFs, and 88.51% applying FDFs.", "paperid": 2766054595, "normalizedname_level1": "artificial intelligence"}
{"index": 685, "text": "This paper presents a novel approach to the initialization of an ego-motion estimation technique for autonomous power line inspection. Dual channel vision, consisting of an infrared and optical camera, is typically adopted during inspection. The infrared camera is far more proficient at reliably detecting heated regions of the power tower which can be regarded as a prior relationship between the tower and cameras. Using the infrared camera, which is equipped parallel to the optical camera, an incomplete correspondence between the optical image and a 3D CAD model is established. Depending on the degree of correspondence, the initial pose of the CAD model in the optical image is estimated through two stages of coarse-to-fine estimation. The primary contributions of this paper include: 1) using dual vision for partial initialization; 2) in-corporating two-stage algorithms to estimate an accurate pose quickly; 3) implementing an algorithm which functions correctly regardless of the motion blur or background texture. Experimental results consistently show that the initial pose can be estimated efficiently and robustly.", "paperid": 2322479123, "normalizedname_level1": "artificial intelligence"}
{"index": 686, "text": "A method of data collecting, training, and using artificial neural networks (ANNs) for evaluating test point (TP) quality for TP insertion (TPI) is presented in this study. The TPI method analyzes a digital circuit and determines where to insert TPs to improve fault coverage under pseudo-random stimulus, but in contrast to conventional TPI algorithms using heuristically-calculated testability measures, the proposed method uses an ANN trained through fault simulation to evaluate a TP's quality. The time of feature extraction is demonstrated to be significantly faster compared to heuristic-based TP evaluation, and the impact of inserted TPs is shown to provide superior stuck-at fault coverage compared to conventional heuristic-based testability analysis.", "paperid": 2973742903, "normalizedname_level1": "artificial intelligence"}
{"index": 687, "text": "This work focuses on the detection of adverse drug reactions (ADRs) in electronic health records (EHRs) written in Spanish. The World Health Organization underlines the importance of reporting ADRs for patients’ safety. The fact is that ADRs tend to be under-reported in daily hospital praxis. In this context, automatic solutions based on text mining can help to alleviate the workload of experts. Nevertheless, these solutions pose two challenges: 1) EHRs show high lexical variability, the characterization of the events must be able to deal with unseen words or contexts and 2) ADRs are rare events, hence, the system should be robust against skewed class distribution. To tackle these challenges, deep neural networks seem appropriate because they allow a high-level representation. Specifically, we opted for a joint AB-LSTM network, a sub-class of the bidirectional long short-term memory network. Besides, in an attempt to reinforce lexical variability, we proposed the use of embeddings created using lemmas. We compared this approach with supervised event extraction approaches based on either symbolic or dense representations. Experimental results showed that the joint AB-LSTM approach outperformed previous approaches, achieving an f-measure of 73.3.", "paperid": 2900223378, "normalizedname_level1": "artificial intelligence"}
{"index": 688, "text": "Technology is the vital criterion to boosting the quality of life. Nowadays, innovation in smart wearable technologies (SWTs) has been coming up to different sectors and is gaining momentum to be implemented in everyday objects. The successful introduction of SWTs will present the production of new generations of innovative and high value-added products. Furthermore, this topic is gaining ground within both academic and practitioner studies with the attempt to better understand the innovation trend in order to provide a guidance for both policy makers and companies in supporting its development. Thus, the aim of this study is to analysis the development trends of SWTs. To this aim, we have built a unique database of 1062 patents included in the Thomson Innovation database and registered between 1998 and 2015. Data analysis are also conducted through citation analysis based on assignees and top IPC subclasses. Our analyses show the overall development trend for different product classes, and top assignees. This study also provides useful results for managers who can monitor their competitors in this industry in order to make decisions on technological investments and market strategies.", "paperid": 2612494250, "normalizedname_level1": "artificial intelligence"}
{"index": 689, "text": "In this paper, we propose a discriminative keypoint selection-based 3D face recognition method that is superior to prevalent techniques in terms of both computational complexity and performance. We use the average face model (AFM) for face registration to efficiently locate the axis of symmetry in the rotated face mesh and recover a full frontal face from a 3D face model commonly corrupted due to pose variances. Instead of using the keypoint detection method, we use the feature selection algorithm to find the most discriminant keypoints for face identification and reduce computational time for not only feature extraction but also keypoint matching. The results of the experiments conducted on the Bosphorus database and the UMB-DB show that our algorithm can improve rank-1 identification accuracy, thus confirming its robustness against pose variances, expressions, and occlusions.", "paperid": 2744648763, "normalizedname_level1": "artificial intelligence"}
{"index": 690, "text": "To be effective, robots will need to reliably operate in scenes with refractive objects in a variety of applications; however, refractive objects can cause many robotic vision algorithms, such as structure from motion, to become unreliable or even fail. We propose a novel method to distinguish between refracted and Lambertian image features using a light field camera. While previous refracted feature detection methods are limited to light field cameras with large baselines relative to the refractive object, our method achieves comparable performance, and we extend these capabilities to light field cameras with much smaller baselines than previously considered, where we achieve up to 50% higher refracted feature detection rates. Specifically, we propose to use textural cross correlation to characterize apparent feature motion in a single light field, and compare this motion to its Lambertian equivalent based on 4-D light field geometry. For structure from motion, we demonstrate that rejecting refracted features using our distinguisher yields lower reprojection error, lower failure rates, and more accurate pose estimates when the robot is approaching refractive objects. Our method is a critical step toward allowing robots to operate in the presence of refractive objects.", "paperid": 2809494891, "normalizedname_level1": "artificial intelligence"}
{"index": 691, "text": "Saliency detection is a significant research topic in the field of image processing and computer vision. Currently, most saliency detection methods are applied to RGB images, so that they may encounter adverse scenarios characterized by complex background, inclement weather, and low illumination. Fusing complementary advantages of RGB and thermal infrared (RGB-T) images can effectively boost saliency detection performance. Therefore, we propose a novel RGB-T saliency detection method in this letter. To this end, we first regard superpixels as graph nodes and calculate the affinity matrix for each feature. Then, we propose a low-rank tensor learning model for the graph affinity, which can suppress redundant information and improve the relevance of similar image regions. Finally, a novel ranking algorithm is proposed to jointly obtain the optimal affinity matrix and saliency values under a unified structure. Test results on two RGB-T datasets illustrate the proposed method performs well when against the state-of-the-art algorithms.", "paperid": 3083388823, "normalizedname_level1": "artificial intelligence"}
{"index": 692, "text": "Due to the impressive performance and computational efficiency of correlation filter (CF)-based object tracking methods, CF trackers have gained lots of popularity in recent years. However, target drift and tracking failure caused by background clutter and target appearance change (resulting from scale variation and deformation and so on) are still challenging tasks. To overcome these challenges, we propose a new tracking method within the CF framework in this paper. First, we learn a large margin CF by exploiting discriminative background patches. Contrary to conventional CF trackers that aim to maximize target response, we model a tracker that maximizes the margin between the target and surrounding background by exploiting background information effectively. To remedy the deficiency in handling target scale variation of CF-based trackers, we propose to train a CF by multi-level scale supervision, which aims to make CF sensitive to the target scale variation. Then, we integrate the two individual modules into one framework to simplify our tracking model. The proposed method can effectively prevent tracking module degradation introduced by target appearance changes. Extensive experiments conducted on public available data sets OTB-50/100 demonstrate that the proposed tracking method is robust to the background clutter and discriminative to the target scale variation. Both qualitative and quantitative results show the excellent performance against some state-of-the-art trackers.", "paperid": 2774104464, "normalizedname_level1": "artificial intelligence"}
{"index": 693, "text": "Blood glucose monitoring is essential for diabetes management. Applying deep learning technique for blood glucose monitoring is promising, given its success in a range of healthcare and medical tasks. In this paper, we proposed a method that combines Empirical Mode Decomposition (EMD) with Long-Short Term Memory (LSTM) to achieve good experimental results in predicting patient blood glucose. We used patients' real blood glucose levels time series data to train the method proposed in this paper and to predict blood glucose for 30 minutes to 120 minutes. First, we use only blood glucose readings and timestamps in the dataset. Meanwhile, we used ADF to verify the non-stationarity of blood glucose time series. Then, we use EMD to decompose the blood glucose time series and use LSTM to train the decomposed time series to obtain a blood glucose prediction model. Finally, Mean Absolute Error (MAE) and root mean squared error (RMSE) were used to evaluate the experimental results. On the test dataset, the mean values of the MAE and RMSE are 0.4458mmol/L and 1.08mmol/L for 30mins, 0.87 and 1.27 mmol/L for 60mins, 0.85mmol/L and 1.36 mmol/L for 120mins, respectively. Experimental results show that the EMD+LSTM had better predictive performance than the LSTM when blood glucose changed dramatically. Meanwhile, it is still challenging to reach a high accuracy of predicting the long-term blood glucose.", "paperid": 3010139956, "normalizedname_level1": "artificial intelligence"}
{"index": 694, "text": "We address talker-independent monaural speaker separation from the perspectives of deep learning and computational auditory scene analysis (CASA). Specifically, we decompose the multi-speaker separation task into the stages of simultaneous grouping and sequential grouping. Simultaneous grouping is first performed in each time frame by separating the spectra of different speakers with a permutation-invariantly trained neural network. In the second stage, the frame-level separated spectra are sequentially grouped to different speakers by a clustering network. The proposed deep CASA approach optimizes frame-level separation and speaker tracking in turn, and produces excellent results for both objectives. Experimental results on the benchmark WSJ0-2mix database show that the new approach achieves the state-of-the-art results with a modest model size.", "paperid": 2972460025, "normalizedname_level1": "artificial intelligence"}
{"index": 695, "text": "Estimation of potential accuracy of the measurement of informative signal parameters on background of non-Gaussian additive noise was obtained. Engineering estimations of the informative signal parameters on the background of additive non-Gaussian noise, with correlated nature were found.", "paperid": 2569071866, "normalizedname_level1": "artificial intelligence"}
{"index": 696, "text": "The feature extraction method of traditional image classification is difficult to deal with complex image problems. Although feature detector based on convolutional neural network can easily extract image features, many current network models have poor recognition accuracy and too many parameters. This paper proposes a multi-scale dual-channel dimension reduction module (DR module) to extract image features. Based on the AlexNet model, a deep global optimization model (GONET model) is proposed by exploiting the DR module, dropout and global pooling strategy. Compared with the AlexNet model, this model has better recognition performance. The accuracy on the Caltech256 dataset reaches 58.8% with GONET model, exceeding that of the AlexNet model by about 4.0%. The accuracy on the 101_food dataset reaches 69.0% with GONET model, exceeding that of the AlexNet model by about 8.9%. The experimental results show that the GONET model has superior image recognition effect, and it significantly reduces the network parameters while improving the recognition accuracy.", "paperid": 2905239520, "normalizedname_level1": "artificial intelligence"}
{"index": 697, "text": "In this paper, we propose a novel neighbor embedding method based on joint sub-bands for image super-resolution. Rather than directly reconstructing the total spatial variations of the input image, we restore each frequency component separately. The input LR image is decomposed into sub-bands defined by steerable filters to capture structural details on different directional frequency components. Then the neighbor embedding principle is employed to reconstruct each band, respectively. Moreover, taken the diverse characteristics of each band into account, we adopt adaptive similarity criteri-ons for searching nearest neighbors. Finally, we recombine the generated HR sub-bands by applying the inverting subband decomposition to get the final super-resolved result. Experimental results demonstrate the effectiveness of our method both in objective and subjective qualities comparing with other state-of-the-art methods.", "paperid": 2396992554, "normalizedname_level1": "artificial intelligence"}
{"index": 698, "text": "Video salient object detection aims at discovering the most visually distinctive objects in a video. How to effectively take object motion into consideration during video salient object detection is a critical issue. Existing state-of-the-art methods either do not explicitly model and harvest motion cues or ignore spatial contexts within optical flow images. In this paper, we develop a multi-task motion guided video salient object detection network, which learns to accomplish two sub-tasks using two sub-networks, one sub-network for salient object detection in still images and the other for motion saliency detection in optical flow images. We further introduce a series of novel motion guided attention modules, which utilize the motion saliency sub-network to attend and enhance the sub-network for still images. These two sub-networks learn to adapt to each other by end-to-end training. Experimental results demonstrate that the proposed method significantly outperforms existing state-of-the-art algorithms on a wide range of benchmarks. We hope our simple and effective approach will serve as a solid baseline and help ease future research in video salient object detection. Code and models will be made available.", "paperid": 2986056979, "normalizedname_level1": "artificial intelligence"}
{"index": 699, "text": "Breast density is widely adopted to reflect the likelihood of early breast cancer development. Existing methods of mammographic density classification either require steps of manual operations or achieve only moderate classification accuracy due to the limited model capacity. In this study, we present a radiomics approach based on dilated and attention-guided residual learning for the task of mammographic density classification. The proposed method was instantiated with two datasets, one clinical dataset and one publicly available dataset, and classification accuracies of 88.7% and 70.0% were obtained, respectively. Although the classification accuracy of the public dataset was lower than the clinical dataset, which was very likely related to the dataset size, our proposed model still achieved a better performance than the naive residual networks and several recently published deep learning-based approaches. Furthermore, we designed a multi-stream network architecture specifically targeting at analyzing the multi-view mammograms. Utilizing the clinical dataset, we validated that multi-view inputs were beneficial to the breast density classification task with an increase of at least 2.0% in accuracy and the different views lead to different model classification capacities. Our method has a great potential to be further developed and applied in computer-aided diagnosis systems.", "paperid": 3004452670, "normalizedname_level1": "artificial intelligence"}
{"index": 700, "text": "In order to improve the noise reduction performance and the clarity of denoising images, a composite convolutional neural network composed of the convolutional autoencoder network and the feature reconstruction network is proposed. Multiple convolutional layers are added into the autoencoder to extract the image feature information and improve the denoising performance, and the feature reconstruction network is designed to recover the texture and detail information of the image. The cross-connected structure is used to fuse feature information in the convolutional autoencoder network into the feature reconstruction network. Experimental results show that the proposed method has better noise reduction performance than the existing methods for different noise intensity. More texture and detail information could be retained, and the clearer denoising images could be obtained.", "paperid": 2969917953, "normalizedname_level1": "artificial intelligence"}
{"index": 701, "text": "Three-dimensional visualization is one of the most important researches in the field of medical images processing. Volume rendering is a powerful technique for visualizing meaningful information extracted from volumetric data in three-dimensional visualization. Although it does not need to generate intermediate geometric primitives and its rendering result is high quality, computational complexity of volume rendering is too high to achieve real-time interaction. Therefore, a fast GPU based high-quality three-dimensional visualization volume rendering method is proposed. A GPU based method is proposed to improve the run-time efficiency of volume rendering using volumetric texture. Because of limitation of video memory storage, large-scale volumetric data cannot be reconstructed or an expensive GPU is required. Therefore a slice texture based volume rendering method is proposed, which merely cost 4MB video memory by making use of a real-time dynamic switch mechanism. On the other hand, in order to eliminate annular distortion of volume rendering, a GPU based pre-integration classification method is presented. Although our methods are all implemented at general PCs, they can not only guarantee image quality but also improve rendering speed.", "paperid": 2736024993, "normalizedname_level1": "artificial intelligence"}
{"index": 702, "text": "Dempster-Shafer Theory has been extensively employed in the field of information fusion due to its impressive capability to cope with uncertain information. But when it deals with completely conflictive evidences or highly conflictive evidences, the phenomenon of counter intuition will occur. In this paper, shortcomings of the commonly accepted measure of conflict are analyzed and to avoid the wrong results made by using the conventional method, pignistic probability function is introduced to discriminate the differences between the evidences. Furthermore, based on the introduced pignistic probability function, an improved method for measuring the degree of conflict is proposed and proved. And then, the evidences are combined via a new combination rule to yield the ultimate result. The illustrative examples certify that even when the evidences are highly conflictive, targets can be recognized effectively.", "paperid": 2766213618, "normalizedname_level1": "artificial intelligence"}
{"index": 703, "text": "Dendritic spines, membranous protrusions of neurons, are one of the few prominent characteristics of neurons. Their shapes change with variations in neuron activity. Spine shape analysis plays a significant role in inferring the inherent relationship between neuron activity and spine morphology variations. First step towards integrating rich shape information is to classify spines into four shape classes reported in literature. This analysis is currently performed manually due to the deficiency of fully automated and reliable tools, which is a time intensive task with subjective results. Availability of automated analysis tools can expedite the analysis process. In this paper, we compare l1-norm-based sparse representation based classification approach to the least squares method, and the l2-norm method for dendritic spine classification as well as to a morphological feature-based approach. On a dataset of 242 automatically segmented stubby and mushroom spines, l1 representation with non-negativity constraint resulted in classification accuracy of 88.02%, which is the highest performance among the techniques considered here.", "paperid": 2433422012, "normalizedname_level1": "artificial intelligence"}
{"index": 704, "text": "The application of image steganography has greatly satisfied the needs of individuals and public security communication. Although steganography technology provides a convenient way to protect personal information exchange, it also becomes an effective tool for criminals. Steganalysis studying is very necessary. The position and capacity of secret information in stego images depend on the sharpness of the region in the adaptive steganography algorithms in spatial domain. According to this feature we propose a region segmentation pre-processing method in this paper, which is based on absolute difference of gray intensity. In order to improve the features discrimination, She entire image is divided into three different regions roughly, and then features are extracted. Those features have a higher correlation according to region characteristics. This proposed method offers a significant improvement in detection accuracy when compared to Region Segmentation method.", "paperid": 2593598205, "normalizedname_level1": "artificial intelligence"}
{"index": 705, "text": "In recent decades, the field of multiobjective optimization has attracted considerable interest among evolutionary computation researchers. One of the main features that makes evolutionary methods particularly appealing for multiobjective problems is the implicit parallelism offered by a population, which enables simultaneous convergence toward the entire Pareto front. While a plethora of related algorithms have been proposed till date, a common attribute among them is that they focus on efficiently solving only a single optimization problem at a time. Despite the known power of implicit parallelism, seldom has an attempt been made to multitask, i.e., to solve multiple optimization problems simultaneously. It is contended that the notion of evolutionary multitasking leads to the possibility of automated transfer of information across different optimization exercises that may share underlying similarities, thereby facilitating improved convergence characteristics. In particular, the potential for automated transfer is deemed invaluable from the standpoint of engineering design exercises where manual knowledge adaptation and reuse are routine. Accordingly, in this paper, we present a realization of the evolutionary multitasking paradigm within the domain of multiobjective optimization. The efficacy of the associated evolutionary algorithm is demonstrated on some benchmark test functions as well as on a real-world manufacturing process design problem from the composites industry.", "paperid": 2410677328, "normalizedname_level1": "artificial intelligence"}
{"index": 706, "text": "In this research work, we are dealing with an Automatic Speaker Verification problem, which consists on the determination if a person really is the person he/she claims to be, using his/her speech signal characteristics. Therefore, we conducted three series of experiments applied to a subset of Hub4 Broadcast-News database using a Support Vector Machine (SVM) as classifier and the Mel Frequency Spectral Coefficients (MFSC) as speakers’ features. In the first series of experiments, we investigated the effect of the number of features in order to obtain the minimum number that gives a Good Verification Score (GVScore). In the second series of experiments, as there are many types of kernel functions, the appropriate one for speaker verification is investigated. In the last series of experiments, we investigated the GVScore with regard to speaker gender (Male vs. Male, Female vs. Female and Male vs. Female). In our approach, we have used the MFSC as features extraction, which are calculated in both training and testing sessions. The obtained results of the proposed techniques are quite interesting.", "paperid": 3097976697, "normalizedname_level1": "artificial intelligence"}
{"index": 707, "text": "The Global Positioning System (GPS) can determine the position of any person or object on earth based on satellite signals. But when inside the building, the GPS cannot receive signals, the indoor positioning system will determine the precise position. How to achieve more precise positioning is the difficulty of an indoor positioning system now. In this paper, we proposed an ultra-wideband fingerprinting positioning method based on a convolutional neural network (CNN), and we collect the dataset in a room to test the model, then compare our method with the existing method. In the experiment, our method can reach an accuracy of 98.36%. Compared with other fingerprint positioning methods our method has a great improvement in robustness. That results show that our method has good practicality while achieves higher accuracy.", "paperid": 3093913350, "normalizedname_level1": "artificial intelligence"}
{"index": 708, "text": "Aiming at the problems of the noise impact on the parametric image of hand gestures, the difficulty of gesture feature extraction, and the inefficient utilization of continuous gesture time sequential information, we propose a time sequential inflated 3 dimensions (TS-I3D) convolutional neural network approach for hand gesture recognition based on frequency modulated continuous wave (FMCW) radar sensor. Specifically, the FMCW radar is used to acquire the hand gesture data, and the range and speed of the gesture in each frame signal are calculated by 2 dimensions fast Fourier transform. Then, the range-Doppler map (RDM) is generated based on the relationship between motion parameters and frequency. The interference in RDM caused by people and the external environment is filtered out and the peak of hand gesture in RDM is further enhanced by wavelet transform. Finally, TS-I3D network is designed to extract the range and speed change information of the continuous gestures. The experimental results show that the average recognition accuracy rate of the hand gestures of the proposed method is 96.17%.", "paperid": 2912659693, "normalizedname_level1": "artificial intelligence"}
{"index": 709, "text": "Visual Cryptography is a secret sharing scheme which owns the technique of sharing the visual information like pictures, text etc. It encrypts a secret into n visual shares printed in transparencies and shared among n participants. Qualified subsets of participants superimpose their transparencies to reconstruct the actual visual secret. The decryption of the visual secret demands no complex computation as the image can be retrieved by the human visual system after superimposing. This paper proposes a tagged visual cryptography for color images, where the secret image is splitted into two base shares based on the traditional visual cryptography scheme. The generated base shares are stamped with the tag pattern using the probabilistic visual cryptography scheme to obtain the tagged shares. One of the main advantage of using tag patterns is providing the participants with augmented information to identify the relevant shares among the numerous shares. During reconstruction the tag patterns are obtained by folding up the individual tagged shares. Superimposing the shares results in the secret color image which retains its original size thus ensuring no pixel expansion.", "paperid": 2612080193, "normalizedname_level1": "artificial intelligence"}
{"index": 710, "text": "Different digital media used by steganography to carry secrete information. This paper presents an algorithm to perform image steganography by combinational approach of genetic algorithm and trained auto associative neural network (TAANN). The proposed algorithm reduce needed time and needed space at encryption and at decryption level because of memory holding ability of neuron of auto associative neural network with high security for secrete information which is embed with cover image. This trained system work on pixel value of image to embedding the confidential information in cover image to perform encryption and the same trained architecture will need with secrete key to perform decryption or decoding. Image steganography is much better than cryptography because retrieving of confidential information from image is much harder than retrieving information from cipher text as plan text.", "paperid": 2559197959, "normalizedname_level1": "artificial intelligence"}
{"index": 711, "text": "In game development, Procedural Content Generation is an approach that replaces the designer’s task in creating contents of games, e.g., game maps. We introduce an incremental learning process that utilizes Inductive Learning (IL) of Answer Set Programs (ASP) to automate solving maps generation problems rather than to explicitly specify the characteristics of the maps. In an incremental learning process, a complex learning task is divided into a sequence of learning iterations, where each iteration consists of a set of smaller learning tasks to learn a set of rules. In order to speed up the learning process, each task in the same iteration is solved asynchronously. Our experiments show that IL of ASP successfully learns an answer set program. That is, it provides a set of rules for generating a collection of game maps that possess the same characteristics as the maps referred in the learning scenario.", "paperid": 3004708769, "normalizedname_level1": "artificial intelligence"}
{"index": 712, "text": "A wireless navigation mobile robot system is proposed in this paper for both path planning and trajectory execution. It should be within an indoor maze environment. The system consists of some device like a mobile robot, motion controller, visual sensor, ZigBee wireless communication device and a maze terrain to capture images of the mobile robot. The camera is used within the maze. To determine the robot's position it uses the Developed image processing and analyzing algorithms and orientation based on the color markers recognition. The Markers are placed on the top of the robot. So with this data the implemented navigation system calculates a trajectory for the mobile robot. It should be from a starting point to a target point for the trajectory calculation the Breadth First Search (BFS) and developed Depth First Search (DFS) algorithms which is modified were used. A developed control algorithm calculates the control signals in a real time. These signals are sent to the robot with the ZigBee device. And the modules for wireless communication, which causes the robot motion along the calculated trajectory and eventually, the completion of the trajectory method. The entire control system is realized and also the experimental results have been obtained. The experimental results confirm the effectiveness and robustness of the implemented control system.", "paperid": 2519549849, "normalizedname_level1": "artificial intelligence"}
{"index": 713, "text": "Person re-identification is being widely used in the forensic, and security and surveillance system, but person re-identification is a challenging task in real life scenario. Hence, in this work, a new feature descriptor model has been proposed using a multilayer framework of Gaussian distribution model on pixel features, which include color moments, color space values and Schmid filter responses. An image of a person usually consists of distinct body regions, usually with differentiable clothing followed by local colors and texture patterns. Thus, the image is evaluated locally by dividing the image into overlapping regions. Each region is further fragmented into a set of local Gaussians on small patches. A global Gaussian encodes, these local Gaussians for each region creating a multi-level structure. Hence, the global picture of a person is described by local level information present in it, which is often ignored. Also, we have analyzed the efficiency of earlier metric learning methods on this descriptor. The performance of the descriptor is evaluated on four public available challenging datasets and the highest accuracy achieved on these datasets are compared with similar state-of-the-arts, which demonstrate the superior performance.", "paperid": 2804621678, "normalizedname_level1": "artificial intelligence"}
{"index": 714, "text": "Recently, an increase in the availability and importance of relational datasets-such as social network data or protein interaction data-has lead to increased interest in modelling and learning from such data. Such data are often modelled as exchangeable arrays, yielding a particular representation due to Aldous and Hoover. We present a Bayesian nonparametric model based on this representation, which uses a novel process to generate a partition of the data. We present a Reversible Jump MCMC algorithm for inference in this model, and demonstrate the effectiveness of this approach on real-world data.", "paperid": 2551114872, "normalizedname_level1": "artificial intelligence"}
{"index": 715, "text": "Vulnerability detection is an import issue in information system security. In this work, we propose the deep learning method for vulnerability detection. We present three deep learning models, namely, convolution neural network (CNN), long short term memory (LSTM) and convolution neural network — long short term memory (CNN-LSTM). In order to test the performance of our approach, we collected 9872 sequences of function calls as features to represent the patterns of binary programs during their execution. We apply our deep learning models to predict the vulnerabilities of these binary programs based on the collected data. The experimental results show that the prediction accuracy of our proposed method reaches 83.6%, which is superior to that of traditional method like multi-layer perceptron (MLP).", "paperid": 2795170942, "normalizedname_level1": "artificial intelligence"}
{"index": 716, "text": "Semi-supervised learning, i.e. jointly learning from labeled and unlabeled samples, is an active research topic due to its key role on relaxing human supervision. In the context of image classification, recent advances to learn from unlabeled samples are mainly focused on consistency regularization methods that encourage invariant predictions for different perturbations of unlabeled samples. We, conversely, propose to learn from unlabeled data by generating soft pseudo-labels using the network predictions. We show that a naive pseudo-labeling overfits to incorrect pseudo-labels due to the so-called confirmation bias and demonstrate that mixup augmentation and setting a minimum number of labeled samples per mini-batch are effective regularization techniques for reducing it. The proposed approach achieves state-of-the-art results in CIFAR-10/100, SVHN, and Mini-ImageNet despite being much simpler than other methods. These results demonstrate that pseudo-labeling alone can outperform consistency regularization methods, while the opposite was supposed in previous work. Source code is available at https://git.io/fjQsC.", "paperid": 3091002423, "normalizedname_level1": "artificial intelligence"}
{"index": 717, "text": "Venue recommendation is an important capability of Location-Based Social Networks such as Yelp and Foursquare. Matrix Factorisation (MF) is a collaborative filtering-based approach that can effectively recommend venues that are relevant to the users' preferences, by training upon either implicit or explicit feedbacks (e.g. check-ins or venue ratings) that these users express about venues. However, MF suffers in that users may only have rated very few venues. To alleviate this problem, recent literature have leveraged additional sources of evidence, e.g. using users' social friendships to reduce the complexity of - or regularise - the MF model, or identifying similar venues based on their comments. This paper argues for a combined regularisation model, where the venues suggested for a user are influenced by friends with similar tastes (as defined by their comments). We propose a MF regularisation technique that seamlessly incorporates both social network information and textual comments, by exploiting word embeddings to estimate a semantic similarity of friends based on their explicit textual feedback, to regularise the complexity of the factorised model. Experiments on a large existing dataset demonstrate that our proposed regularisation model is promising, and can enhance the prediction accuracy of several state-of-the-art matrix factorisation-based approaches.", "paperid": 2533870691, "normalizedname_level1": "artificial intelligence"}
{"index": 718, "text": "We propose a novel method for the estimation of respiratory rate in real-time from the electrocardiogram (ECG) signals catered to the deployment on wearable devices. Continuous data acquisition on wearable devices will lead to predatory battery consumption. We developed a model which learns the respiratory induced inter beat variability representations from a 10 second ECG epoch using the statistical methods of PCA. The coefficients of the principal components describe these learned representations which are generalized to breaths per minute (bpm) using the cubic spline extrapolation technique. The proposed method was validated using the physiological recordings from the Physionet — Fantasia Database after the application of preprocessing methods, achieves an overall mean absolute error (MAE) of 0.5. The experimental results of elderly subjects (MAE 0.15) outperformed that of young subjects (MAE 0.85), notably due to the heart rate variability. Consequently, further investigations are recommended.", "paperid": 2785483432, "normalizedname_level1": "artificial intelligence"}
{"index": 719, "text": "One of the main issues in cluster analysis is to determine the correct number of clusters in the real-world applications. This study suggests an adaptive Differential Evolution (DE) algorithm to perform the automatic clustering and determine the number of clusters automatically. The proposed approach is denoted as Adaptive Differential Evolution (ADE) utilizes adaptive approaches to fine-tune the standard DE algorithms key parameters and uses new mutation approaches to keep a balance between the exploration and exploitation in the algorithm. The proposed algorithm is used for several benchmark datasets and applied to customer segmentation as a case study. After performing the customer segmentation, different clusters are obtained which will determined different groups of customers. In order to test the efficiency of the proposed approach, the Wilcoxon Rank sum test has been used. After conducting the experiments, the proposed algorithm revealed a superior efficiency in comparison with the employed algorithms.", "paperid": 3016274399, "normalizedname_level1": "artificial intelligence"}
{"index": 720, "text": "Structural similarity index (SSIM) is a widely used full-reference metric for assessment of visual quality of images and remote sensing data. It is calculated in a block-wise manner and is based on multiplication of three components: similarity of means of image blocks, similarity of contrasts and a correlation factor. In this paper, two modifications of SSIM are proposed. First, a fourth multiplicative component is introduced to SSIM (thus obtaining SSIM4) that describes a similarity of predictability of image blocks. A predictability for a given block is calculated as a minimal value of mean square error between the considered block and the neighboring blocks. Second, a simple scheme for calculating the metrics SSIM and SSIM4 for color images is proposed and optimized. Effectiveness of the proposed modifications is confirmed for the specialized image databases TID2013, LIVE, and FLT. In particular, the Spearman rank order correlation coefficient (SROCC) for the recently introduced FLT Database, calculated between the proposed metric color SSIM4 and mean opinion scores (MOS), has reached the value 0.85 (the best result for all compared metrics) whilst for SSIM it is equal to 0.58.", "paperid": 2890853274, "normalizedname_level1": "artificial intelligence"}
{"index": 721, "text": "Human gait function can decrease due to disability or aging. The elderly and persons with disabilities need walking training or assistance using a device, which require appropriate selection of methods for evaluating walking function. This study aimed at continuously measuring human walking motion over long distances. The proposed system moves a measurement device that can estimate human posture to enable to continuous measurements of human walking motion. Therefore, the proposed system consists of a measurement device and sensors or a robot that can measure the travel distance of the measurement device. We proposed two systems for the required applications. A manually moved device, consisting of a color depth sensor and a wheel equipped with a rotary encoder, measured patients with relatively high walking function. We also developed a robot that can automatically track subjects to measure patients with low gait function while the therapist supports the patient. Evaluation experiments on the developed systems confirm 7-9° error in joint angle estimations. Moreover, we find that the developed systems are susceptible to vibration.", "paperid": 3011153086, "normalizedname_level1": "artificial intelligence"}
{"index": 722, "text": "Deep neural networks are difficult to train when applied to tasks that can be expressed as algorithmic procedures. In this article, we propose to study how the explicit guidance of a network through all steps of the algorithm, using external memory and active choice of inputs, can improve its learning capability. The idea is to take inspiration from a child’s learning and running through a procedure via interaction with an external support such as a paper. We show that this mechanism applied to a simple multilayer perceptron can significantly improve its performance when learning either a multi-digit addition or multiplication, which are simple but yet challenging operations to learn.", "paperid": 3083742331, "normalizedname_level1": "artificial intelligence"}
{"index": 723, "text": "Recently, automated biometric identification system (ABIS) has wide applications involving automatic identification and data capture (AIDC), which includes automatic security checking, verifying personal identity to prevent information disclosure or identity fraud, and so on. With the advancement of biotechnology, identification systems based on biometrics have emerged in the market. These systems require high accuracy and ease of use. Palm vein identification is a type of biometric that identifies palm vein features. Compared with other features, palm vein recognition provides accurate results and has received considerable attention. We developed a novel high-performance and noncontact palm vein recognition system by using high-performance adaptive background filtering to obtain palm vein images of the region of interest. We then used a modified convolutional neural network to determine the best recognition model through training and testing. Finally, the developed system was implemented on the low-level embedded Raspberry Pi platform with cloud computing technology. The results showed that the system can achieve an accuracy of 96.54%.", "paperid": 3088350551, "normalizedname_level1": "artificial intelligence"}
{"index": 724, "text": "Deep neural networks (DNNs) have been demonstrated as effective prognostic models across various domains, e.g. natural language processing, computer vision, and genomics. However, modern-day DNNs demand high compute and memory storage for executing any reasonably complex task. To optimize the inference time and alleviate the power consumption of these networks, DNN accelerators with low-precision representations of data and DNN parameters are being actively studied. An interesting research question is in how low-precision networks can be ported to edge-devices with similar performance as high-precision networks. In this work, we employ the fixed-point, floating point, and posit numerical formats at $\\leq$8-bit precision within a DNN accelerator, Deep Positron, with exact multiply-and-accumulate (EMAC) units for inference. A unified analysis quantifies the trade-offs between overall network efficiency and performance across five classification tasks. Our results indicate that posits are a natural fit for DNN inference, outperforming at $\\leq$8-bit precision, and can be realized with competitive resource requirements relative to those of floating point.", "paperid": 2924943819, "normalizedname_level1": "artificial intelligence"}
{"index": 725, "text": "This paper proposed a high capacity reversible data hiding (RDH) scheme using three steganographic images, on which three successive embedding phases are performed. An embedding rule is elaborately designed to guide the data embedding and three alike stego-images are generated in the first phase. In view of the similarity of three stego-images, the pixel value ordering (PVO) strategy is utilized in the second phase. In the third phase, the prediction error histogram shifting (PEHS) strategy is employed by exploiting the slight difference among three temporary stego-images. Since no complex operation is involved, the algorithm is efficient. The experimental results verify that our method is superior to other schemes in both EC and image quality. Moreover, the proposed scheme can successfully resist the RS steganalysis and provide a secure secret transmission.", "paperid": 2997837529, "normalizedname_level1": "artificial intelligence"}
{"index": 726, "text": "Increasing number of genomic studies have associated copy number variations (CNVs) with several diseases such as cancer, autism, Alzheimer, and many autoimmune diseases. Therefore, developing reliable computational tools for recurrent CNV detection is crucial to understand the development of such diseases. A widely used microarray technology for measuring DNA copy number is array-based Comparative Genomic Hybridization (aCGH). Identifying concurrent CNVs is challenging due to the presence of noise and sample-specific variations. In this paper, we propose two matrix decomposition-based approaches, Smooth Regularization Decomposition (SRD) and Smooth Regularization Sparse Decomposition (SRSD) for reliable recurrent CNV detection from aCGH data. The essence of the two techniques is to model the aCGH profiles as smooth signals. However, the SRSD algorithm extends the SRD model to account for sample-specific variations. We also propose an algorithm to efficiently solve the SRSD model. Our simulations, using synthetic and realistic datasets, show that our proposed models achieve better accuracies when compared to the state-of-the-art models.", "paperid": 2987129607, "normalizedname_level1": "artificial intelligence"}
{"index": 727, "text": "In this paper we introduce three main features extracted from Moodle logs in order to be uses a possible means to predict future student grades. We discuss the statistical analysis on these features and show how they cannot be applied isolatedly to model our data. We then apply them as a whole and use principal component analysis to derive a decision tree based on the features. With derived tree we are able to predict grades in three intervals, namely to predict failures. Our proposed analysis methodology can be incorporated in an LMS and be used during a course. As the course unfolds, the system can to trigger alarms regarding possible failure situations.", "paperid": 2557961137, "normalizedname_level1": "artificial intelligence"}
{"index": 728, "text": "This research developed an alternative to grayscale Phase Shifting Interferometry for 3D surface measurement by utilizing three channels color fringe. As it has been known, grayscale PSI has limitation on dynamic object measurement due to its multi-frame term. By utilizing digital color image, it merely needs a single fringe projection making it possible to obtain faster data acquisition. However, each channel of the recorded image has different intensity range due to optical system's non-linearity that would significantly affect the quality of the reconstruction. Therefore, normalization is urgently needed before performing phase computation. In this study, the normalization was performed using Isotropic N-Dimensional Fringe Normalization (INFPN) based on Hilbert Transformation, while the phase processing includes extraction using 3-step PSI and global phase unwrapping. Experiments are conducted to evaluate RGB fringe performance compared to the grayscale 3-step PSI and grayscale single frame Fourier Transform Profilometry (FTP). The results show that RGB fringe can produce a fairly good reconstruction with the measurement error of less than 6% compared to the grayscale 3-step PSI on static evaluation. It also gives far better quality of reconstruction than the grayscale single frame FTP.", "paperid": 2773971046, "normalizedname_level1": "artificial intelligence"}
{"index": 729, "text": "Vision guided robotic operation has been widely used in industrial applications. Especially, visual servoing has a glory prospect use in this scenario. It's widely known that the eye-in-hand configuration in visual servoing architectures is categorized as a highly coupled and nonlinear system. With the decoupling properties, it is very suitable to use some features deduced from moments to control the whole six Degrees of Freedom (DOFs) of a camera. In this paper, some new moment based features are given to control the rotational motion around different axis and a simple adaptive factor controller is introduced to further enhance the performance of the servo system. As a result, we get a greater convergence domain and better dynamic properties.", "paperid": 2510572532, "normalizedname_level1": "artificial intelligence"}
{"index": 730, "text": "This paper is aimed at the difficult problem of multi region segmentation of weld pool image, analyzed The difficulty of edge extraction in the inner region of the weld pool. According to the characteristics between pixel neighborhood space and neighbor pixel correlation, based on local standard deviation, presented a noise suppression, edge enhancement of the weld pool image multi region division and multi region edge detection algorithm, Through the test of the weld pool image, It shows that the algorithm can accurately divide the internal details of the weld pool. Finally, the Sobel operator, Roberts operator, Prewitt operator and the edge detection results of the weld pool image are analyzed and compared by experiments, The results show that the algorithm in this paper is much better than other algorithms, At last, the accuracy of the algorithm is tested by the difference shadow detection, a continuous multi region edge was obtained by the expansion of corrosion.", "paperid": 2577886012, "normalizedname_level1": "artificial intelligence"}
{"index": 731, "text": "Brain-Computer Interfaces (BCI) face a great challenge: how to harness the wide variability of brain signals from a user to another. The most visible problem is the lack of a sound framework to capture the specificity of a user brain waves. A first attempt to leverage this issue is to design user-specific spatial filters, carefully adjusted with a lengthy calibration phase. A second, more recent, opening is the systematic study of brain signals through their covariance, in an appropriate space from a geometric point of view. Riemannian geometry allows to efficiently characterize the variability of inter-subject EEG, even with noisy or scarce data. This contribution is the first attempt for SSVEP-based BCI to make the most of the available data from a user, relying on Riemannian geometry to estimate the similarity with a multi-user dataset. The proposed method is built in the framework of transfer learning and borrows the notion of composite mean to partition the space. This method is evaluated on 12 subjects performing an SSVEP task for the control of an exoskeleton arm and the results show the contribution of Riemannian geometry and of the user-specific composite mean, whereas there is only a few data available for a subject.", "paperid": 2902297607, "normalizedname_level1": "artificial intelligence"}
{"index": 732, "text": "The differential count and analysis of blood cells in microscope images can provide useful information concerning the health of patients. There are three major blood cell types, namely, erythrocytes (RBCs), leukocytes (WBCs), and platelets. Automated blood cell analysers can provide RBCs, WBCs and platelets count but the presence of abnormal cells could affect the cells counting, that should be checked manually. This is why today the conventional practice for such procedure is executed manually by pathologists under light microscope. However, the manual visual inspection is tedious, time consuming, repetitive and it is strongly influenced by the operator's capabilities and tiredness. Therefore, a good clinical decision support system for cells counting and classification has always become a necessity. Few examples of automated systems that can analyse and classify blood cells have been reported in the literature. This research proposes a computer-aided systems that simulates a human visual inspection to automate the process of detection and identification of WBCs and RBCs from blood smear images. The proposed method has been tested on public datasets of blood cell images and demonstrates a reliable and effective system for differential counting, obtaining an average accuracy value of 99.2% for WBCs and 98% for RBCs, outperforming the state-of-the-art.", "paperid": 2609608141, "normalizedname_level1": "artificial intelligence"}
{"index": 733, "text": "Abnormal activity recognition and its detection becomes a major task in surveillance videos. In the context of security purposes, it becomes more challenging to identify the abnormal events or activities in video surveillance. Surveillance closely observes, monitors and identify the behaviour of any object like people, suspicious thing or any abnormal activity. Technology is increases very fast, it becomes easier to identify and detect the abnormal activities. There are a lot of techniques and methods are available in field of detection of abnormal activities. In this paper, we discuss about the various methods and techniques and discuss about their advantages and disadvantages. And also compare these technologies based upon their performance. In related work, there are many techniques like Spatio-temporal Saliency Detection, Graph Formulation, Oriented GMM, Based upon Sparse reconstruction and using Statistical Hypothesis Detector etc.", "paperid": 2966647624, "normalizedname_level1": "artificial intelligence"}
{"index": 734, "text": "Surface electromyography (sEMG) is widely used in clinical diagnosis, rehabilitation engineering and humancomputer interaction and other fields. In this paper, we use Myo armband to collect sEMG signals. Myo armband can be worn above any elbow of any arm and it can capture the bioelectric signal generated when the arm muscles move. MYO can pass of signals through its low-power Blue-tooth, and its interference is small, which makes the signal quality really good. By collecting the sEMG signals of the upper limb forearm, we extract five eigenvalues in the time domain, and use the BP neural network classification algorithm to realize the recognition of six gestures in this paper. Experimental results show that the use of MYO for gesture recognition can get a very good recognition results, it can accurately identify the six hand movements with the average recognition rate of 93%.", "paperid": 2781686820, "normalizedname_level1": "artificial intelligence"}
{"index": 735, "text": "Clustering has many applications in research and industry. However, traditional clustering methods, such as K-means, DBSCAN and HAC, impose oversimplifying assumptions and thus are not well-suited to face clustering. To adapt to the distribution of realistic problems, a natural approach is to use Graph Convolutional Networks (GCNs) to enhance features for clustering. However, GCNs can only utilize local information, which ignores the overall characterisitcs of the clusters. In this paper, we propose a Density-Aware Feature Embedding Network (DA-Net) for the task of face clustering, which utilizes both local and non-local information, to learn a robust feature embedding. Specifically, DA-Net uses GCNs to aggregate features locally, and then incorporates non-local information using a density chain, which is a chain of faces from low density to high density. This density chain exploits the non-uniform distribution of face images in the dataset. Then, an LSTM takes the density chain as input to generate the final feature embedding. Once this embedding is generated, traditional clustering methods, such as density-based clustering, can be used to obtain the final clustering results. Extensive experiments verify the effectiveness of the proposed feature embedding method, which can achieve state-of-the-art performance on public benchmarks.", "paperid": 3035028247, "normalizedname_level1": "artificial intelligence"}
{"index": 736, "text": "In this paper, based on AlphaZero, we propose a model with deep convolutional neural networks using value function and policy function for Dots-and-Boxes game system. In supervised game learning strategies, one challenge is the lack of sample data of high-quality. Our approach for solving this problem is to generate sample data effectively by iteration and self-playing. Experiments demonstrate that our novel method can significantly enhance the gaming skill of Dots-and-Boxes.", "paperid": 2972739456, "normalizedname_level1": "artificial intelligence"}
{"index": 737, "text": "This paper presents an in-depth analysis of the majority of the deep neural networks (DNNs) proposed in the state of the art for image recognition. For each DNN, multiple performance indices are observed, such as recognition accuracy, model complexity, computational complexity, memory usage, and inference time. The behavior of such performance indices and some combinations of them are analyzed and discussed. To measure the indices, we experiment the use of DNNs on two different computer architectures, a workstation equipped with a NVIDIA Titan X Pascal, and an embedded system based on a NVIDIA Jetson TX1 board. This experimentation allows a direct comparison between DNNs running on machines with very different computational capacities. This paper is useful for researchers to have a complete view of what solutions have been explored so far and in which research directions are worth exploring in the future, and for practitioners to select the DNN architecture(s) that better fit the resource constraints of practical deployments and applications. To complete this work, all the DNNs, as well as the software used for the analysis, are available online.", "paperid": 2893813411, "normalizedname_level1": "artificial intelligence"}
{"index": 738, "text": "Real world traffic sign recognition is an important step towards building autonomous vehicles, most of which highly dependent on Deep Neural Networks (DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to adversarial examples. Many attack methods have been proposed to understand and generate adversarial examples, such as gradient based attack, score based attack, decision based attack, and transfer based attacks. However, most of these algorithms are ineffective in real-world road sign attack, because (1) iteratively learning perturbations for each frame is not realistic for a fast moving car and (2) most optimization algorithms traverse all pixels equally without considering their diverse contribution. To alleviate these problems, this paper proposes the targeted attention attack (TAA) method for real world road sign attack. Specifically, we have made the following contributions: (1) we leverage the soft attention map to highlight those important pixels and skip those zero-contributed areas -this also helps to generate natural perturbations, (2) we design an efficient universal attack that optimizes a single perturbation/noise based on a set of training images under the guidance of the pre-trained attention map, (3) we design a simple objective function that can be easily optimized, (4) we evaluate the effectiveness of TAA on real world data sets. Experimental results validate that the TAA method improves the attack successful rate (nearly 10%) and reduces the perturbation loss (about a quarter) compared with the popular RP2 method. Additionally, our TAA also provides good properties, e.g., transferability and generalization capability. We provide code and data to ensure the reproducibility: https://github.com/AdvAttack/RoadSignAttack.", "paperid": 3097206420, "normalizedname_level1": "artificial intelligence"}
{"index": 739, "text": "There are many applications available for detecting the electricity theft. However, only few studies compare the machine learning techniques in discovering electricity-stealing behavior. This study, therefore, compares the predictive accuracy of several machine learning methods including Logistic Regression (LR), The K-Nearest Neighbor Algorithm, (K-NN), Support Vector Machines (SVM), and Neural Networks (NNet) for predicting the electricity thefts in a concrete model.", "paperid": 3010832015, "normalizedname_level1": "artificial intelligence"}
{"index": 740, "text": "Learning general image representations has proven key to the success of many computer vision tasks. For example, many approaches to image understanding problems rely on deep networks that were initially trained on ImageNet, mostly because the learned features are a valuable starting point to learn from limited labeled data. However, when it comes to 3D motion capture of multiple people, these features are only of limited use. In this paper, we therefore propose an approach to learning features that are useful for this purpose. To this end, we introduce a self-supervised approach to learning what we call a neural scene decomposition (NSD) that can be exploited for 3D pose estimation. NSD comprises three layers of abstraction to represent human subjects: spatial layout in terms of bounding-boxes and relative depth; a 2D shape representation in terms of an instance segmentation mask; and subject-specific appearance and 3D pose information. By exploiting self-supervision coming from multiview data, our NSD model can be trained end-to-end without any 2D or 3D supervision. In contrast to previous approaches, it works for multiple persons and full-frame images. Because it encodes 3D geometry, NSD can then be effectively leveraged to train a 3D pose estimation network from small amounts of annotated data.", "paperid": 2962806941, "normalizedname_level1": "artificial intelligence"}
{"index": 741, "text": "This paper proposes the decision tree latent controller generative adversarial network (DTLC-GAN), an extension of a GAN that can learn hierarchically interpretable representations without relying on detailed supervision. To impose a hierarchical inclusion structure on latent variables, we incorporate a new architecture called the DTLC into the generator input. The DTLC has a multiple-layer tree structure in which the ON or OFF of the child node codes is controlled by the parent node codes. By using this architecture hierarchically, we can obtain the latent space in which the lower layer codes are selectively used depending on the higher layer ones. To make the latent codes capture salient semantic features of images in a hierarchically disentangled manner in the DTLC, we also propose a hierarchical conditional mutual information regularization and optimize it with a newly defined curriculum learning method that we propose as well. This makes it possible to discover hierarchically interpretable representations in a layer-by-layer manner on the basis of information gain by only using a single DTLC-GAN model. We evaluated the DTLC-GAN on various datasets, i.e., MNIST, CIFAR-10, Tiny ImageNet, 3D Faces, and CelebA, and confirmed that the DTLC-GAN can learn hierarchically interpretable representations with either unsupervised or weakly supervised settings. Furthermore, we applied the DTLC-GAN to image-retrieval tasks and showed its effectiveness in representation learning.", "paperid": 2962764349, "normalizedname_level1": "artificial intelligence"}
{"index": 742, "text": "Detection of skin in images is a very important clue in many image processing applications such as biometric system, medical imaging, face recognition and many more. An eye’s perception of human skin depends on sensing the color, texture, feel and many more factors. This paper is a survey paper. Some popular approaches that are used to identify human skin are endowed. To distinguish skin from the given image based on colors, various methods are discussed that are based on different color models. Based on the survey, a comparison of various methods is provided.", "paperid": 3035335680, "normalizedname_level1": "artificial intelligence"}
{"index": 743, "text": "In order to compress omnidirectional video clips, a projection onto a two-dimensional image plane is necessary. The most commonly used projection format is the equirectangular panoramic projection, which results into a significant amount of redundant samples in the polar areas. The redundant samples incur extra bitrate and increase the encoding/decoding time. In this paper, we study regional down-sampling (RDS) for achieving better compression and smaller encoding/decoding time for omnidirectional content. We extend the persistent RDS method applied equally to all pictures to be applied to selected pictures only in our proposed temporal RDS method and then compare the persistent and temporal RDS methods. The simulation results indicate that both the persistent and temporal RDS improve the rate-distortion (RD) performance compared to the conventional coding of equirectangular panoramas, while the temporal RDS method has less sequence-wise RD performance variation and slightly better RD performance on average when compared to the persistent RDS technique. Alongside the coding methods, we study spherical quality measurement methods for VR images/video and analyze the coding methods with these quality metrics. Moreover, we propose a uniformly sampled spherical quality metric in order to evaluate the coding distortion of omnidirectional videos.", "paperid": 2610830679, "normalizedname_level1": "artificial intelligence"}
{"index": 744, "text": "In this paper, we present a novel pixel-based airplane segmentation method from remote sensing images by combining Single Shot MultiBox Detector (SSD) and Single-layer Cellular Automata (SCA). SSD is a kind of deep ConvNet for object detection while SCA is a saliency detection method via Cellular Automata. First, we obtain detection result where every airplane is boxed by a rectangle through the SSD model. The last two conventional layers in original SSD are removed in order to fit the small objects of remote sensing (RS) image. Then the result is processed via single-layer Cellular Automata to achieve pixel-based segmentation. The experiments demonstrate that our approach is efficient and works well for automatic airplane segmentation in RS image.", "paperid": 2736136227, "normalizedname_level1": "artificial intelligence"}
{"index": 745, "text": "Falls are one of the greatest risks for the older adults living alone at home. This paper presents a novel visual-based fall detection approach to support independent living for older adults. The proposed approach employs three unique features; motion information, human shape variation and projection histogram to detect a fall. Motion information of a segmented silhouette, which when extracted can provide a useful cue for classifying different behaviours. Also, the projection histogram and variation in human shape can be used to describe human body postures and subsequently fall events. The proposed approach presented here extracts motion information, using best-fit approximated ellipse around the human body and in addition projection histogram features to further improve the accuracy of fall detection. Experimental results are presented and show high fall detection rate of 99.81% with partially occluded video data.", "paperid": 2810743613, "normalizedname_level1": "artificial intelligence"}
{"index": 746, "text": "Occlusion is one of the major challenges for object tracking in real life scenario. Various techniques in particle filter framework have been developed to solve this problem. This framework depends on two issues: motion model and observation (likelihood) model. Due to the lack of effective observation model and efficient motion model, problem of occlusion still remains unsolvable in the tracking task. In this article, an effective observation model is proposed based on confidence (classification) score provided by the developing online prototypes based discriminative appearance model. This appearance model is constructed with the prior knowledge of two classes (object and background) and tries to discriminate between three classes such as object, background and occluded part of the object. The considered composite motion model can handle both the object motion as well as scale change of the object. The proposed update mechanism is able to adapt the appearance changes during tracking. We show a realization of the proposed method and demonstrate its performance (both quantitatively and qualitatively) with respect to state-of-the-art techniques on several challenging sequences. Analysis of the results concludes that the proposed technique can track (fully or partially) occluded objects as well as objects in various complex environments in a better way as compared to the existing ones.", "paperid": 2563422734, "normalizedname_level1": "artificial intelligence"}
{"index": 747, "text": "The version identification (VI) task deals with the automatic detection of recordings that correspond to the same underlying musical piece. Despite many efforts, VI is still an open problem, with much room for improvement, specially with regard to combining accuracy and scalability. In this paper, we present MOVE, a musically-motivated method for accurate and scalable version identification. MOVE achieves state-of-the-art performance on two publicly-available benchmark sets by learning scalable embeddings in an Euclidean distance space, using a triplet loss and a hard triplet mining strategy. It improves over previous work by employing an alternative input representation, and introducing a novel technique for temporal content summarization, a standardized latent space, and a data augmentation strategy specifically designed for VI. In addition to the main results, we perform an ablation study to highlight the importance of our design choices, and study the relation between embedding dimensionality and model performance.", "paperid": 3015271757, "normalizedname_level1": "artificial intelligence"}
{"index": 748, "text": "A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is  WeightLifter , a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.", "paperid": 2510911826, "normalizedname_level1": "artificial intelligence"}
{"index": 749, "text": "Resting state Functional magnetic resonance imaging (rsfMRI) provides complementary information to the sulcal brain anatomy about the cytoarchitecture and function of the human brain. Hence due to this parcellation based on rsfMRI is popular for potential application. This paper presents a comparison of correlation based connectivity measures and addresses the question what connectivity measure should be used for fMRI based connectivity analysis. It is observed that the popularly used functional connectivity measure does not show an adequate performance and is also computationally expensive. A new measure of connectivity is suggested and evaluated in the present work based on geodesic distance. A quantitative performance provides evidence that the proposed geodesic distance measure performs best for the connectivity studies.", "paperid": 2728532816, "normalizedname_level1": "artificial intelligence"}
{"index": 750, "text": "Scientists frequently use experiments published in other articles or reports by governing entities (e.g. NIH) as templates for reporting on their own experiments. Those templates occasionally change to reflect new discoveries. For creating retrospective studies and meta-analyses, finding the template parameters associated with scientific results can be critical. To aid in the extraction of experimental parameters (e.g. animal housing temperature) in a corpus of ∼8M scientific reports, we used a combination of pattern matching, part of speech tagging, units and measures extraction, and machine learning. We describe a use case where the housing temperature used for experiments involving mice was shown to impact their response to tumor reduction drugs. We show that 1) combining deep learning and pattern matching is a good model to address the problem described and 2) that researcher's behavior and experimental template usage takes a while to change after the publication of an important discovery.", "paperid": 2784291557, "normalizedname_level1": "artificial intelligence"}
{"index": 751, "text": "Adversarial domain adaptation (DA) has been an effective approach for learning domain-invariant features by adversarial training. In this paper, we propose a novel adversarial DA approach completely defined in spherical feature space, in which we define spherical classifier for label prediction and spherical domain discriminator for discriminating domain labels. To utilize pseudo-label robustly, we develop a robust pseudo-label loss in the spherical feature space, which weights the importance of estimated labels of target data by posterior probability of correct labeling, modeled by Gaussian-uniform mixture model in spherical feature space. Extensive experiments show that our method achieves state-of-the-art results, and also confirm effectiveness of spherical classifier, spherical discriminator and spherical robust pseudo-label loss.", "paperid": 3034738317, "normalizedname_level1": "artificial intelligence"}
{"index": 752, "text": "Tuberculosis(TB) in India is the world’s largest TB epidemic [1] leading to 480,000 deaths every year [2]. Between the years 2006 and 2014, Indian economy lost $340 billion(USD) due to TB. This, combined with the emergence of drug resistant bacteria in India makes the problem worse [3]. The government of India has hence come up with a new strategy which requires a high-sensitivity microscopy based TB diagnosis mechanism [2]. We propose a new deep neural network based TB diagnosis methodology with recall and precision of 83.78% and 67.55% respectively for bacillus detection from microscopy images of sputum. The proposed method takes a microscopy image of sputum with proper zoom level as input and returns locations of suspected Mycobacterium tuberculosis bacilli as output. The high sensitivity of our method gives it the potential to evolve into an effective and accessible screening tool for TB detection, when trained at scale.", "paperid": 2964322910, "normalizedname_level1": "artificial intelligence"}
{"index": 753, "text": "The aim of the study is to compare motor performance of goal-directed vs. non-goal-directed dorsiflexion ankle movements, for exploring how the central nervous system (CNS) plans movements that require the optimization of different kinematic parameters, which are the movement accuracy and speed. Measurements were performed using the pediAnklebot robot on 10 normally developed children. The protocol consisted of two tasks (i.e. goal-directed and non-goal-directed), each one composed by 20 movement trials. Subjects performed the protocol with both dominant and non-dominant leg. In the goal-directedtask, the subject was instructed to control a pointer in the monitor, by means of the ankle dorsiflexion movements, to reach a virtual target with a straight trajectory. In the non-goal-directed task, instead, the subject was asked to perform the same movement aiming at fast kicking a virtual ball. Ankle angular displacements were gathered by encoders embedded in the robot. Ankle motor performance was evaluated by means of both kinematic (duration of the movement, lateral deviation, position error and speed metric) and submovement indices (number, duration and rate). Comparing the two tasks, no differences were found in kinematic parameters, whereas differences were highlighted in submovement features. From the results, it emerges a higher capability of the central nervous system in planning non-goal-directed movements than goal-directed ones, even if the smoothness and accuracy of the trajectory have not been altered by the different required task. These findings provide an important starting point to understand how the CNS changes the motor planning to face different request in the execution of the movement, such as accuracy or speed optimization.", "paperid": 2886237054, "normalizedname_level1": "artificial intelligence"}
{"index": 754, "text": "A robust calibration and supervised machine learning reliability framework has been developed to aid the circuit designer in the design and implementation of reliable digitally-reconfigurable self-healing RFICs. For calibration algorithm performance and reliability validation, we advocate the use of surrogate modeling, a supervised machine learning technique, which offers a significant reduction in the required computational complexity relative to relying solely on the execution of expensive circuit simulations. An RF phase rotator test case is used to show the robustness and utility of the developed self-healing reliability framework.", "paperid": 2758089863, "normalizedname_level1": "artificial intelligence"}
{"index": 755, "text": "Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.", "paperid": 2751746637, "normalizedname_level1": "artificial intelligence"}
{"index": 756, "text": "Electrocardiogram (ECG) signal is widely used for diagnosing cardiac diseases. Several denoising methods have been proposed based on Empirical Mode Decomposition (EMD). Moreover, EMD is a successful tool for denoising. In this paper a review of comparative study of ECG signal denoising based on EMD and Thresholding Functions is presented. Five denoising algorithms (EMD-Conv, EMD-IT-Soft, EMD-IT-Hard, EMD-ITF and EMD-Custom) are applied on real ECG signals contaminated with different levels of white gaussian noise. EMD was applied to decompose adaptively a noisy signal into Intrinsic Mode Functions (IMFs). The noisy IMFs were denoised by thresholding functions. The performances are evaluated by measuring signal to noise ratio in dB and mean square error (MSE). EMD-Conv, EMD-IT-Soft, EMD-IT-Hard are used as references techniques. Simulation results show that the EMD-ITF and EMD-Custom approaches outperforms the conventional EMD methods.", "paperid": 2967016369, "normalizedname_level1": "artificial intelligence"}
{"index": 757, "text": "A study of human breast cancer using image processing is presented in this paper. Breast cancer can be treated effectively only if it is detected at the early stages. Thermography is a substitute for mammography and its significance is increased due to its non-invasiveness in breast cancer detection. In this work, suitable image enhancement algorithm is identified for a better support to the subjective analysis of breast cancer. The normal and abnormal images are also distinguished by extracting the features from the enhanced images. This paper consists of three stages of processing; In the first stage, separation of the region of breast from the original image is performed. In the second stage, image enhancement using overall brightness local contrast adaptive equalization (OBLCAE) algorithm is applied which is better even for low illumination color image. This method handles local contrast of low illumination color image and color thermograms can be effectively enhanced. In the final stage, feature extraction matrix is generated by applying GLCM over the enhanced image. This paper provides better support to the diagnosis of disease in breast based on the objective and subjective measures, which are calculated from breast images. In Future work, it can be used to classify the thermograms to provide a breast diagnostic tool for the detection of breast abnormalities.", "paperid": 2540612288, "normalizedname_level1": "artificial intelligence"}
{"index": 758, "text": "The basic tool in fundus treatment is laser coagulation, when a series of metered microscopic thermal wounds — laser coagulates — are applied in edema on the eye's retina. Currently available software packages are focused first on the use of the specified template (pattern) for coagulate location. Effects of the pattern application are caused by irregular coagulate location by reason of high variability in edema and vasculature forms. The paper presents algorithms for calculating a coagulate map within the framework of the solution of the sphere close-packing problem in a random region and research results for developed algorithms.", "paperid": 2767693465, "normalizedname_level1": "artificial intelligence"}
{"index": 759, "text": "I Ching (Chinese characters: $$$) philosophy, stemming from ancient Chinese culture, is Chinese view of empiricism, world outlook and dialectics. Over thousands of years of evolving and interpretation, its cosmological wisdom has broad and profound influences not only on Chinese prevailing philosophy, but also on westerns. I Ching concentrates on the virtue of being moderate and appropriate, representing the balance by which it is contended that power/destiny can be well generated/controlled. Among the whole 64 hexagrams in I Ching, is the QIAN hexagram which is ranked in the first place, standing for the strong action and the everlasting desire for success. Behind I Ching philosophy lie the thinking and action models of optimization, specifically, identification from changing states, embracing vision, and optimal action obeying the balance of moderateness and appropriateness. I Ching philosophy could act as the driving force to establish and develop new optimization scheme. In this regard, enlightened by I Ching philosophy, particularly the QIAN hexagram, we propose I Ching philosophy inspired optimization, labeled as ICO for continuous optimization problems. Characterized by population-based, stochastic, iterative, and empiricism inspired features, the ICO evolves the population of solutions by multiple searching operators derived from underlying mechanism of the QIAN hexagram, as expected that the balance between global exploration and local exploitation can be well achieved. Specifically, the whole population is divided into four subpopulations, each of which corresponds to one solid line (state in the QIAN hexagram), then five search operators are developed to perform the learning, emerging, controlling, chasing and stabilizing operations on each subpopulation. The performances of the proposed ICO are investigated on well-known testing benchmarks and digital IIR filter designing problem which is crucial in control field. Comparisons with several state-of-the-art algorithms show the efficacy of the proposed ICO algorithm.", "paperid": 2743674692, "normalizedname_level1": "artificial intelligence"}
{"index": 760, "text": "This communication proposes an unsupervised neighbor dependent nonlinear unmixing algorithm for hyperspectral data. The proposed mixing scheme models the reflectance vector of a pixel as the sum of a linear combination of the endmem-bers plus a nonlinear function acting on neighboring spectra. The nonlinear function belongs to a reproducing kernel Hilbert space. The observations themselves are considered as the endmember candidates, and the group lasso regulariza-tion is used to enable selecting the purest pixels among the candidates. Experiments on synthetic data demonstrate the effectiveness of the proposed approach.", "paperid": 2405897054, "normalizedname_level1": "artificial intelligence"}
{"index": 761, "text": "Stress disorders are a common issue among working IT professionals in the industry today. With changing lifestyle and work cultures, there is an increase in the risk of stress among the employees. Though many industries and corporates provide mental health related schemes and try to ease the workplace atmosphere, the issue is far from control. In this paper, we would like to apply machine learning techniques to analyze stress patterns in working adults and to narrow down the factors that strongly determine the stress levels. Towards this, data from the OSMI mental health survey 2017 responses of working professionals within the tech-industry was considered. Various Machine Learning techniques were applied to train our model after due data cleaning and preprocessing. The accuracy of the above models was obtained and studied comparatively. Boosting had the highest accuracy among the models implemented. By using Decision Trees, prominent features that influence stress were identified as gender, family history and availability of health benefits in the workplace. With these results, industries can now narrow down their approach to reduce stress and create a much comfortable workplace for their employees.", "paperid": 2965199238, "normalizedname_level1": "artificial intelligence"}
{"index": 762, "text": "Rolling element bearing is a vital but also an easily damageable part for rotating machinery. In this paper, sparse representation-based classification is introduced in the method of fault diagnosis for rolling bearing. In the method, Wavelet Packet Transform and Fisher discrimination criterion are used to construct the sample feature dictionary. It takes advantage of the Orthogonal Matching Pursuit algorithm to get sparse coefficients and diagnose fault according to the minimal ratio of reconstruction error to L1-norm of the sparse coefficients. Its performance is demonstrated in test of faulty bearing vibration signals, and its advantage is further validated through comparison with other classification-based diagnosis methods such as support vector machine.", "paperid": 3006133518, "normalizedname_level1": "artificial intelligence"}
{"index": 763, "text": "In this paper, a new optimization approach is designed for convolutional neural network (CNN) which introduces explicit logical relations between filters in the convolutional layer. In a conventional CNN, the filters’ weights in convolutional layers are separately trained by their own residual errors, and the relations of these filters are not explored for learning. Different from the traditional learning mechanism, the proposed correlative filters (CFs) are initiated and trained jointly in accordance with predefined correlations, which are efficient to work cooperatively and finally make a more generalized optical system. The improvement in CNN performance with the proposed CF is verified on five benchmark image classification datasets, including CIFAR-10, CIFAR-100, MNIST, STL-10, and street view house number. The comparative experimental results demonstrate that the proposed approach outperforms a number of state-of-the-art CNN approaches.", "paperid": 2561910431, "normalizedname_level1": "artificial intelligence"}
{"index": 764, "text": "Besides the traditional cartographic data sources, spatial information can also be derived from location-based sources. However, even though different location-based sources refer to the same physical world, each one has only partial coverage of the spatial entities, describe them with different attributes, and sometimes provide contradicting information. Hence, we introduce the spatial entity linkage problem, which finds which pairs of spatial entities belong to the same physical spatial entity. Our proposed solution (QuadSky) starts with a time-efficient spatial blocking technique (QuadFlex), compares pairwise the spatial entities in the same block, ranks the pairs using Pareto optimality with the SkyRank algorithm, and finally, classifies the pairs with our novel SkyEx-* family of algorithms that yield 0.85 precision and 0.85 recall for a manually labeled dataset of 1,500 pairs and 0.87 precision and 0.6 recall for a semi-manually labeled dataset of 777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the SkyEx-FES algorithm that explores only 27% of the skylines without any loss in F-measure. Furthermore, our fully unsupervised algorithm SkyEx-D approximates the optimal result with an F-measure loss of just 0.01. Finally, QuadSky provides the best trade-off between precision and recall, and the best F-measure compared to the existing baselines and clustering techniques, and approximates the results of supervised learning solutions.", "paperid": 3103302145, "normalizedname_level1": "artificial intelligence"}
{"index": 765, "text": "In facial animation, the accurate shape and motion of the lips of virtual humans is of paramount importance, since subtle nuances in mouth expression strongly influence the interpretation of speech and the conveyed emotion. Unfortunately, passive photometric reconstruction of expressive lip motions, such as a kiss or rolling lips, is fundamentally hard even with multi-view methods in controlled studios. To alleviate this problem, we present a novel approach for fully automatic reconstruction of detailed and expressive lip shapes along with the dense geometry of the entire face, from just monocular RGB video. To this end, we learn the difference between inaccurate lip shapes found by a state-of-the-art monocular facial performance capture approach, and the true 3D lip shapes reconstructed using a high-quality multi-view system in combination with applied lip tattoos that are easy to track. A robust gradient domain regressor is trained to infer accurate lip shapes from coarse monocular reconstructions, with the additional help of automatically extracted inner and outer 2D lip contours. We quantitatively and qualitatively show that our monocular approach reconstructs higher quality lip shapes, even for complex shapes like a kiss or lip rolling, than previous monocular approaches. Furthermore, we compare the performance of person-specific and multi-person generic regression strategies and show that our approach generalizes to new individuals and general scenes, enabling high-fidelity reconstruction even from commodity video footage.", "paperid": 2555027164, "normalizedname_level1": "artificial intelligence"}
{"index": 766, "text": "Fog is a major reason behind road accidents and road side causalities as it reduces visibility, limits contrast and distorts perception. This paper presents some concepts for maturing of a scheme which will be able to increase clearity in winter and foggy conditions using the light rays and heat properties. Various type of foggy environments, their effects on visibility range and remedial measures are discussed. We proposed the Infrared Vision (IV) for fog detection systems to improve object visibility in dense fog.", "paperid": 3007212077, "normalizedname_level1": "artificial intelligence"}
{"index": 767, "text": "The main idea of the recent proposed clustering by fast search and find of density peaks (CFSFDP) clustering algorithm depicts the cluster center with the local density and distance and it achieves significant effects in typical applications. But it can't select the cluster centers adaptively. Therefore, an improved CFSFDP algorithm is proposed in this paper, which determines the cluster centers by the Max-min algorithm. First, the Max-min algorithm is introduced to obtain the number of categories. Then the local density and distance information is used to determine the cluster centers as do in CFSFDP algorithm. It can not only adaptively obtain categories number of the data, but also obtain the corresponding clustering centers. The simulation results show that the proposed algorithm can find the number of categories and find the cluster centers. Meanwhile, it can find the cluster centers which are hard to be obtained through decision diagram.", "paperid": 2874182292, "normalizedname_level1": "artificial intelligence"}
{"index": 768, "text": "Agriculture plays an essential role in ecological, social, biological prospects of about 65 per cent to 70 per cent of the human population. The production of the crop decreases due to the bad effects of leaves, fruit leaves and plant diseases. Fruit, leaf infection is the main reason of the maximum damage of the fruit which decrease the amount and superiority of the farming. Citrus canker infection may infect plants or fruits like as orange leaves that disturb the creation of fruit in plants. The early detection of the disease is challenging aspect of improving the productivity of the plant. This analysis emphasized on the identification, classification and detection of the leaf disease. Firstly, describes the concept of the orange, orange leaf disease and symptoms. Then, a detailed survey of various papers has done. In addition, a detection and identification techniques are explained which includes GLCM, multi-SVM, threshold value, neural network and Fuzzy method. Then, a method is explained to diagnose infected orange leaf on the basis of the convolution neural network (CNN). Convolutional neural network (CNN) is one of the main area of research in classification and detection of the leave disease. The features of the fruit (orange) leaves are extracted to detect and classify the disease. In this study, various stages for identification of the leaves disease are described. In addition, different phases to overcome the leaves diseases are also explained namely conjuring up hidden layer method, visualization of feature, semantic library and consideration mapping. Lastly, architecture is demonstrated along with different steps and procedure in orange leaf disease.", "paperid": 3006060389, "normalizedname_level1": "artificial intelligence"}
{"index": 769, "text": "Text classification is the most important research issues in the field of data mining. The main idea of using the stemming technique is to reduce the number of features that can be extracted from the document. Furthermore, the stemming aims to enhance the accuracy of the classifier. This paper aims to study the effectiveness of using stemming techniques. The paper will use two popular word extractions: Khoja and Light stemmers. The results will compare with the result of classification without using the technique of word extraction. In the experiment, the Sequential Minimal Optimization (SMO), Naive Bayesian (NB) J48 and K-nearest neighbors (KNN) were used to build the training models and test the data. By implement the two approaches of word extraction and measured the accuracy of them by precision, recall and f-measure, the results show that the Light stemmers outperforms the Khoja stemmer. Furthermore, the results were comparing with the results of classification without using stemming technique.", "paperid": 2344555666, "normalizedname_level1": "artificial intelligence"}
{"index": 770, "text": "“The friction ridge pattern is a 3D structure which, in its natural state, is not deformed by contact with a surface”. Building upon this rather trivial observation, the present work constitutes a first solid step towards a paradigm shift in fingerprint recognition from its very foundations. We explore and evaluate the feasibility to move from current technology operating on 2D images of elastically deformed impressions of the ridge pattern, to a new generation of systems based on full-3D models of the natural non-deformed ridge pattern itself. There are already a small number of previous studies that have already started scratching the surface of 3D fingerprint recognition and that should not go overlooked. However, the vast majority of these few successful approaches published so far, are based on the reconstruction of fingerprints from multiple 2D images acquired with different lighting conditions (photometric stereo 3D reconstruction) or acquired from different angles (stereo vision 3D reconstruction). Such reconstruction methods lead in general to 2D fingerprints wrapped over the overall volume of the finger. These volumetric fingerprints have shown some promising performance, but still miss the real depth information of the ridge pattern, which, in the best case scenario, is coarsely estimated during the error-prone reconstruction process. In the present work we take one step further, directly acquiring for the first time in a consistent and repeatable manner, full-3D fingerprint models stored as point-clouds, where each point is defined by its $[x,y,z]$ coordinates. This way, the 3D data is directly measured by the sensor, with no post-processing reconstruction stage required. The complete recognition system developed represents as well an alternative to traditional technology based on minutiae detection. It shows that image-based processing algorithms and descriptors can be successfully applied to the new full-3D data, reaching very competitive results and confirming the high distinctiveness of the models.", "paperid": 3047652157, "normalizedname_level1": "artificial intelligence"}
{"index": 771, "text": "We present a framework for constructing a specific type of knowledge graph, a concept map from textbooks. Using Wikipedia, we derive prerequisite relations among these concepts. A traditional approach for concept map extraction consists of two sub-problems: key concept extraction and concept relationship identification. Previous work for the most part had considered these two sub-problems independently. We propose a framework that jointly optimizes these sub-problems and investigates methods that identify concept relationships. Experiments on concept maps that are manually extracted in six educational areas (computer networks, macroeconomics, precalculus, databases, physics, and geometry) show that our model outperforms supervised learning baselines that solve the two sub-problems separately. Moreover, we observe that incorporating textbook information helps with concept map extraction.", "paperid": 2532161561, "normalizedname_level1": "artificial intelligence"}
{"index": 772, "text": "Both vision and touch contribute to the perception of real surfaces. Although there have been many studies on the individual contributions of each sense, it is still unclear how each modality’s information is processed and integrated. To fill this gap, we investigated the similarity of visual and haptic perceptual spaces, as well as how well they each correlate with fingertip interaction metrics. Twenty participants interacted with ten different real surfaces from the Penn Haptic Texture Toolkit by either looking at or touching them and judged their similarity in pairs. By analyzing the resulting similarity ratings using non-metric multi-dimensional scaling (NMDS), we found that surfaces are similarly organized within the three-dimensional perceptual spaces of both modalities. Also, between-participant correlations were significantly higher in the haptic condition. In a separate experiment, we obtained the contact forces and accelerations acting on one finger interacting with each surface in a controlled way. We analyzed the collected fingertip interaction data in both the time and frequency domains. Our results suggest that the three perceptual dimensions for each modality can be represented by roughness/smoothness, hardness/softness, and friction, and that these dimensions can be estimated by surface vibration power, tap spectral centroid, and kinetic friction coefficient, respectively.", "paperid": 2948943639, "normalizedname_level1": "artificial intelligence"}
{"index": 773, "text": "Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities.", "paperid": 2584853650, "normalizedname_level1": "artificial intelligence"}
{"index": 774, "text": "This work presents an end-to-end trainable deep bidirectional LSTM (Long-Short Term Memory) model for image captioning. Our model builds on a deep convolutional neural network (CNN) and two separate LSTM networks. It is capable of learning long term visual-language interactions by making use of history and future context information at high level semantic space. Two novel deep bidirectional variant models, in which we increase the depth of nonlinearity transition in different way, are proposed to learn hierarchical visual-language embeddings. Data augmentation techniques such as multi-crop, multi-scale and vertical mirror are proposed to prevent overfitting in training deep models. We visualize the evolution of bidirectional LSTM internal states over time and qualitatively analyze how our models \"translate\" image to sentence. Our proposed models are evaluated on caption generation and image-sentence retrieval tasks with three benchmark datasets: Flickr8K, Flickr30K and MSCOCO datasets. We demonstrate that bidirectional LSTM models achieve highly competitive performance to the state-of-the-art results on caption generation even without integrating additional mechanism (e.g. object detection, attention model etc.) and significantly outperform recent methods on retrieval task", "paperid": 2339652278, "normalizedname_level1": "artificial intelligence"}
{"index": 775, "text": "Mogao Grottoes are known as one of the three famous ancient Buddhist sculptural sites of China, which contain some of finest Buddhist paintings spanning a period of 1,000 years. Chronological classification of the ancient Buddhist paintings of Mogao Grottoes can help archaeologists and culture researchers to study the humanities, customs and economy of the corresponding eras. In this paper, this paper first perform an initial study on the effect of three state-of-the-art convolutional neural network based methods (AlexNet, VGG and ResNet) on chronological classification of paintings of Mogao Grottoes, and then propose a new network by replacing the last average pooling layer of ResNet-50 with a sequential layers. Experiments demonstrate that our method achieves higher classification accuracy than the three models and two existing chronological classification methods.", "paperid": 2981058102, "normalizedname_level1": "artificial intelligence"}
{"index": 776, "text": "In the presence of metal implants, metal artifacts are introduced to x-ray CT images. Although a large number of metal artifact reduction (MAR) methods have been proposed in the past decades, MAR is still one of the major problems in clinical x-ray CT. In this work, we develop a convolutional neural network (CNN) based open MAR framework, which fuses the information from the original and corrected images to suppress artifacts. The proposed approach consists two phases. In the CNN training phase, we build a database consisting of metal-free, metal-inserted and pre-corrected CT images, and image patches are extracted and used for CNN training. In the MAR phase, the uncorrected and pre-corrected images are used as the input of the trained CNN to generate a CNN image with reduced artifacts. To further reduce the remaining artifacts, water equivalent tissues in a CNN image are set to a uniform value to yield a CNN prior, whose forward projections are used to replace the metal-affected projections, followed by the FBP reconstruction. The effectiveness of the proposed method is validated on both simulated and real data. Experimental results demonstrate the superior MAR capability of the proposed method to its competitors in terms of artifact suppression and preservation of anatomical structures in the vicinity of metal implants.", "paperid": 2753044865, "normalizedname_level1": "artificial intelligence"}
{"index": 777, "text": "One of the most popular techniques for eye-gaze tracking is pupil-corneal reflection (PCR). It is a low-cost and non-invasive approach, which consists of infrared lights to illuminate the user's eye and a camera for capturing the resulting images. The major problems of this technology are repeatability errors and the lack of accuracy. In this paper, we propose the use of an interactive method for reducing the systematic effects of PCR devices and we evaluate how this method affects the selection of a point in a 3D scenario acquired through the use of a Microsoft Kinect. Results show that, on a 17-inch screen with a resolution of 1280×1024 pixels, the systematic effects can be reduced from 100 to approximately 15 pixels and that the uncertainty also decreases in the 3D case. This could be a good starting point for using PCR technology in applications where the accurate estimate of a certain position, also in 3D, is fundamental.", "paperid": 2549020794, "normalizedname_level1": "artificial intelligence"}
{"index": 778, "text": "In visual object recognition problems essential to surveillance and navigation problems in a variety of military and civilian use cases, low-resolution and low-quality images present great challenges to this problem. Recent advancements in deep learning based methods like EDSR/VDSR have boosted pixel domain image super-resolution (SR) performances significantly in terms of signal to noise ratio(SNR)/ mean square error(MSE) metrics of the super-resolved image. However, these pixel domain signal quality metrics may not directly correlate to the machine vision tasks like key points detection and object recognition. In this work, we develop a machine vision tasks-friendly super-resolution technique which enhances the gradient images and associated features from the low-resolution images that benefit the high level machine vision tasks. Here, a residual learning deep neural network based gradient image super-resolution solution is developed with scale space adaptive network depth, and simulation results demonstrate the performance gains in both gradient image quality as well as key points repeatability.", "paperid": 2939565811, "normalizedname_level1": "artificial intelligence"}
{"index": 779, "text": "Visual tracking in a video is a challenging problem in computer vision. The core component of object tracker based on tracking-by-detection framework is a discriminative classifier, tasked with distinguishing between the target and the surrounding environment. Fast compressive tracking algorithm is utilized to cope with real time tracking which trained a classifier to distinguish foreground and background, however, it does not take into account the influence of previous positive samples, when target occluded, it is easy lead to tracking fail or drifting problem. This paper proposed a new samples extracted method which take the previous positive samples into classifier training, two sub-classifier are trained and combined to a strong classifier which is used to distinguish target. Experimental results demonstrated the effectiveness of our method.", "paperid": 2511730917, "normalizedname_level1": "artificial intelligence"}
{"index": 780, "text": "Video synthetic aperture radar (VideoSAR) presents significant potential to enhance the performance of automatic information retrieval and interpretation in the dynamic region of interest (DROI). Key-frame extraction represents effective contents in processing massive video data. In this article, a novel computer vision-based background subtraction perspective is proposed for automatic VideoSAR scattering key-frame selection. A universal parameterization scattering key-frame model is firstly investigated, which serves to reveal the VideoSAR scattering key frames. Then, a spatiotemporal scattering extractor, called the subaperture energy gradient (SEG), together with a modified statistical and knowledge-based object tracker (MSAKBOT) is proposed to robustly discriminate the scattering key-frame state of the alternation between transient persistence and disappearance. The proposed SEG-MSAKBOT method presents a more comprehensive measurement of scattering key frames that is adaptive to the multitemporal video sequences effectively. Finally, experimental results and performance assessment conducted on two real airborne VideoSAR data with the coherent integration angles of 21° and 27° demonstrate that the proposed perspective is robust and reliable to capture scattering key frames and video content summarization with highly accurate descriptions in various DROIs.", "paperid": 2985767503, "normalizedname_level1": "artificial intelligence"}
{"index": 781, "text": "Lung segmentation in chest radiographs is a requisite pre-processing step in the Computer-aided Diagnosis (CAD) system for the detection of chest diseases. This paper proposes an unsupervised lung segmentation method in chest radiographs based on shadow filter and multilevel thresholding. The method consists of three main processes: pre-processing, initial lung field estimation and noise elimination. For First step, resize the original image and adjust contrast. Then, shadow filter is applied to enhance each lung outlines. After that, the initial lung fields are estimated by using local thresholding, delete outer body regions, fill holes, filter regions from their properties, and using multilevel thresholding to remove unwanted regions. Finally, morphological operations and refine edge techniques are used to eliminate the noise in the result. All 247 chest radiographs from a public JSRT dataset were used to evaluate the performance. The performance measures of the proposed method (overlap, accuracy, sensitivity, specificity, precision, and F-score) are above 91% and the average computation time for 512 by 512 pixels resolutions is 8.46 seconds, improved from our previous work. The accuracy and overlap are 97.28% and 91.36%, respectively. The results show that our proposed unsupervised method is performed accurately.", "paperid": 2589536696, "normalizedname_level1": "artificial intelligence"}
{"index": 782, "text": "We propose a novel approach to address the problem of jointly tracking and gait recognition of multiple people in a video sequence. The most state of the art algorithms for gait recognition consider the cases where there is only one person without any occlusion in a very constrained environment. However, in real scenarios such as in airports, train stations, etc, there are many people in the environment that make these algorithms inapplicable. Although first tracking of each person and then gait recognition could be a solution, we argue that the multi-people tracking and the gait recognition in a video are two sub-problems that can help each other. Hence, we propose a joint tracking and gait recognition of multiple people as one framework that can improve gait recognition accuracy and decrease the ID switching in tracking. Experimental results confirm the validity of proposed approach.", "paperid": 2755083564, "normalizedname_level1": "artificial intelligence"}
{"index": 783, "text": "We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks (RNN). Our framework first extracts deep features from the input video frames with a deep Convolutional Neural Networks (CNN). Two RNN layers with an encoder-decoder architecture are then used to encode the visual features and sequentially generate the output words as the command. We demonstrate that the translation accuracy can be improved by allowing a smooth transaction between two RNN layers and using the state-of-the-art feature extractor. The experimental results on our new challenging dataset show that our approach outperforms recent methods by a fair margin. Furthermore, we combine the proposed translation module with the vision and planning system to let a robot perform various manipulation tasks. Finally, we demonstrate the effectiveness of our framework on a full-size humanoid robot WALK-MAN.", "paperid": 2963860638, "normalizedname_level1": "artificial intelligence"}
{"index": 784, "text": "In large squint high-resolution cases, smearing introduced by path deviation and air turbulence in synthetic aperture radar (SAR) imagery reconstructed via fast factorised backprojection algorithm (FFBP) will exist along space variant oblique angles. To refocus the blurred FFBP imagery, a motion phase error estimation and compensation methodology based on range bandwidth factorisation is proposed in this study. Motion phase error is estimated based on lower resolution data and then sparsity-driven combination is performed to derive the high-resolution refocused imagery. Extended point target simulation can verify the bandwidth-factorisation-based autofocus algorithm.", "paperid": 2953522425, "normalizedname_level1": "artificial intelligence"}
{"index": 785, "text": "Nonlinear similarity measures defined in kernel space, such as correntropy, can extract higher order statistics of data and offer potentially significant performance improvement over their linear counterparts especially in non Gaussian signal processing and machine learning. In this paper, we propose a new similarity measure in kernel space, called the  kernel risk-sensitive loss  (KRSL), and provide some important properties. We apply the KRSL to adaptive filtering and investigate the robustness, and then develop the MKRSL algorithm and analyze the mean square convergence performance. Compared with correntropy, the KRSL can offer a more efficient performance surface, thereby enabling a gradient-based method to achieve faster convergence speed and higher accuracy while still maintaining the robustness to outliers. Theoretical analysis results and superior performance of the new algorithm are confirmed by simulation.", "paperid": 2500157231, "normalizedname_level1": "artificial intelligence"}
{"index": 786, "text": "Centrifugal pumps are fundamental instruments in many industry plants, whose continuously operation plays an important role in the production cycle. For improving production efficiency, autonomous pump fault diagnosis has been widely adopted by many enterprises and has also attracted great research attentions. Existing studies exploit machine learning algorithms for autonomous pump fault diagnosis, which generally needs human knowledge to select distinctive data features. To avoid the bias of human selection, this paper proposes a multi-kernel learning (MKL) based autonomous pump fault diagnosis method. It trains basic classifiers (BCs) by each feature and weightily combines the basic classifiers to form the combined classifier for fault diagnosis. An autonomous BC weighting algorithm is proposed, which trains the combination weights of the BCs autonomously. We show the MKL based fault diagnosis method provide more accurate fault detection than the existing methods and without the need of human experts' interventions.", "paperid": 2903988403, "normalizedname_level1": "artificial intelligence"}
{"index": 787, "text": "Multiple sclerosis (MS) is a major auto-immune disease that is the leading cause of non-traumatic impairment of the central nervous system (CNS) in young adults. Successful treatment of MS patients depends on accurate tools for both the MS diagnosis and the disability progression. In current and upcoming studies the authors aim to explore the capabilities of applying a commercial electromyographic and inertial sensor (MYO Armband by Thalmic Labs Inc.), coupled with a multichannel signal processing tool, to standard neurological examination of MS progression. In this pilot study we formulate a two-class “healthy control” - “having MS” classification problem. A dataset of electromyographic signals and inertial sensor measurements from 71 individuals (31 MS patients and 40 healthy controls) was acquired during standard neurological examination routine. Temporal and spectral features of the signals were extracted in order to train and validate a classification model. Finally, a Support Vector Machine classifier was obtained giving AUROC = 0.94, 95% CI = [0.88, 0.99]. We propose a set of signal descriptors that correlate with objective components of the neurological examination. The proposed signal acquisition and processing technique, being easy to integrate into the traditional neurological exam, may have high potential for aiding in quantifying MS progression.", "paperid": 2889466198, "normalizedname_level1": "artificial intelligence"}
{"index": 788, "text": "Whenever I hear or read \"Industry 4.0\" or 4th Industrial Revolution I experience contrasting feelings. On the one hand, I have in mind the evolution of technology: the automation, the robotics, the Internet of Things (IoT), the artificial intelligence and the fundamental role of measurements, sensors, sensor networks, data acquisition systems and data processing, that have the promising scent of the future; on the other hand, I have some concerns about the consequences of this evolution and in particular on our occupations.", "paperid": 2905361449, "normalizedname_level1": "artificial intelligence"}
{"index": 789, "text": "This paper addresses the attitude estimation problem using vector and gyroscope measurements. We propose a novel adaptation scheme for the complementary filter cut-off frequency which is based on the similarity between independent estimates obtained from the vector and gyroscope measurements. The adaptive complementary filter is also derived on the special orthogonal group and convergence of the filter is established. The effectiveness of our approach is demonstrated with simulation results.", "paperid": 2903459759, "normalizedname_level1": "artificial intelligence"}
{"index": 790, "text": "In this paper, a Discrete Genetic Algorithm (DGA) is proposed for solving the task allocation problem in a multi-robot scenario. In the proposed DGA, a discrete population generation is proposed to adjust the genetic algorithm for solving the task allocation problem of a multi-robot system which aims to maintain the balance of exploration and exploitation. In the proposed scenario, the defined problem consists of assigning the robots to the known targets in two-dimensional search space. The scalability of the proposed DGA algorithm is tested in terms of the number of robots. The comparison confirms the superiority of the proposed method compared to the existing methods.", "paperid": 3094630817, "normalizedname_level1": "artificial intelligence"}
{"index": 791, "text": "In this paper, we address the problem of deformed point clouds of small targets under farm condition. Strawberry point cloud data were extracted through image detection and corresponding coordinate transformation. The deformed point cloud caused by adhesion of adjacent objects make the localization inaccurate. Therefore, multiple features in three spatial dimensions were constructed to represent the shape and distribution of the strawberry point data. Some fundamental features, such as eccentricity and least moment of inertia, were utilized, while some new features, such as 3D shape matrix and ratio of data amount in certain space, were proposed. Furthermore, classifiers that can identify unpickable strawberry data and other defined classes were trained and evaluated on constructed features and different label sets. The evaluation results show that the classifier could effectively identify unpickable cases. This work proposes a new problem and provides possible solutions that could optimize the performance of machine vision system of the strawberry harvesting robot.", "paperid": 3091989549, "normalizedname_level1": "artificial intelligence"}
{"index": 792, "text": "Learning automatically the structure of object categories remains an important open problem in computer vision. In this paper, we propose a novel unsupervised approach that can discover and learn landmarks in object categories, thus characterizing their structure. Our approach is based on factorizing image deformations, as induced by a viewpoint change or an object deformation, by learning a deep neural network that detects landmarks consistently with such visual effects. Furthermore, we show that the learned landmarks establish meaningful correspondences between different object instances in a category without having to impose this requirement explicitly. We assess the method qualitatively on a variety of object types, natural and man-made. We also show that our unsupervised landmarks are highly predictive of manually-annotated landmarks in face benchmark datasets, and can be used to regress these with a high degree of accuracy.", "paperid": 2962981304, "normalizedname_level1": "artificial intelligence"}
{"index": 793, "text": "Thanks to the rapid increase in technology and electronic communications, e-mail has become a serious communication tool. In many applications such as business correspondence, reminders, academic notices, web page memberships, e-mail is used as primary way of communication. If we ignore spam e-mails, there remain hundreds of e-mails received every day. In order to determine the importance of received e-mails, the subject or content of each e-mail must be checked. In this study we proposed an unsupervised system to classify received e-mails. Received e-mails' coordinates are determined by a method of natural language processing called as Word2Vec algorithm. According to the similarities, processed data are grouped by k-means algorithm with an unsupervised training model. In this study, 10517 e-mails were used in training. The success of the system is tested on a test group of 200 e-mails. In the test phase M3 model (window size 3, min. Word frequency 10, Gram skip) consolidated the highest success (91%). Obtained results are evaluated in section VI.", "paperid": 2969401096, "normalizedname_level1": "artificial intelligence"}
{"index": 794, "text": "The main goal of supervised data analytics is to model a target phenomenon given a limited amount of samples, each represented by an arbitrarily large number of variables. Especially when the number of variables is much larger than the number of available samples, variable selection is a key step as it allows to identify a possibly reduced subset of relevant variables describing the observed phenomenon. Obtaining interpretable and reliable results, in this highly indeterminate scenario, is often a non-trivial task. In this work we present PALLADIO, a framework designed for HPC cluster architectures, that is able to provide robust variable selection in high-dimensional problems. PALLADIO is developed in Python and it integrates CUDA kernels to decrease the computational time needed for several independent element-wise operations. The scalability of the proposed framework is assessed on synthetic data of different sizes, which represent realistic scenarios.", "paperid": 2564561867, "normalizedname_level1": "artificial intelligence"}
{"index": 795, "text": "Despite the existence of various matching algorithms, matching of images from Micro Aerial Vehicles (MAVs) and airplanes is still a tough problem due to the substantial differences in scale and rotation. This paper investigates the fusion of MAV imagery and airplane imagery and proposes a new robust image matching method with self-adaption to differences in scale and viewing direction. This method is further applied to register a MAV image block with reference to the orthophoto and DSM of a previously-geolocalized aerial image dataset. After registration, a fused 3D point cloud is generated and then combined with images as inputs for land cover (here roofs) classification. Experiments show that the proposed matching method outperforms SIFT/ASIFT methods in both quantity and reliability of matching results, while the registration of MAV imagery achieves decimeter-level accuracy without using any onboard GPS/IMU data. Besides, the pixel-level classification that integrates information of point clouds and images achieves significantly higher accuracy than simply image-based classification.", "paperid": 2547296514, "normalizedname_level1": "artificial intelligence"}
{"index": 796, "text": "Generative adversarial networks (GAN) are trained through a minimax game between a generator and a discriminator to generate data that mimics observations. While being widely used, GAN training is known to be empirically unstable. This paper presents a new theory for generative adversarial methods that does not rely on the traditional minimax formulation. Our theory shows that with a strong discriminator, a good generator can be obtained by composite functional gradient learning, so that several distance measures (including the KL divergence and the JS divergence) between the probability distributions of real data and generated data are simultaneously improved after each functional gradient step until converging to zero. This new point of view leads to stable procedures for training generative models. It also gives a new theoretical insight into the original GAN. Empirical results on image generation show the effectiveness of our new method.", "paperid": 2955680640, "normalizedname_level1": "artificial intelligence"}
{"index": 797, "text": "Point clouds have recently gained interest for the represention of 3D scenes in augmented and virtual reality. In real-time applications point clouds typically assume one color per point. While this approach is suited to represent diffuse objects, it is less realistic with specular surfaces. We consider the compression of plenoptic point clouds, wherein each voxel is associated to colors as seen by different angles. We propose an efficiently compressible representation to incorporate the plenoptic information of each voxel. We have proposed three compression methods, one based on a cylindrical projection and two others based on the intersection of the line of view with the voxel's face, one using flat boundaries and the other using a spherical boundary. Extensive tests have shown that the last two have the best performance, which are much superior than independently encoding the color attributes from each of the cameras point of views.", "paperid": 2891837944, "normalizedname_level1": "artificial intelligence"}
{"index": 798, "text": "The human visual system (HVS) exhibits nonlinear sensitivity to the distortions introduced by lossy image and video coding. This effect is due to the luminance masking, contrast masking, and spatial and temporal frequency masking characteristics of the HVS. This paper proposes a novel perception-based quantization to remove nonvisible information in high dynamic range (HDR) color pixels by exploiting luminance masking so that the performance of the High Efficiency Video Coding (HEVC) standard is improved for HDR content. A profile scaling based on a tone-mapping curve computed for each HDR frame is introduced. The quantization step is then perceptually tuned on a transform unit basis. The proposed method has been integrated into the HEVC reference model for the HEVC range extensions (HM-RExt), and its performance was assessed by measuring the bitrate reduction against the HM-RExt. The results indicate that the proposed method achieves significant bitrate savings, up to 42.2%, with an average of 12.8%, compared with HEVC at the same quality (based on HDR-visible difference predictor-2 and subjective evaluations).", "paperid": 1991171126, "normalizedname_level1": "artificial intelligence"}
{"index": 799, "text": "We find that most Scene Graph Generation approaches suffer from two limitations as they: 1) use generic attention mechanisms and dataset-specific statistics that supersede visual features and 2) treat \"no interaction\" as an extra, both noisy and dominant, class and prune graph edges manually or applying simple filters. As a result, such approaches do not scale up on different settings and specifications. We propose a three-stage pipeline that employs Multi-Head Attention driven by language and spatial features, Translation Embeddings and Multi-Tasking to detect an interacting pair of objects. Our attentional scheme is able to maximize the visual features' interpretability, as well as to capture the nature of datasets of different scales, while multi-tasking robustly resolves the bias of the background class. We present an experimental overview of the related literature, unveil a multitude of evaluation inconsistencies and provide quantitative and qualitative support with experiments on a variety of datasets, where our approach performs on par or even outperforms current state-of-the-art.", "paperid": 2992195701, "normalizedname_level1": "artificial intelligence"}
